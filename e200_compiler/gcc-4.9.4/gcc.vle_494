diff --git a/gcc/calls.c b/gcc/calls.c
index abf61c6..0aaa22c 100644
--- a/gcc/calls.c
+++ b/gcc/calls.c
@@ -872,7 +872,9 @@ precompute_register_parameters (int num_actuals, struct arg_data *args,
 
 	   For small register classes, also do this if this call uses
 	   register parameters.  This is to avoid reload conflicts while
-	   loading the parameters registers.  */
+	   loading the parameters registers.
+
+	   Avoid creating the extra move if optimizing for size.  */
 
 	else if ((! (REG_P (args[i].value)
 		     || (GET_CODE (args[i].value) == SUBREG
@@ -880,6 +882,7 @@ precompute_register_parameters (int num_actuals, struct arg_data *args,
 		 && args[i].mode != BLKmode
 		 && set_src_cost (args[i].value, optimize_insn_for_speed_p ())
 		    > COSTS_N_INSNS (1)
+		 && !optimize_size
 		 && ((*reg_parm_seen
 		      && targetm.small_register_classes_for_mode_p (args[i].mode))
 		     || optimize))
diff --git a/gcc/config.gcc b/gcc/config.gcc
index 094e426..7991dbd 100644
--- a/gcc/config.gcc
+++ b/gcc/config.gcc
@@ -2275,6 +2275,12 @@ powerpc-xilinx-eabi*)
 	tmake_file="rs6000/t-fprules rs6000/t-ppcgas rs6000/t-ppccomm rs6000/t-xilinx"
 	use_gcc_stdint=wrap
 	;;
+powerpc-*-eabivle)
+	tm_file="${tm_file} elfos.h usegas.h freebsd-spec.h newlib-stdint.h rs6000/sysv4.h rs6000/singlefp.h rs6000/e200.h"
+	extra_options="${extra_options} rs6000/sysv4.opt"
+	tmake_file="rs6000/t-e200"
+	use_gcc_stdint=wrap
+	;;
 powerpc-*-eabi*)
 	tm_file="${tm_file} dbxelf.h elfos.h usegas.h freebsd-spec.h newlib-stdint.h rs6000/sysv4.h rs6000/eabi.h rs6000/e500.h"
 	extra_options="${extra_options} rs6000/sysv4.opt"
@@ -3946,7 +3952,7 @@ case "${target}" in
 			| 401 | 403 | 405 | 405fp | 440 | 440fp | 464 | 464fp \
 			| 476 | 476fp | 505 | 601 | 602 | 603 | 603e | ec603e \
 			| 604 | 604e | 620 | 630 | 740 | 750 | 7400 | 7450 \
-			| a2 | e300c[23] | 854[08] | e500mc | e500mc64 | e5500 | e6500 \
+			| a2 | e200z[023467] | e300c[23] | 854[08] | e500mc | e500mc64 | e5500 | e6500 \
 			| titan | 801 | 821 | 823 | 860 | 970 | G3 | G4 | G5 | cell)
 				# OK
 				;;
diff --git a/gcc/config/rs6000/constraints.md b/gcc/config/rs6000/constraints.md
index 78a3ff0..4929cc9 100644
--- a/gcc/config/rs6000/constraints.md
+++ b/gcc/config/rs6000/constraints.md
@@ -178,6 +178,103 @@
   (and (match_code "const_int")
        (match_test "(unsigned HOST_WIDE_INT) ((- ival) + 0x8000) < 0x10000")))
 
+;; VLE constraints
+
+(define_register_constraint "kareg" "VLE_ALT_REGS"
+  "Alternate General Purpose Register in the range r8-r23 to be used in VLE")
+
+(define_register_constraint "kcreg" "VLE_CR_REGS"
+  "CR fields from Field 0 to Field 3 to be used in VLE")
+
+(define_register_constraint "kcrxx"
+  "rs6000_constraints[RS6000_CONSTRAINT_kcrxx]"
+  "@internal")
+
+(define_constraint "kli20"
+  "A signed 20-bit immediate"
+  (and (match_code "const_int")
+       (match_test "ival >= -524288 && ival <= 524287")))
+
+(define_constraint "kmsd4"
+  "An SD4(Rx) form memory operand"
+  (match_operand 0 "vle_sd4_operand"))
+
+(define_constraint "kmmd8"
+  "An 8-bit signed immediate"
+  (and (match_code "const_int")
+       (match_test " ival >= -128 && ival < 128")))
+
+(define_constraint "koim5"
+  "A constant in the range 1-32"
+  (and (match_code "const_int")
+       (match_test "ival >= 1 && ival <= 32")))
+
+(define_constraint "kone1"
+  "The constant 1"
+  (match_test "op == const1_rtx || op == CONST1_RTX (GET_MODE (op))"))
+
+(define_register_constraint "kregs" "VLE_REGS"
+  "General Purpose Register in the ranges r0-r7 or r24-r31 to be used in VLE")
+
+(define_constraint "ksci8"
+  "An eight bit immediate constant shifted left by 0, 1, 2 or 3 bytes"
+  (and (match_code "const_int")
+       (match_test "valid_sci8_immediate (ival)")))
+
+(define_constraint "kscp8"
+  "A constant whose negation is an eight bit immediate shifted left by 0, 1, 2 or 3 bytes"
+  (and (match_code "const_int")
+       (match_test "valid_sci8_immediate (-ival)")))
+
+(define_constraint "kscI8"
+  "An immediate constant that matches the ksci8 or I constraint if making VLE or non-VLE code respectively"
+  (and (match_code "const_int")
+       (if_then_else (match_test "TARGET_VLE")
+		     (match_test "satisfies_constraint_ksci8 (op)")
+		     (match_test "satisfies_constraint_I (op)"))))
+
+(define_constraint "kscP8"
+  "An immediate constant that matches the kscp8 or P constraint if making VLE or non-VLE code respectively"
+  (and (match_code "const_int")
+       (if_then_else (match_test "TARGET_VLE")
+		     (match_test "satisfies_constraint_kscp8 (op)")
+		     (match_test "satisfies_constraint_P (op)"))))
+
+(define_constraint "kuim5"
+  "A constant in the range 0-31"
+  (and (match_code "const_int")
+       (match_test "ival >= 0 && ival <= 31")))
+
+(define_constraint "kbit5"
+  "A 32-bit constant that has exactly one bit set"
+  (and (match_code "const_int")
+       (ior (match_test "ival != 0 && (ival & -ival & 0xffffffff) == ival")
+	    (match_test "TARGET_32BIT && ival + 0x80000000 == 0"))))
+
+(define_constraint "kbic5"
+  "A 32-bit constant that has exactly one bit clear"
+  (and (match_code "const_int")
+       (ior (match_test "(~ival & -~ival & 0xffffffff) == ~ival")
+	    (match_test "TARGET_32BIT && ival == 0x7fffffff"))))
+
+(define_constraint "kmsk5"
+  "A 32-bit constant that is a contiguous mask of 1-32 low-order bits set"
+  (and (match_code "const_int")
+       (ior (and (match_test "((ival | 0xffffffff) ^ 0xffffffff) == 0")
+		 (match_test "((ival + 1) & -(ival + 1)) == ival + 1"))
+	    (match_test "TARGET_32BIT && ival + 1 == 0"))))
+
+(define_constraint "kuim7"
+  "A constant in the range 0-127"
+  (and (match_code "const_int")
+       (match_test "ival >= 0 && ival <= 127")))
+
+(define_constraint "kui16"
+  "An unsigned 16-bit constant."
+  (and (match_code "const_int")
+       (match_test "ival >= 0 && ival <= 65535")))
+
+
 ;; Floating-point constraints
 
 (define_constraint "G"
diff --git a/gcc/config/rs6000/e200.h b/gcc/config/rs6000/e200.h
new file mode 100644
index 0000000..5ed3975
--- /dev/null
+++ b/gcc/config/rs6000/e200.h
@@ -0,0 +1,153 @@
+/* Enable E200 support.
+   Copyright (C) 2003-2014 Free Software Foundation, Inc.
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify it
+   under the terms of the GNU General Public License as published
+   by the Free Software Foundation; either version 3, or (at your
+   option) any later version.
+
+   GCC is distributed in the hope that it will be useful, but WITHOUT
+   ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
+   or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public
+   License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with GCC; see the file COPYING3.  If not see
+   <http://www.gnu.org/licenses/>.  */
+
+#undef TARGET_SPE_ABI
+#undef TARGET_SPE
+#undef TARGET_FPRS
+#undef TARGET_E500_SINGLE
+#undef TARGET_E500_DOUBLE
+#undef CHECK_E500_OPTIONS
+
+#define TARGET_SPE_ABI rs6000_spe_abi
+#define TARGET_SPE rs6000_spe
+#define TARGET_FPRS (rs6000_float_gprs == 0)
+#define TARGET_E500_SINGLE (TARGET_HARD_FLOAT)
+#define TARGET_E500_DOUBLE 0
+
+#undef TARGET_ASM_NAMED_SECTION
+#define TARGET_ASM_NAMED_SECTION  rs6000_elf_asm_named_section
+
+#undef	TEXT_SECTION_ASM_OP
+#define	TEXT_SECTION_ASM_OP	"\t.section\t\".text\",\"axv\""
+#undef	TEXT_SECTION_ASM_OP_BOOKE
+#define	TEXT_SECTION_ASM_OP_BOOKE	"\t.section\t\".text\",\"ax\""
+
+#undef CRT_CALL_STATIC_FUNCTION
+#ifdef __VLE__
+#define CRT_CALL_STATIC_FUNCTION(SECTION_OP, FUNC)	 \
+static void __attribute__((__used__))			 \
+call_ ## FUNC (void)					 \
+{							 \
+  asm (SECTION_OP);					 \
+  FUNC ();						 \
+  FORCE_CODE_SECTION_ALIGN				 \
+  asm (TEXT_SECTION_ASM_OP);				 \
+}
+#else
+#define CRT_CALL_STATIC_FUNCTION(SECTION_OP, FUNC)	 \
+static void __attribute__((__used__))			 \
+call_ ## FUNC (void)					 \
+{							 \
+  asm (SECTION_OP);					 \
+  FUNC ();						 \
+  FORCE_CODE_SECTION_ALIGN				 \
+  asm (TEXT_SECTION_ASM_OP_BOOKE);			 \
+}
+#endif
+
+#define CHECK_E500_OPTIONS									\
+  do {														\
+    if (TARGET_SPE || TARGET_SPE_ABI || TARGET_E500_SINGLE)	\
+      {														\
+	if (TARGET_ALTIVEC)										\
+	  error ("AltiVec instructions cannot coexist");		\
+	if (TARGET_VSX)											\
+	  error ("VSX instructions cannot coexist");			\
+	if (TARGET_64BIT)										\
+	  error ("64-bit SPE not supported");					\
+	if (TARGET_HARD_FLOAT && TARGET_FPRS)					\
+	  error ("E200 and FPRs not supported");				\
+	if (TARGET_E500_DOUBLE)									\
+	  error ("E200 and double FPRs not supported");			\
+      }														\
+  } while (0)
+
+/* Override rs6000.h definition.  */
+#undef HARD_REGNO_CALLER_SAVE_MODE
+
+#undef REG_ALLOC_ORDER
+#define REG_ALLOC_ORDER						\
+  {32,								\
+   /* move fr13 (ie 45) later, so if we need TFmode, it does */ \
+   /* not use fr14 which is a saved register.	*/		\
+   44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 45,		\
+   33,								\
+   63, 62, 61, 60, 59, 58, 57, 56, 55, 54, 53, 52, 51,		\
+   50, 49, 48, 47, 46,						\
+   75, 74, 68, 69, 72, 71, 70,					\
+   MAYBE_R2_AVAILABLE						\
+   7, 6, 5, 4, 						\
+   3, 0,							\
+   31, 30, 29, 28, 27, 26, 25, 24, 23, EARLY_R12 11, 9, 10, 8,	\
+   22, 21, 20, 19,						\
+   18, 17, 16, 15, 14, 13, LATE_R12				\
+   66, 65,							\
+   73, 1, MAYBE_R2_FIXED 67, 76,				\
+   /* AltiVec registers.  */					\
+   77, 78,							\
+   90, 89, 88, 87, 86, 85, 84, 83, 82, 81, 80,			\
+   79,								\
+   96, 95, 94, 93, 92, 91,					\
+   108, 107, 106, 105, 104, 103, 102, 101, 100, 99, 98, 97,	\
+   109, 110,							\
+   111, 112, 113, 114, 115, 116,				\
+   117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128,	\
+   129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,	\
+   141, 142, 143, 144, 145, 146, 147, 148			\
+}
+
+/* When setting up caller-save slots (MODE == VOIDmode) ensure we
+   allocate space for DFmode.  Save gprs in the correct mode too.  */
+#define HARD_REGNO_CALLER_SAVE_MODE(REGNO, NREGS, MODE) \
+  (choose_hard_reg_mode ((REGNO), (NREGS), false))
+
+/* Add -meabi to target flags.  */
+#undef TARGET_DEFAULT
+#define TARGET_DEFAULT MASK_EABI
+
+/* Invoke an initializer function to set up the GOT.  */
+#define NAME__MAIN "__eabi"
+#define INVOKE__main
+
+#undef TARGET_OS_CPP_BUILTINS
+#define TARGET_OS_CPP_BUILTINS()          \
+  do                                      \
+    {                                     \
+      builtin_define_std ("PPC");         \
+      builtin_define ("__embedded__");    \
+      builtin_define ("__PPC_EABI__");    \
+      builtin_assert ("system=embedded"); \
+      builtin_assert ("cpu=powerpc");     \
+      builtin_assert ("machine=powerpc"); \
+      TARGET_OS_SYSV_CPP_BUILTINS ();     \
+    }                                     \
+  while (0)
+
+#undef SUBSUBTARGET_OVERRIDE_OPTIONS
+#define SUBSUBTARGET_OVERRIDE_OPTIONS	\
+  do					\
+    {					\
+      if (!global_options_set.x_rs6000_alignment_flags)	\
+	rs6000_alignment_flags = MASK_ALIGN_NATURAL;		\
+      target_flags &= ~(MASK_PPC_GPOPT);	\
+      if (TARGET_HARD_FLOAT)		\
+        rs6000_float_gprs=1;		\
+      if (align_functions < 4)		\
+        align_functions = 4;		\
+    }					\
+  while (0)
diff --git a/gcc/config/rs6000/eabi.h b/gcc/config/rs6000/eabi.h
index f3be1e3..664872c 100644
--- a/gcc/config/rs6000/eabi.h
+++ b/gcc/config/rs6000/eabi.h
@@ -33,6 +33,7 @@
     {                                     \
       builtin_define_std ("PPC");         \
       builtin_define ("__embedded__");    \
+      builtin_define ("__PPC_EABI__");    \
       builtin_assert ("system=embedded"); \
       builtin_assert ("cpu=powerpc");     \
       builtin_assert ("machine=powerpc"); \
diff --git a/gcc/config/rs6000/ppc-asm.h b/gcc/config/rs6000/ppc-asm.h
index c26a11a..a2e12ca 100644
--- a/gcc/config/rs6000/ppc-asm.h
+++ b/gcc/config/rs6000/ppc-asm.h
@@ -238,6 +238,41 @@ see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
 #define vs63	63
 #endif
 
+#ifdef __VLE__
+#define ADD16I	e_add16i
+#define B		e_b
+#define BDZ		e_bdz
+#define BLR		se_blr
+#define LWZ		e_lwz
+#define MFAR	se_mfar
+#define MTAR	se_mtar
+#define MFLR	se_mflr
+#define MTLR	se_mtlr
+#define MFCR	se_mfcr
+#define MTCR	se_mtcr
+#define STW		e_stw
+#define STWU	e_stwu
+#define RLWINM  e_rlwinm
+#define LI		e_li
+#define LWZU	e_lwzu
+#else
+#define ADD16I	addi
+#define B		b
+#define BDZ		bdz
+#define BLR		blr
+#define LWZ		lwz
+#define MFAR	mr
+#define MTAR	mr
+#define MFLR	mflr
+#define MTLR	mtlr
+#define MFCR	mfcr
+#define MTCR	mtcr
+#define STW		stw
+#define STWU	stwu
+#define RLWINM  rlwinm
+#define LI		li
+#endif
+
 /*
  * Macros to glue together two tokens.
  */
diff --git a/gcc/config/rs6000/ppu_intrinsics.h b/gcc/config/rs6000/ppu_intrinsics.h
index f572f29..b9a986a 100644
--- a/gcc/config/rs6000/ppu_intrinsics.h
+++ b/gcc/config/rs6000/ppu_intrinsics.h
@@ -195,6 +195,18 @@ typedef int __V4SI __attribute__((vector_size(16)));
       : [current_tb] "=r" (result):				\
       :"cr7");							\
   result; })
+#elif defined __VLE__
+#define __mftb() __extension__			\
+  ({ unsigned long long result;			\
+  unsigned long t;				\
+  __asm__ volatile ("1:\n"			\
+		    "\tmftbu %0\n"		\
+		    "\tmftb %L0\n"		\
+		    "\tmftbu %1\n"		\
+		    "\tcmpw %0,%1\n"		\
+		    "\te_bne 1b"		\
+		    : "=r" (result), "=r" (t));	\
+  result; })
 #else
 #define __mftb() __extension__			\
   ({ unsigned long long result;			\
diff --git a/gcc/config/rs6000/predicates.md b/gcc/config/rs6000/predicates.md
index 808e5b8..d0602c5 100644
--- a/gcc/config/rs6000/predicates.md
+++ b/gcc/config/rs6000/predicates.md
@@ -208,6 +208,156 @@
   return INT_REGNO_P (REGNO (op)) || FP_REGNO_P (REGNO (op));
 })
 
+ 
+;; Return 1 if op is a register in the range 0-7 or 24-31.
+;;(define_predicate "vle_reg_operand"
+;;   (and (match_operand 0 "register_operand")
+;;        (match_test "(REGNO (op) <= 7
+;;		       || (REGNO (op) >= 24 && REGNO (op) <= 31))")))
+(define_predicate "vle_reg_operand"
+   (match_operand 0 "register_operand")
+{
+  if (GET_CODE (op) == SUBREG)
+    op = SUBREG_REG (op);
+
+  if (!REG_P (op))
+    return 0;
+
+  if (REGNO (op) > LAST_VIRTUAL_REGISTER)
+    return 1;
+
+  return (REGNO (op) <= 7 || (REGNO (op) >= 24 && REGNO (op) <= 31));
+})
+
+;; Return 1 if op is a valid add operand for VLE instructions.
+(define_predicate "vle_add_operand"
+  (if_then_else (match_code "const_int")
+    (match_test "satisfies_constraint_I (op)
+		 || satisfies_constraint_L (op)
+		 || satisfies_constraint_koim5 (op)
+		 || satisfies_constraint_ksci8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid three-argument add operand for VLE instructions.
+(define_predicate "vle_add3_operand"
+  (if_then_else (match_code "const_int")
+    (match_test "satisfies_constraint_I (op)
+		 || satisfies_constraint_ksci8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a non-special register or a constant integer whose
+;; negation is a valid add operand for VLE instructions.
+(define_predicate "vle_reg_or_neg_imm_operand"
+  (if_then_else (match_code "const_int")
+    (match_test "satisfies_constraint_I (op)
+		 || satisfies_constraint_kscp8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid 1st subtract operand for VLE instructions.
+(define_predicate "vle_sub_operand1"
+  (if_then_else (match_code "const_int")
+    (match_test "satisfies_constraint_ksci8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid 2nd subtract operand for VLE instructions.
+(define_predicate "vle_sub_operand2"
+  (if_then_else (match_code "const_int")
+    (match_test "satisfies_constraint_koim5 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid and operand for VLE instructions.
+(define_predicate "vle_and_operand"
+  (if_then_else (match_code "const_int")
+		(ior (match_test "satisfies_constraint_kuim5 (op)")
+		     (match_test "satisfies_constraint_kbic5 (op)")
+		     (match_test "satisfies_constraint_ksci8 (op)")
+		     (match_test "satisfies_constraint_T (op)")
+		     (match_test "satisfies_constraint_K (op)")
+		     (match_test "satisfies_constraint_L (op)"))
+		(match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid andc operand for VLE instructions.
+(define_predicate "vle_andc_operand"
+  (if_then_else (match_code "const_int")
+		(match_test "satisfies_constraint_kbit5 (op)")
+		(match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid or operand for VLE instructions.
+(define_predicate "vle_or_operand"
+  (if_then_else (match_code "const_int")
+		(ior (match_test "satisfies_constraint_kuim5 (op)")
+		     (match_test "satisfies_constraint_kbit5 (op)")
+		     (match_test "satisfies_constraint_K (op)")
+		     (match_test "satisfies_constraint_L (op)")
+		     (match_test "satisfies_constraint_ksci8 (op)"))
+		(match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid xor operand for VLE instructions.
+(define_predicate "vle_xor_operand"
+  (if_then_else (match_code "const_int")
+		(match_test "satisfies_constraint_ksci8 (op)")
+		(match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid and-compare operand for VLE instructions.
+(define_predicate "vle_andcmp_operand"
+  (if_then_else (match_code "const_int")
+		(ior (match_test "satisfies_constraint_K (op)")
+		     (match_test "satisfies_constraint_L (op)")
+		     (match_test "satisfies_constraint_ksci8 (op)"))
+		(match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid operand for the SImode VLE arithmetic compares.
+(define_predicate "vle_arith_cmpsi_operand"
+  (if_then_else (match_code "const_int")
+       (match_test "satisfies_constraint_kuim5 (op)
+		 || satisfies_constraint_I (op)
+		 || satisfies_constraint_ksci8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid operand for the SImode VLE logical compares.
+(define_predicate "vle_logical_cmpsi_operand"
+  (if_then_else (match_code "const_int")
+       (match_test "satisfies_constraint_koim5 (op)
+		 || satisfies_constraint_K (op)
+		 || satisfies_constraint_ksci8 (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid operand for the HImode VLE arithmetic compares.
+(define_predicate "vle_arith_cmphi_operand"
+  (if_then_else (match_code "const_int")
+       (match_test "satisfies_constraint_I (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid operand for the HImode VLE logical compares.
+(define_predicate "vle_logical_cmphi_operand"
+  (if_then_else (match_code "const_int")
+       (match_test "satisfies_constraint_K (op)")
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a valid SCI8 field.
+(define_predicate "vle_sci8_operand"
+   (and (match_code "const_int")
+        (match_test "satisfies_constraint_ksci8 (op)")))
+
+;; Return 1 if op is a valid D8 field.
+(define_predicate "vle_d8_operand"
+   (and (match_code "const_int")
+        (match_test "satisfies_constraint_kmmd8 (op)")))
+
+;; Return 1 if the operand is a memory operand with an address divisible
+;; by 4 and not requesting an address update.
+(define_predicate "vle_sd4_operand"
+   (and (match_operand 0 "memory_operand")
+        (match_test "valid_vle_sd4_field (op, GET_MODE (op))")))
+
+;; Return 1 if the operand is a condition register field
+;; that is valid in VLE instructions.
+(define_predicate "vle_cc_reg_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || VLE_CR_REGNO_P (REGNO (op))")))
+
 ;; Return 1 if op is a general purpose register.  Unlike gpc_reg_operand, don't
 ;; allow floating point or vector registers.
 (define_predicate "int_reg_operand"
@@ -322,6 +472,31 @@
   return CR_REGNO_NOT_CR0_P (REGNO (op));
 })
 
+;; Return 1 if op is a register that is a condition register field
+;; suitable for the cmpi/cmpli/bc instructions in the current mode.
+(define_predicate "cmpi_cc_reg_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || (TARGET_VLE ? VLE_CR_REGNO_P (REGNO (op))
+			 : CR_REGNO_P (REGNO (op)))")))
+
+;; Return 1 if op is a register that is a condition register field not cr0
+;; suitable for the cmpi/cmpli/bc instructions in the current mode.
+(define_predicate "cmpi_cc_reg_not_cr0_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || (TARGET_VLE ? VLE_CR_REGNO_NOT_CR0_P (REGNO (op))
+			 : CR_REGNO_NOT_CR0_P (REGNO (op)))")))
+
+;; Return 1 if op is a register that is condition register field cr0.
+(define_predicate "cc_reg_cr0_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || CR0_REGNO_P (REGNO (op))")))
+
 ;; Return 1 if op is a register that is a condition register field and if generating microcode, not cr0.
 (define_predicate "cc_reg_not_micro_cr0_operand"
   (match_operand 0 "register_operand")
@@ -341,6 +516,31 @@
     return CR_REGNO_P (REGNO (op));
 })
 
+;; Return 1 if op is a register that is a condition register field
+;; suitable for the cmpi/cmpli/bc instructions in the current mode
+;; and if generating microcode, not cr0.
+(define_predicate "cmpi_cc_reg_not_micro_cr0_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || (rs6000_gen_cell_microcode
+			 ? (TARGET_VLE ? VLE_CR_REGNO_NOT_CR0_P (REGNO (op))
+			    : CR_REGNO_NOT_CR0_P (REGNO (op)))
+			 : (TARGET_VLE ? VLE_CR_REGNO_P (REGNO (op))
+			    : CR_REGNO_P (REGNO (op))))")))
+
+;; Return 1 if op is a register that is a condition register field
+;; suitable for the cmpi/cmpli/bc instructions in the current mode
+;; and if non-VLE and generating microcode, not cr0.
+(define_predicate "cmpi_cc_reg_vle_or_not_micro_cr0_operand"
+   (and (match_operand 0 "register_operand")
+	(match_test "GET_CODE (op) != REG
+		     || REGNO (op) > LAST_VIRTUAL_REGISTER
+		     || (TARGET_VLE ? VLE_CR_REGNO_P (REGNO (op))
+			 : (rs6000_gen_cell_microcode
+			    ? CR_REGNO_NOT_CR0_P (REGNO (op))
+			    : CR_REGNO_P (REGNO (op))))")))
+
 ;; Return 1 if op is a constant integer valid for D field
 ;; or non-special register register.
 (define_predicate "reg_or_short_operand"
@@ -348,6 +548,24 @@
     (match_operand 0 "short_cint_operand")
     (match_operand 0 "gpc_reg_operand")))
 
+;; Return 1 if op is a constant integer valid for D field
+;; or non-special register register.
+(define_predicate "reg_or_short_operand_vle_sci8"
+  (if_then_else (match_code "const_int")
+  	(if_then_else (match_test "TARGET_VLE")
+        (match_test "satisfies_constraint_ksci8 (op)")
+    	(match_operand 0 "short_cint_operand"))
+    (match_operand 0 "gpc_reg_operand")))
+
+;; Return 1 if op is a constant integer whose negation is valid for
+;; D or D8 field, as applicable to the selected instruction set for the
+;; load/store-with-update instruction, or a non-special register.
+(define_predicate "reg_or_neg_d_d8_operand"
+  (if_then_else (match_code "const_int")
+    (match_test "(!TARGET_VLE && INTVAL (op) >= -32767 && INTVAL (op) <= 32768)
+		 || (INTVAL (op) >= -127 && INTVAL (op) <= 128)")
+    (match_operand 0 "gpc_reg_operand")))
+
 ;; Return 1 if op is a constant integer valid whose negation is valid for
 ;; D field or non-special register register.
 ;; Do not allow a constant zero because all patterns that call this
@@ -603,6 +821,11 @@
   (and (match_code "const_int,const_double,const_vector")
        (match_test "op == CONST0_RTX (mode)")))
 
+;; Return 1 if operand is constant one.
+(define_predicate "one_constant"
+  (and (match_code "const_int")
+       (match_test "op == CONST1_RTX (mode)")))
+
 ;; Return 1 if operand is 0.0.
 (define_predicate "zero_fp_constant"
   (and (match_code "const_double")
@@ -767,11 +990,13 @@
 		 || satisfies_constraint_L (op)")
     (match_operand 0 "gpc_reg_operand")))
 
-;; Return 1 if OP is a constant but not a valid add_operand.
+;; Return 1 if OP is a constant but not a valid add_operand/vle_add_operand..
 (define_predicate "non_add_cint_operand"
   (and (match_code "const_int")
-       (match_test "!satisfies_constraint_I (op)
-		    && !satisfies_constraint_L (op)")))
+       (if_then_else (match_test "TARGET_VLE")
+		    (match_test "!vle_add_operand (op, mode)") 
+			(match_test "!satisfies_constraint_I (op)
+		     && !satisfies_constraint_L (op)"))))
 
 ;; Return 1 if the operand is a constant that can be used as the operand
 ;; of an OR or XOR.
@@ -1179,8 +1404,7 @@
    (and (match_operand 0 "comparison_operator")
 	(and (match_test "GET_MODE_CLASS (GET_MODE (XEXP (op, 0))) == MODE_CC")
 	     (match_test "validate_condition_mode (GET_CODE (op),
-						   GET_MODE (XEXP (op, 0))),
-			  1"))))
+						   GET_MODE (XEXP (op, 0)))"))))
 
 ;; Return 1 if OP is a valid comparison operator for "cbranch" instructions.
 ;; If we're assuming that FP operations cannot generate user-visible traps,
@@ -1604,7 +1828,7 @@
       if (base_regno == 0)
 	return 0;
     }
-  else if (rs6000_legitimate_offset_address_p (SImode, src_addr, false, false))
+  else if (rs6000_legitimate_offset_address_p (SImode, src_addr, false, false, false))
     {
       offset = INTVAL (XEXP (src_addr, 1));
       base_regno = REGNO (XEXP (src_addr, 0));
@@ -1632,7 +1856,7 @@
 	  newoffset = 0;
 	  addr_reg = newaddr;
 	}
-      else if (rs6000_legitimate_offset_address_p (SImode, newaddr, false, false))
+      else if (rs6000_legitimate_offset_address_p (SImode, newaddr, false, false, false))
 	{
 	  addr_reg = XEXP (newaddr, 0);
 	  newoffset = INTVAL (XEXP (newaddr, 1));
@@ -1679,7 +1903,7 @@
       if (base_regno == 0)
 	return 0;
     }
-  else if (rs6000_legitimate_offset_address_p (SImode, dest_addr, false, false))
+  else if (rs6000_legitimate_offset_address_p (SImode, dest_addr, false, false, false))
     {
       offset = INTVAL (XEXP (dest_addr, 1));
       base_regno = REGNO (XEXP (dest_addr, 0));
@@ -1707,7 +1931,7 @@
 	  newoffset = 0;
 	  addr_reg = newaddr;
 	}
-      else if (rs6000_legitimate_offset_address_p (SImode, newaddr, false, false))
+      else if (rs6000_legitimate_offset_address_p (SImode, newaddr, false, false, false))
 	{
 	  addr_reg = XEXP (newaddr, 0);
 	  newoffset = INTVAL (XEXP (newaddr, 1));
diff --git a/gcc/config/rs6000/rs6000-c.c b/gcc/config/rs6000/rs6000-c.c
index 684173b..ec195ba 100644
--- a/gcc/config/rs6000/rs6000-c.c
+++ b/gcc/config/rs6000/rs6000-c.c
@@ -354,6 +354,8 @@ rs6000_target_modify_macros (bool define_p, HOST_WIDE_INT flags,
     rs6000_define_or_undefine_macro (define_p, "__ALTIVEC2__");
   if ((flags & OPTION_MASK_VSX) != 0)
     rs6000_define_or_undefine_macro (define_p, "__VSX__");
+  if ((flags & OPTION_MASK_VLE) != 0)
+    rs6000_define_or_undefine_macro (define_p, "__VLE__");
   if ((flags & OPTION_MASK_HTM) != 0)
     {
       rs6000_define_or_undefine_macro (define_p, "__HTM__");
@@ -423,6 +425,23 @@ rs6000_cpu_cpp_builtins (cpp_reader *pfile)
   if (TARGET_NO_LWSYNC)
     builtin_define ("__NO_LWSYNC__");
 
+  if (TARGET_VLE)
+    {
+      builtin_define ("__PPCVLE__");
+    }
+  if (rs6000_cpu == PROCESSOR_PPCE200Z0)
+    builtin_define ("__PPCE200Z0__");
+  if (rs6000_cpu == PROCESSOR_PPCE200Z2)
+    builtin_define ("__PPCE200Z2__");
+  if (rs6000_cpu == PROCESSOR_PPCE200Z3)
+    builtin_define ("__PPCE200Z3__");
+  if (rs6000_cpu == PROCESSOR_PPCE200Z4)
+    builtin_define ("__PPCE200Z4__");
+  if (rs6000_cpu == PROCESSOR_PPCE200Z6)
+    builtin_define ("__PPCE200Z6__");
+  if (rs6000_cpu == PROCESSOR_PPCE200Z7)
+    builtin_define ("__PPCE200Z7__");
+
   if (TARGET_EXTRA_BUILTINS)
     {
       /* For the VSX builtin functions identical to Altivec functions, just map
diff --git a/gcc/config/rs6000/rs6000-cpus.def b/gcc/config/rs6000/rs6000-cpus.def
index 0f4570c..a46030a 100644
--- a/gcc/config/rs6000/rs6000-cpus.def
+++ b/gcc/config/rs6000/rs6000-cpus.def
@@ -59,6 +59,8 @@
 
 #define POWERPC_7400_MASK	(OPTION_MASK_PPC_GFXOPT | OPTION_MASK_ALTIVEC)
 
+#define POWERPC_E200_MASK	(OPTION_MASK_ISEL | OPTION_MASK_VLE)
+
 /* Deal with ports that do not have -mstrict-align.  */
 #ifdef OPTION_MASK_STRICT_ALIGN
 #define OPTION_MASK_STRICT_ALIGN_OPTIONAL OPTION_MASK_STRICT_ALIGN
@@ -98,6 +100,7 @@
 				 | OPTION_MASK_SOFT_FLOAT		\
 				 | OPTION_MASK_STRICT_ALIGN_OPTIONAL	\
 				 | OPTION_MASK_VSX			\
+				 | OPTION_MASK_VLE			\
 				 | OPTION_MASK_ALTIVEC2			\
 				 | OPTION_MASK_VSX_TIMODE)
 
@@ -152,6 +155,12 @@ RS6000_CPU ("8548", PROCESSOR_PPC8548, MASK_STRICT_ALIGN | MASK_ISEL)
 RS6000_CPU ("a2", PROCESSOR_PPCA2,
 	    MASK_PPC_GFXOPT | MASK_POWERPC64 | MASK_POPCNTB | MASK_CMPB
 	    | MASK_NO_UPDATE)
+RS6000_CPU ("e200z0", PROCESSOR_PPCE200Z0, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
+RS6000_CPU ("e200z2", PROCESSOR_PPCE200Z2, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
+RS6000_CPU ("e200z3", PROCESSOR_PPCE200Z3, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
+RS6000_CPU ("e200z4", PROCESSOR_PPCE200Z4, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
+RS6000_CPU ("e200z6", PROCESSOR_PPCE200Z6, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
+RS6000_CPU ("e200z7", PROCESSOR_PPCE200Z7, POWERPC_E200_MASK | MASK_SOFT_FLOAT )
 RS6000_CPU ("e300c2", PROCESSOR_PPCE300C2, MASK_SOFT_FLOAT)
 RS6000_CPU ("e300c3", PROCESSOR_PPCE300C3, 0)
 RS6000_CPU ("e500mc", PROCESSOR_PPCE500MC, MASK_PPC_GFXOPT | MASK_ISEL)
diff --git a/gcc/config/rs6000/rs6000-opts.h b/gcc/config/rs6000/rs6000-opts.h
index 72151d8..a24f489 100644
--- a/gcc/config/rs6000/rs6000-opts.h
+++ b/gcc/config/rs6000/rs6000-opts.h
@@ -65,7 +65,14 @@ enum processor_type
    PROCESSOR_MPCCORE,
    PROCESSOR_CELL,
    PROCESSOR_PPCA2,
-   PROCESSOR_TITAN
+   PROCESSOR_TITAN,
+
+   PROCESSOR_PPCE200Z0,
+   PROCESSOR_PPCE200Z2,
+   PROCESSOR_PPCE200Z3,
+   PROCESSOR_PPCE200Z4,
+   PROCESSOR_PPCE200Z6,
+   PROCESSOR_PPCE200Z7
 };
 
 
diff --git a/gcc/config/rs6000/rs6000-protos.h b/gcc/config/rs6000/rs6000-protos.h
index 339627b..3192b8d 100644
--- a/gcc/config/rs6000/rs6000-protos.h
+++ b/gcc/config/rs6000/rs6000-protos.h
@@ -39,12 +39,14 @@ extern int small_data_operand (rtx, enum machine_mode);
 extern bool mem_operand_gpr (rtx, enum machine_mode);
 extern bool toc_relative_expr_p (const_rtx, bool);
 extern bool invalid_e500_subreg (rtx, enum machine_mode);
-extern void validate_condition_mode (enum rtx_code, enum machine_mode);
+extern bool validate_condition_mode (enum rtx_code, enum machine_mode);
 extern bool legitimate_constant_pool_address_p (const_rtx, enum machine_mode,
 						bool);
 extern bool legitimate_indirect_address_p (rtx, int);
 extern bool legitimate_indexed_address_p (rtx, int);
 extern bool avoiding_indexed_address_p (enum machine_mode);
+extern bool valid_vle_sd4_field (rtx, enum machine_mode);
+extern bool valid_sci8_immediate (HOST_WIDE_INT);
 
 extern rtx rs6000_got_register (rtx);
 extern rtx find_addr_reg (rtx);
@@ -137,7 +139,7 @@ extern enum machine_mode rs6000_secondary_memory_needed_mode (enum
 extern rtx (*rs6000_legitimize_reload_address_ptr) (rtx, enum machine_mode,
 						    int, int, int, int *);
 extern bool rs6000_legitimate_offset_address_p (enum machine_mode, rtx,
-						bool, bool);
+						bool, bool, bool);
 extern rtx rs6000_find_base_term (rtx);
 extern rtx rs6000_return_addr (int, rtx);
 extern void rs6000_output_symbol_ref (FILE*, rtx);
diff --git a/gcc/config/rs6000/rs6000-tables.opt b/gcc/config/rs6000/rs6000-tables.opt
index 41e7e14..91a8d26 100644
--- a/gcc/config/rs6000/rs6000-tables.opt
+++ b/gcc/config/rs6000/rs6000-tables.opt
@@ -114,80 +114,98 @@ EnumValue
 Enum(rs6000_cpu_opt_value) String(a2) Value(28)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e300c2) Value(29)
+Enum(rs6000_cpu_opt_value) String(e200z0) Value(29)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e300c3) Value(30)
+Enum(rs6000_cpu_opt_value) String(e200z2) Value(30)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e500mc) Value(31)
+Enum(rs6000_cpu_opt_value) String(e200z3) Value(31)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e500mc64) Value(32)
+Enum(rs6000_cpu_opt_value) String(e200z4) Value(32)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e5500) Value(33)
+Enum(rs6000_cpu_opt_value) String(e200z6) Value(33)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(e6500) Value(34)
+Enum(rs6000_cpu_opt_value) String(e200z7) Value(34)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(860) Value(35)
+Enum(rs6000_cpu_opt_value) String(e300c2) Value(35)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(970) Value(36)
+Enum(rs6000_cpu_opt_value) String(e300c3) Value(36)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(cell) Value(37)
+Enum(rs6000_cpu_opt_value) String(e500mc) Value(37)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(ec603e) Value(38)
+Enum(rs6000_cpu_opt_value) String(e500mc64) Value(38)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(G3) Value(39)
+Enum(rs6000_cpu_opt_value) String(e5500) Value(39)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(G4) Value(40)
+Enum(rs6000_cpu_opt_value) String(e6500) Value(40)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(G5) Value(41)
+Enum(rs6000_cpu_opt_value) String(860) Value(41)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(titan) Value(42)
+Enum(rs6000_cpu_opt_value) String(970) Value(42)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power3) Value(43)
+Enum(rs6000_cpu_opt_value) String(cell) Value(43)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power4) Value(44)
+Enum(rs6000_cpu_opt_value) String(ec603e) Value(44)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power5) Value(45)
+Enum(rs6000_cpu_opt_value) String(G3) Value(45)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power5+) Value(46)
+Enum(rs6000_cpu_opt_value) String(G4) Value(46)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power6) Value(47)
+Enum(rs6000_cpu_opt_value) String(G5) Value(47)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power6x) Value(48)
+Enum(rs6000_cpu_opt_value) String(titan) Value(48)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power7) Value(49)
+Enum(rs6000_cpu_opt_value) String(power3) Value(49)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(power8) Value(50)
+Enum(rs6000_cpu_opt_value) String(power4) Value(50)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(powerpc) Value(51)
+Enum(rs6000_cpu_opt_value) String(power5) Value(51)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(powerpc64) Value(52)
+Enum(rs6000_cpu_opt_value) String(power5+) Value(52)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(powerpc64le) Value(53)
+Enum(rs6000_cpu_opt_value) String(power6) Value(53)
 
 EnumValue
-Enum(rs6000_cpu_opt_value) String(rs64) Value(54)
+Enum(rs6000_cpu_opt_value) String(power6x) Value(54)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(power7) Value(55)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(power8) Value(56)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(powerpc) Value(57)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(powerpc64) Value(58)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(powerpc64le) Value(59)
+
+EnumValue
+Enum(rs6000_cpu_opt_value) String(rs64) Value(60)
 
diff --git a/gcc/config/rs6000/rs6000.c b/gcc/config/rs6000/rs6000.c
index 3ce9883..c217364 100644
--- a/gcc/config/rs6000/rs6000.c
+++ b/gcc/config/rs6000/rs6000.c
@@ -290,6 +290,9 @@ enum rs6000_recip_mask {
   RECIP_LOW_PRECISION	= (RECIP_ALL & ~(RECIP_DF_RSQRT | RECIP_V2DF_RSQRT))
 };
 
+/* VLE codegen */
+int vle_code;
+
 /* -mrecip options.  */
 static struct
 {
@@ -781,6 +784,25 @@ struct processor_costs ppc8540_cost = {
   1,			/* prefetch streams /*/
 };
 
+/* Instruction costs on PPCE200 processors.  */
+static const
+struct processor_costs ppce200_cost = {
+  COSTS_N_INSNS (4),    /* mulsi */
+  COSTS_N_INSNS (4),    /* mulsi_const */
+  COSTS_N_INSNS (4),    /* mulsi_const9 */
+  COSTS_N_INSNS (4),    /* muldi */
+  COSTS_N_INSNS (14),   /* divsi */
+  COSTS_N_INSNS (14),   /* divdi */
+  COSTS_N_INSNS (8),    /* fp */
+  COSTS_N_INSNS (10),   /* dmul */
+  COSTS_N_INSNS (36),   /* sdiv */
+  COSTS_N_INSNS (66),   /* ddiv */
+  64,			/* cache line size */
+  32,			/* l1 cache */
+  128,			/* l2 cache */
+  1,			/* prefetch streams /*/
+};
+
 /* Instruction costs on E300C2 and E300C3 cores.  */
 static const
 struct processor_costs ppce300c2c3_cost = {
@@ -2469,8 +2491,22 @@ rs6000_init_hard_regno_mode_ok (bool global_init_p)
 
   /* Precalculate REGNO_REG_CLASS.  */
   rs6000_regno_regclass[0] = GENERAL_REGS;
-  for (r = 1; r < 32; ++r)
-    rs6000_regno_regclass[r] = BASE_REGS;
+  if (TARGET_VLE)
+    {
+      for (r = 1; r < 8; ++r)
+        rs6000_regno_regclass[r] = BASE_REGS;
+
+      for (r = 8; r < 24; ++r)
+        rs6000_regno_regclass[r] = VLE_ALT_REGS;
+
+      for (r = 24; r < 32; ++r)
+        rs6000_regno_regclass[r] = BASE_REGS;
+    }
+  else
+    {
+      for (r = 1; r < 32; ++r)
+        rs6000_regno_regclass[r] = BASE_REGS;
+    }
 
   for (r = 32; r < 64; ++r)
     rs6000_regno_regclass[r] = FLOAT_REGS;
@@ -2482,8 +2519,19 @@ rs6000_init_hard_regno_mode_ok (bool global_init_p)
     rs6000_regno_regclass[r] = ALTIVEC_REGS;
 
   rs6000_regno_regclass[CR0_REGNO] = CR0_REGS;
-  for (r = CR1_REGNO; r <= CR7_REGNO; ++r)
-    rs6000_regno_regclass[r] = CR_REGS;
+  if (TARGET_VLE)
+  {
+     for (r = CR1_REGNO; r <= CR3_REGNO; ++r)
+       rs6000_regno_regclass[r] = VLE_CR_REGS;
+
+     for (r = CR4_REGNO; r <= CR7_REGNO; ++r)
+       rs6000_regno_regclass[r] = CR_REGS;
+  }
+   else
+  {
+    for (r = CR1_REGNO; r <= CR7_REGNO; ++r)
+      rs6000_regno_regclass[r] = CR_REGS;
+  }
 
   rs6000_regno_regclass[LR_REGNO] = LINK_REGS;
   rs6000_regno_regclass[CTR_REGNO] = CTR_REGS;
@@ -2738,6 +2786,11 @@ rs6000_init_hard_regno_mode_ok (bool global_init_p)
   if (TARGET_LFIWZX)
     rs6000_constraints[RS6000_CONSTRAINT_wz] = FLOAT_REGS;	/* DImode  */
 
+  if (TARGET_VLE)
+    rs6000_constraints[RS6000_CONSTRAINT_kcrxx] = VLE_CR_REGS;
+  else
+    rs6000_constraints[RS6000_CONSTRAINT_kcrxx] = CR_REGS;
+
   /* Set up the reload helper and direct move functions.  */
   if (TARGET_VSX || TARGET_ALTIVEC)
     {
@@ -3308,6 +3361,23 @@ rs6000_option_override_internal (bool global_init_p)
 	error ("SPE not supported in this target");
     }
 
+  /* VLE special processing.  */
+  if (TARGET_VLE)
+    {
+      if (!BYTES_BIG_ENDIAN)
+	    error ("-mvle cannot be used with -mlittle-endian");
+      vle_code = 1;
+      rs6000_isa_flags &= ~OPTION_MASK_PPC_GPOPT;
+      if (TARGET_ALTIVEC)
+    	  error ("AltiVec not supported in this target");
+      if (TARGET_POWERPC64)
+    	  error ("Power 64 not supported in this target");
+      
+      if (flag_stack_protect != 0)
+    	  error ("-fstack-protector is not supported for VLE mode");
+	      
+    }
+
   /* Disable Cell microcode if we are optimizing for the Cell
      and not optimizing for size.  */
   if (rs6000_gen_cell_microcode == -1)
@@ -3738,10 +3808,26 @@ rs6000_option_override_internal (bool global_init_p)
 
       break;
 
+    case PROCESSOR_PPCE200Z0:
+    case PROCESSOR_PPCE200Z2:
+    case PROCESSOR_PPCE200Z3:
+    case PROCESSOR_PPCE200Z4:
+    case PROCESSOR_PPCE200Z6:
+    case PROCESSOR_PPCE200Z7:
+      {
+      /* All e200 processors do not have string instructions */
+      rs6000_isa_flags &= ~OPTION_MASK_STRING;
+      
+      /* This target defaults to strict volatile bitfields. BAD: This causes failures on dejagnu */
+      //if (flag_strict_volatile_bitfields < 0)
+      //  flag_strict_volatile_bitfields = 1;
+      break;
+      }
+
     default:
 
       if (have_cpu && !(rs6000_isa_flags_explicit & OPTION_MASK_ISEL))
-	rs6000_isa_flags &= ~OPTION_MASK_ISEL;
+        rs6000_isa_flags &= ~OPTION_MASK_ISEL;
 
       break;
     }
@@ -4027,7 +4113,16 @@ rs6000_option_override_internal (bool global_init_p)
 	rs6000_cost = &ppca2_cost;
 	break;
 
-      default:
+      case PROCESSOR_PPCE200Z0:
+      case PROCESSOR_PPCE200Z2:
+      case PROCESSOR_PPCE200Z3:
+      case PROCESSOR_PPCE200Z4:
+      case PROCESSOR_PPCE200Z6:
+      case PROCESSOR_PPCE200Z7:
+	rs6000_cost = &ppce200_cost;
+	break;
+
+	default:
 	gcc_unreachable ();
       }
 
@@ -5450,9 +5545,9 @@ output_vec_const_move (rtx *operands)
   operands[1] = CONST_VECTOR_ELT (vec, 0);
   operands[2] = CONST_VECTOR_ELT (vec, 1);
   if (cst == cst2)
-    return "li %0,%1\n\tevmergelo %0,%0,%0";
+    return "%^li %0,%1\n\tevmergelo %0,%0,%0";
   else
-    return "li %0,%1\n\tevmergelo %0,%0,%0\n\tli %0,%2";
+    return "%^li %0,%1\n\tevmergelo %0,%0,%0\n\t%^li %0,%2";
 }
 
 /* Initialize TARGET of vector PAIRED to VALS.  */
@@ -6560,7 +6655,7 @@ legitimate_small_data_p (enum machine_mode mode, rtx x)
 
 bool
 rs6000_legitimate_offset_address_p (enum machine_mode mode, rtx x,
-				    bool strict, bool worst_case)
+				    bool strict, bool worst_case, bool vle_update)
 {
   unsigned HOST_WIDE_INT offset;
   unsigned int extra;
@@ -6635,8 +6730,16 @@ rs6000_legitimate_offset_address_p (enum machine_mode mode, rtx x,
       break;
     }
 
-  offset += 0x8000;
-  return offset < 0x10000 - extra;
+  if (vle_update)
+  {
+	  offset += 0x80;
+	  return offset < 0x100 - extra;
+  }
+  else
+  {
+      offset += 0x8000;
+      return offset < 0x10000 - extra;
+  }
 }
 
 bool
@@ -7054,7 +7157,13 @@ rs6000_delegitimize_address (rtx orig_x)
 
 /* Return true if X shouldn't be emitted into the debug info.
    The linker doesn't like .toc section references from
-   .debug_* sections, so reject .toc section symbols.  */
+   .debug_* sections, so reject .toc section symbols.
+
+   Also as a temporary fix for PR60655 we reject certain MINUS
+   expressions.  Ideally we need to handle most of these cases in
+   the generic part but currently we reject minus (..) (sym_ref).
+   We try to ameliorate the case with minus (sym_ref1) (sym_ref2)
+   where they are in the same section.  */
 
 static bool
 rs6000_const_not_ok_for_debug_p (rtx x)
@@ -7068,6 +7177,34 @@ rs6000_const_not_ok_for_debug_p (rtx x)
 	return true;
     }
 
+  if (GET_CODE (x) == MINUS)
+    {
+      tree decl_op0 = NULL;
+      tree decl_op1 = NULL;
+
+      if (GET_CODE (XEXP (x, 1)) == SYMBOL_REF)
+       {
+	 decl_op1 = SYMBOL_REF_DECL (XEXP (x, 1));
+	 if (decl_op1
+	     && GET_CODE (XEXP (x, 0)) == SYMBOL_REF
+	     && (decl_op0 = SYMBOL_REF_DECL (XEXP (x, 0))))
+	   {
+	     if ((TREE_CODE (decl_op1) == VAR_DECL
+		  || TREE_CODE (decl_op1) == CONST_DECL)
+		 && (TREE_CODE (decl_op0) == VAR_DECL
+		     || TREE_CODE (decl_op0) == CONST_DECL))
+	       return (get_variable_section (decl_op1, false)
+		       != get_variable_section (decl_op0, false));
+
+	     if (TREE_CODE (decl_op1) == LABEL_DECL
+		 && TREE_CODE (decl_op0) == LABEL_DECL)
+	       return (DECL_CONTEXT (decl_op1)
+		       != DECL_CONTEXT (decl_op0));
+	   }
+
+	 return true;
+       }
+    }
   return false;
 }
 
@@ -7735,7 +7872,7 @@ rs6000_legitimate_address_p (enum machine_mode mode, rtx x, bool reg_ok_strict)
 	  || XEXP (x, 0) == arg_pointer_rtx)
       && GET_CODE (XEXP (x, 1)) == CONST_INT)
     return 1;
-  if (rs6000_legitimate_offset_address_p (mode, x, reg_ok_strict, false))
+  if (rs6000_legitimate_offset_address_p (mode, x, reg_ok_strict, false, false))
     return 1;
   if (mode != TFmode
       && mode != TDmode
@@ -7753,7 +7890,7 @@ rs6000_legitimate_address_p (enum machine_mode mode, rtx x, bool reg_ok_strict)
       && mode_supports_pre_modify_p (mode)
       && legitimate_indirect_address_p (XEXP (x, 0), reg_ok_strict)
       && (rs6000_legitimate_offset_address_p (mode, XEXP (x, 1),
-					      reg_ok_strict, false)
+					      reg_ok_strict, false, TARGET_VLE)
 	  || (!avoiding_indexed_address_p (mode)
 	      && legitimate_indexed_address_p (XEXP (x, 1), reg_ok_strict)))
       && rtx_equal_p (XEXP (XEXP (x, 1), 0), XEXP (x, 0)))
@@ -7914,7 +8051,7 @@ rs6000_offsettable_memref_p (rtx op, enum machine_mode reg_mode)
   worst_case = ((TARGET_POWERPC64 && GET_MODE_CLASS (reg_mode) == MODE_INT)
 		|| GET_MODE_SIZE (reg_mode) == 4);
   return rs6000_legitimate_offset_address_p (GET_MODE (op), XEXP (op, 0),
-					     true, worst_case);
+					     true, worst_case, false);
 }
 
 /* Change register usage conditional on target flags.  */
@@ -13679,6 +13816,22 @@ spe_expand_builtin (tree exp, rtx target, bool *expandedp)
 }
 
 static rtx
+lsp_expand_builtin (tree exp ATTRIBUTE_UNUSED, rtx target ATTRIBUTE_UNUSED, bool *expandedp)
+{
+  //tree fndecl = TREE_OPERAND (CALL_EXPR_FN (exp), 0);
+  //tree arg1, arg0;
+  //enum rs6000_builtins fcode = (enum rs6000_builtins) DECL_FUNCTION_CODE (fndecl);
+  //enum insn_code icode;
+  //enum machine_mode tmode, mode0;
+  //rtx pat, op0;
+  //const struct builtin_description *d;
+  //size_t i;
+
+  *expandedp = true;
+  return NULL_RTX;
+}
+
+static rtx
 paired_expand_predicate_builtin (enum insn_code icode, tree exp, rtx target)
 {
   rtx pat, scratch, tmp;
@@ -13931,6 +14084,8 @@ rs6000_invalid_builtin (enum rs6000_builtins fncode)
     error ("Builtin function %s requires the -mpaired option", name);
   else if ((fnmask & RS6000_BTM_SPE) != 0)
     error ("Builtin function %s requires the -mspe option", name);
+  else if ((fnmask & RS6000_BTM_LSP) != 0)
+    error ("Builtin function %s requires the -mlsp option", name);
   else if ((fnmask & (RS6000_BTM_DFP | RS6000_BTM_P8_VECTOR))
 	   == (RS6000_BTM_DFP | RS6000_BTM_P8_VECTOR))
     error ("Builtin function %s requires the -mhard-dfp and"
@@ -14420,6 +14575,13 @@ rs6000_expand_builtin (tree exp, rtx target, rtx subtarget ATTRIBUTE_UNUSED,
       if (success)
 	return ret;
     }
+  if (TARGET_LSP)
+    {
+//      ret = lsp_expand_builtin (exp, target, &success);
+
+      if (success)
+	return ret;
+    }
   if (TARGET_PAIRED_FLOAT)
     {
       ret = paired_expand_builtin (exp, target, &success);
@@ -14469,9 +14631,10 @@ rs6000_init_builtins (void)
   enum machine_mode mode;
 
   if (TARGET_DEBUG_BUILTIN)
-    fprintf (stderr, "rs6000_init_builtins%s%s%s%s\n",
+    fprintf (stderr, "rs6000_init_builtins%s%s%s%s%s\n",
 	     (TARGET_PAIRED_FLOAT) ? ", paired"	 : "",
 	     (TARGET_SPE)	   ? ", spe"	 : "",
+	     (TARGET_LSP)	   ? ", lsp"	 : "",
 	     (TARGET_ALTIVEC)	   ? ", altivec" : "",
 	     (TARGET_VSX)	   ? ", vsx"	 : "");
 
@@ -14673,7 +14836,7 @@ rs6000_init_builtins (void)
   if (TARGET_HTM)
     htm_init_builtins ();
 
-  if (TARGET_EXTRA_BUILTINS || TARGET_SPE || TARGET_PAIRED_FLOAT)
+  if (TARGET_EXTRA_BUILTINS || TARGET_LSP || TARGET_SPE || TARGET_PAIRED_FLOAT)
     rs6000_common_init_builtins ();
 
   ftype = builtin_function_type (DFmode, DFmode, DFmode, VOIDmode,
@@ -16534,7 +16697,7 @@ rs6000_output_load_multiple (rtx operands[3])
   rtx xop[10];
 
   if (XVECLEN (operands[0], 0) == 1)
-    return "lwz %2,0(%1)";
+    return "%^lwz %2,0(%1)";
 
   for (i = 0; i < words; i++)
     if (refers_to_regno_p (REGNO (operands[2]) + i,
@@ -16545,7 +16708,7 @@ rs6000_output_load_multiple (rtx operands[3])
 	    xop[0] = GEN_INT (4 * (words-1));
 	    xop[1] = operands[1];
 	    xop[2] = operands[2];
-	    output_asm_insn ("lswi %2,%1,%0\n\tlwz %1,%0(%1)", xop);
+	    output_asm_insn ("lswi %2,%1,%0\n\t%^lwz %1,%0(%1)", xop);
 	    return "";
 	  }
 	else if (i == 0)
@@ -16553,7 +16716,7 @@ rs6000_output_load_multiple (rtx operands[3])
 	    xop[0] = GEN_INT (4 * (words-1));
 	    xop[1] = operands[1];
 	    xop[2] = gen_rtx_REG (SImode, REGNO (operands[2]) + 1);
-	    output_asm_insn ("addi %1,%1,4\n\tlswi %2,%1,%0\n\tlwz %1,-4(%1)", xop);
+	    output_asm_insn ("%^addi %1,%1,4\n\tlswi %2,%1,%0\n\t%^lwz %1,-4(%1)", xop);
 	    return "";
 	  }
 	else
@@ -16564,11 +16727,11 @@ rs6000_output_load_multiple (rtx operands[3])
 		  xop[0] = GEN_INT (j * 4);
 		  xop[1] = operands[1];
 		  xop[2] = gen_rtx_REG (SImode, REGNO (operands[2]) + j);
-		  output_asm_insn ("lwz %2,%0(%1)", xop);
+		  output_asm_insn ("%^lwz %2,%0(%1)", xop);
 		}
 	    xop[0] = GEN_INT (i * 4);
 	    xop[1] = operands[1];
-	    output_asm_insn ("lwz %1,%0(%1)", xop);
+	    output_asm_insn ("%^lwz %1,%0(%1)", xop);
 	    return "";
 	  }
       }
@@ -16581,7 +16744,7 @@ rs6000_output_load_multiple (rtx operands[3])
    match.  The other alternatives either don't make sense or should
    never be generated.  */
 
-void
+bool
 validate_condition_mode (enum rtx_code code, enum machine_mode mode)
 {
   gcc_assert ((GET_RTX_CLASS (code) == RTX_COMPARE
@@ -16589,28 +16752,36 @@ validate_condition_mode (enum rtx_code code, enum machine_mode mode)
 	      && GET_MODE_CLASS (mode) == MODE_CC);
 
   /* These don't make sense.  */
-  gcc_assert ((code != GT && code != LT && code != GE && code != LE)
-	      || mode != CCUNSmode);
+  if (mode == CCUNSmode
+      && (code == GT || code == LT || code == GE || code == LE))
+    return false;
 
-  gcc_assert ((code != GTU && code != LTU && code != GEU && code != LEU)
-	      || mode == CCUNSmode);
+  if (mode != CCUNSmode
+      && (code == GTU || code == LTU || code == GEU || code == LEU))
+    return false;
 
-  gcc_assert (mode == CCFPmode
-	      || (code != ORDERED && code != UNORDERED
-		  && code != UNEQ && code != LTGT
-		  && code != UNGT && code != UNLT
-		  && code != UNGE && code != UNLE));
+  if (mode != CCFPmode
+      && (code == ORDERED || code == UNORDERED
+	  || code == UNEQ || code == LTGT
+	  || code == UNGT || code == UNLT
+	  || code == UNGE || code == UNLE))
+    return false;
 
   /* These should never be generated except for
      flag_finite_math_only.  */
-  gcc_assert (mode != CCFPmode
-	      || flag_finite_math_only
-	      || (code != LE && code != GE
-		  && code != UNEQ && code != LTGT
-		  && code != UNGT && code != UNLT));
+  if (mode == CCFPmode
+      && !flag_finite_math_only
+      && (code == LE || code == GE
+	  || code == UNEQ || code == LTGT
+	  || code == UNGT || code == UNLT))
+    return false;
 
   /* These are invalid; the information is not there.  */
-  gcc_assert (mode != CCEQmode || code == EQ || code == NE);
+  if (mode == CCEQmode
+      && code != EQ && code != NE)
+    return false;
+
+  return true;
 }
 
 
@@ -17202,7 +17373,7 @@ rs6000_secondary_reload (bool in_p,
 
 	      else if (!legitimate_indirect_address_p (addr, false)
 		       && !rs6000_legitimate_offset_address_p (PTImode, addr,
-							       false, true))
+							       false, true, false))
 		{
 		  sri->icode = icode;
 		  /* account for splitting the loads, and converting the
@@ -17218,7 +17389,7 @@ rs6000_secondary_reload (bool in_p,
                   && (legitimate_indirect_address_p (addr, false)
                       || legitimate_indirect_address_p (addr, false)
                       || rs6000_legitimate_offset_address_p (mode, addr,
-                                                             false, true)))
+                                                             false, true, false)))
 
            ;
          /* Loads to and stores from vector registers can only do reg+reg
@@ -17488,7 +17659,7 @@ rs6000_secondary_reload_inner (rtx reg, rtx mem, rtx scratch, bool store_p)
       if (GET_CODE (addr) == PLUS
 	  && (and_op2 != NULL_RTX
 	      || !rs6000_legitimate_offset_address_p (PTImode, addr,
-						      false, true)))
+						      false, true, false)))
 	{
 	  /* find_replacement already recurses into both operands of
 	     PLUS so we don't need to call it here.  */
@@ -17524,7 +17695,7 @@ rs6000_secondary_reload_inner (rtx reg, rtx mem, rtx scratch, bool store_p)
 	}
       else if (!legitimate_indirect_address_p (addr, false)
 	       && !rs6000_legitimate_offset_address_p (PTImode, addr,
-						       false, true))
+						       false, true, false))
 	{
 	  if (TARGET_DEBUG_ADDR)
 	    {
@@ -17546,7 +17717,7 @@ rs6000_secondary_reload_inner (rtx reg, rtx mem, rtx scratch, bool store_p)
 	  || ((GET_MODE_SIZE (mode) == 4 || GET_MODE_SIZE (mode) == 8)
 	      && and_op2 == NULL_RTX
 	      && scratch_or_premodify == scratch
-	      && rs6000_legitimate_offset_address_p (mode, addr, false, false)))
+	      && rs6000_legitimate_offset_address_p (mode, addr, false, false, false)))
 	break;
 
       /* If this isn't a legacy floating point load/store, fall through to the
@@ -17878,7 +18049,7 @@ rs6000_preferred_reload_class (rtx x, enum reg_class rclass)
       if (MEM_P (x) && reg_addr[mode].scalar_in_vmx_p)
 	{
 	  rtx addr = XEXP (x, 0);
-	  if (rs6000_legitimate_offset_address_p (mode, addr, false, true)
+	  if (rs6000_legitimate_offset_address_p (mode, addr, false, true, false)
 	      || legitimate_lo_sum_address_p (mode, addr, false))
 	    return FLOAT_REGS;
 	}
@@ -17892,6 +18063,13 @@ rs6000_preferred_reload_class (rtx x, enum reg_class rclass)
       return rclass;
     }
 
+  /* For VLE, we have cheaper insns for moving to LR and CTR.  */
+  if (TARGET_VLE
+      && REG_P (x)
+      && (REGNO (x) == LR_REGNO || REGNO (x) == CTR_REGNO)
+      && reg_classes_intersect_p (rclass, VLE_ALT_REGS))
+    return VLE_REGS;
+
   return rclass;
 }
 
@@ -18011,9 +18189,15 @@ rs6000_secondary_reload_class (enum reg_class rclass, enum machine_mode mode,
   else
     regno = -1;
 
+  if (TARGET_VLE
+      && CR_REGNO4_THRU_7_P (regno)
+      && rclass == CR_REGS)
+    return VLE_CR_REGS;
+
   /* We can place anything into GENERAL_REGS and can put GENERAL_REGS
      into anything.  */
   if (rclass == GENERAL_REGS || rclass == BASE_REGS
+      || (TARGET_VLE && rclass == VLE_REGS)
       || (regno >= 0 && INT_REGNO_P (regno)))
     return NO_REGS;
 
@@ -18377,7 +18561,7 @@ ccr_bit (rtx op, int scc_p)
   cc_regnum = REGNO (reg);
   base_bit = 4 * (cc_regnum - CR0_REGNO);
 
-  validate_condition_mode (code, cc_mode);
+  gcc_assert(validate_condition_mode (code, cc_mode));
 
   /* When generating a sCOND operation, only positive conditions are
      allowed.  */
@@ -18596,7 +18780,31 @@ print_operand (FILE *file, rtx x, int code)
 
   switch (code)
     {
-      /* %a is output_address.  */
+    case '^':
+      /* Print the "e_" prefix for VLE instructions.  */
+      if (TARGET_VLE)
+        fprintf (file, "%s", "e_");
+      return;
+
+    case '+':
+      /* Print the "se_" prefix for VLE instructions.  */
+      if (TARGET_VLE)
+        fprintf (file, "%s", "se_");
+      return;
+
+    case '?':
+      /* Print the "16" to modify VLE add immediate instructions.  */
+      if (TARGET_VLE)
+        fprintf (file, "%s", "16");
+      return;
+
+    case '-':
+      /* Print a '-' suffix on branch insns if not VLE.  */
+      if (!TARGET_VLE)
+	fprintf (file, "-");
+      return;
+
+     /* %a is output_address.  */
 
     case 'b':
       /* If constant, low-order 16 bits of constant, unsigned.
@@ -18627,7 +18835,19 @@ print_operand (FILE *file, rtx x, int code)
       fprintf (file, "%d", i + 1);
       return;
 
-    case 'E':
+    case 'e':
+      /* Like 'X' but used to print the "e_" prefix for non-indexed
+	     VLE instructions.  */
+      if (TARGET_VLE
+	  && ! (GET_CODE (x) == MEM
+		&& (legitimate_indexed_address_p (XEXP (x, 0), 0)
+		    || (GET_CODE (XEXP (x, 0)) == PRE_MODIFY
+			&& legitimate_indexed_address_p (XEXP (XEXP (x, 0), 1),
+							 0)))))
+	  fprintf (file, "e_");
+      return;
+
+      case 'E':
       /* X is a CR register.  Print the number of the EQ bit of the CR */
       if (GET_CODE (x) != REG || ! CR_REGNO_P (REGNO (x)))
 	output_operand_lossage ("invalid %%E value");
@@ -18653,6 +18873,23 @@ print_operand (FILE *file, rtx x, int code)
 	fprintf (file, "%d", 32 - 4 * (REGNO (x) - CR0_REGNO));
       return;
 
+    case 'g':
+      /* X is a CONST_INT that is a 32-bit complement of a power of two.
+	 Output the number of most significant one bits.  */
+      uval = 0;
+      if (INT_P (x))
+	{
+	  uval = UINTVAL (x);
+	  if (TARGET_32BIT && uval == 0x7fffffff)
+	    uval = ~uval ^ 0xffffffff;
+	  uval = ~uval;
+	}
+      if (!INT_P (x) /*|| uval < 0*/ || (i = exact_log2 (uval)) < 0 || i > 31)
+	output_operand_lossage ("invalid %%g value");
+      else
+	fprintf (file, "%d", 31 - i);
+      return;
+
     case 'G':
       /* X is a constant integer.  If it is negative, print "m",
 	 otherwise print "z".  This is to make an aze or ame insn.  */
@@ -18682,6 +18919,12 @@ print_operand (FILE *file, rtx x, int code)
 	print_operand (file, x, 0);
       return;
 
+    case 'i':
+      /* If constant, print the "e_" prefix for VLE instructions.  */
+      if (TARGET_VLE && INT_P (x))
+        fprintf (file, "%s", "e_");
+      return;
+
     case 'I':
       /* Print `i' if this is a constant, else nothing.  */
       if (INT_P (x))
@@ -18788,6 +19031,22 @@ print_operand (FILE *file, rtx x, int code)
 	fprintf (file, "%d", XVECLEN (x, 0) * 4);
       return;
 
+    case 'o':
+      /* X is a CONST_INT that is a 32-bit power of two.  Output the number
+	 of most significant zero bits.  */
+      uval = 0;
+      if (INT_P (x))
+	{
+	  uval = UINTVAL (x);
+	  if (TARGET_32BIT && uval + 0x80000000 == 0)
+	    uval &= 0xffffffff;
+	}
+      if (!INT_P (x) /*|| uval < 0*/ || (i = exact_log2 (uval)) < 0 || i > 31)
+	output_operand_lossage ("invalid %%o value");
+      else
+	fprintf (file, "%d", 31 - i);
+      return;
+
     case 'O':
       /* Similar, but subtract 1 first.  */
       if (GET_CODE (x) != PARALLEL)
@@ -18868,7 +19127,25 @@ print_operand (FILE *file, rtx x, int code)
 	fprintf (file, "%d", 128 >> (REGNO (x) - CR0_REGNO));
       return;
 
-    case 's':
+    case 'r':
+      /* X is a CONST_INT that is a contiguous mask of 1-32 low-order bits
+	 set.  Print the number of bits set, or 0 for 32.  */
+      uval = 0;
+      if (INT_P (x))
+	{
+	  uval = UINTVAL (x);
+	  if (TARGET_32BIT && uval + 1 == 0)
+	    uval &= 0xffffffff;
+	}
+      if (!INT_P (x)
+	  || ((uval | 0xffffffff) ^ 0xffffffff) != 0
+	  || (i = exact_log2 (uval + 1)) < 0)
+	output_operand_lossage ("invalid %%r value");
+      else
+	fprintf (file, "%d", i & 0x1f);
+      return;
+
+	  case 's':
       /* Low 5 bits of 32 - value */
       if (! INT_P (x))
 	output_operand_lossage ("invalid %%s value");
@@ -19698,8 +19975,8 @@ rs6000_generate_compare (rtx cmp, enum machine_mode mode)
 	case UNLT: or1 = UNORDERED;  or2 = LT;  break;
 	default:  gcc_unreachable ();
 	}
-      validate_condition_mode (or1, comp_mode);
-      validate_condition_mode (or2, comp_mode);
+      gcc_assert (validate_condition_mode (or1, comp_mode));
+      gcc_assert (validate_condition_mode (or2, comp_mode));
       or1_rtx = gen_rtx_fmt_ee (or1, SImode, compare_result, const0_rtx);
       or2_rtx = gen_rtx_fmt_ee (or2, SImode, compare_result, const0_rtx);
       compare2_rtx = gen_rtx_COMPARE (CCEQmode,
@@ -19711,7 +19988,7 @@ rs6000_generate_compare (rtx cmp, enum machine_mode mode)
       code = EQ;
     }
 
-  validate_condition_mode (code, GET_MODE (compare_result));
+  gcc_assert (validate_condition_mode (code, GET_MODE (compare_result)));
 
   return gen_rtx_fmt_ee (code, VOIDmode, compare_result, const0_rtx);
 }
@@ -19828,13 +20105,14 @@ output_cbranch (rtx op, const char *label, int reversed, rtx insn)
   enum machine_mode mode = GET_MODE (cc_reg);
   int cc_regno = REGNO (cc_reg) - CR0_REGNO;
   int need_longbranch = label != NULL && get_attr_length (insn) == 8;
+  int short_rbranch = TARGET_VLE && need_longbranch && cc_regno == 0;
   int really_reversed = reversed ^ need_longbranch;
   char *s = string;
   const char *ccode;
   const char *pred;
   rtx note;
 
-  validate_condition_mode (code, mode);
+  gcc_assert (validate_condition_mode (code, mode));
 
   /* Work out which way this really branches.  We could use
      reverse_condition_maybe_unordered here always but this
@@ -19919,25 +20197,42 @@ output_cbranch (rtx op, const char *label, int reversed, rtx insn)
 	}
     }
 
-  if (label == NULL)
-    s += sprintf (s, "b%slr%s ", ccode, pred);
+  if (TARGET_VLE)
+    {
+      gcc_assert (label != NULL);
+      s += sprintf (s, "%sb%s ", short_rbranch ? "se_" : "e_", ccode);
+      gcc_assert((short_rbranch && cc_regno == 0) || !short_rbranch);
+    }
+  else if (label == NULL)
+	  s += sprintf (s, "b%slr%s ", ccode, pred);
   else
-    s += sprintf (s, "b%s%s ", ccode, pred);
-
-  /* We need to escape any '%' characters in the reg_names string.
-     Assume they'd only be the first character....  */
-  if (reg_names[cc_regno + CR0_REGNO][0] == '%')
-    *s++ = '%';
-  s += sprintf (s, "%s", reg_names[cc_regno + CR0_REGNO]);
+	  s += sprintf (s, "b%s%s ", ccode, pred);
+
+	/* We need to escape any '%' characters in the reg_names string.
+	   Assume they'd only be the first character....  */
+  if (!TARGET_VLE || !short_rbranch) {
+	  if (reg_names[cc_regno + CR0_REGNO][0] == '%')
+		  *s++ = '%';
+	  s += sprintf (s, "%s", reg_names[cc_regno + CR0_REGNO]);
+  }
 
   if (label != NULL)
     {
       /* If the branch distance was too far, we may have to use an
 	 unconditional branch to go the distance.  */
-      if (need_longbranch)
-	s += sprintf (s, ",$+8\n\tb %s", label);
-      else
-	s += sprintf (s, ",%s", label);
+     if (need_longbranch)
+     {
+    	if (short_rbranch) {
+        	if (!TARGET_VLE)
+        		*s++ = ',';
+        	s += sprintf (s, "$+6");
+    	}
+    	else
+	    s += sprintf (s, ",$+8");
+	  s += sprintf (s, "\n\t%sb %s", TARGET_VLE ? "e_" : "", label);
+     }
+     else
+	   s += sprintf (s, ",%s", label);
     }
 
   return string;
@@ -19957,7 +20252,7 @@ output_e500_flip_gt_bit (rtx dst, rtx src)
   a = 4 * (REGNO (dst) - CR0_REGNO) + 1;
   b = 4 * (REGNO (src) - CR0_REGNO) + 1;
 
-  sprintf (string, "crnot %d,%d", a, b);
+  sprintf (string, "%%^crnot %d,%d", a, b);
   return string;
 }
 
@@ -21491,11 +21786,12 @@ rs6000_savres_strategy (rs6000_stack_t *info,
   int strategy = 0;
   bool lr_save_p;
 
-  if (TARGET_MULTIPLE
+  if (TARGET_VLE_MULTIPLE
       && !TARGET_POWERPC64
       && !(TARGET_SPE_ABI && info->spe_64bit_regs_used)
       && info->first_gp_reg_save < 31
-      && !global_regs_p (info->first_gp_reg_save, 32))
+      && !global_regs_p (info->first_gp_reg_save, 32)
+	  && (!TARGET_VLE || info->total_size < 128))
     strategy |= SAVRES_MULTIPLE;
 
   if (crtl->calls_eh_return
@@ -22762,7 +23058,7 @@ rs6000_emit_allocate_stack (HOST_WIDE_INT size, rtx copy_reg, int copy_off)
 	emit_move_insn (copy_reg, stack_reg);
     }
 
-  if (size > 32767)
+  if ((TARGET_VLE && size > 128) || size > 32767)
     {
       /* Need a note here so that try_split doesn't get confused.  */
       if (get_last_insn () == NULL_RTX)
@@ -23562,6 +23858,9 @@ rs6000_emit_prologue (void)
   HOST_WIDE_INT frame_off = 0;
   HOST_WIDE_INT sp_off = 0;
 
+  if (TARGET_DEBUG_STACK)
+    debug_stack_info (info);
+
 #ifdef ENABLE_CHECKING
   /* Track and check usage of r0, r11, r12.  */
   int reg_inuse = using_static_chain_p ? 1 << 11 : 0;
@@ -24081,7 +24380,7 @@ rs6000_emit_prologue (void)
       hi = gen_int_mode (toc_restore_insn & ~0xffff, SImode);
       emit_insn (gen_xorsi3 (tmp_reg_si, tmp_reg_si, hi));
       compare_result = gen_rtx_REG (CCUNSmode, CR0_REGNO);
-      validate_condition_mode (EQ, CCUNSmode);
+      gcc_assert (validate_condition_mode (EQ, CCUNSmode));
       lo = gen_int_mode (toc_restore_insn & 0xffff, SImode);
       emit_insn (gen_rtx_SET (VOIDmode, compare_result,
 			      gen_rtx_COMPARE (CCUNSmode, tmp_reg_si, lo)));
@@ -27183,7 +27482,7 @@ rs6000_adjust_cost (rtx insn, rtx link, rtx dep_insn, int cost)
             break;
           }
 
-      if ((rs6000_cpu == CPU_PPCE500MC
+      if ((rs6000_cpu == PROCESSOR_PPCE500MC
           || rs6000_cpu_attr == CPU_PPCE500MC64
           || rs6000_cpu_attr == CPU_PPCE5500
           || rs6000_cpu_attr == CPU_PPCE6500)
@@ -28145,7 +28444,7 @@ remove_redundant_mov (void)
     if ((REGNO(operands[3]) == 3))
     {
       rtx ret_reg;
-      int insn_code_number;
+      int insn_code_number ATTRIBUTE_UNUSED;
       
       ret_reg = copy_rtx (operands[3]);
       XEXP(pat0,0) = ret_reg;
@@ -28928,7 +29227,9 @@ rs6000_trampoline_size (void)
 
     case ABI_DARWIN:
     case ABI_V4:
-      ret = (TARGET_32BIT) ? 40 : 48;
+      ret = (TARGET_VLE) ? VLE_TRAMPOLINE_SIZE :
+    		  (TARGET_32BIT) ? TARGET_32BIT_TRAMPOLINE_SIZE :
+    				  TARGET_64BIT_TRAMPOLINE_SIZE;
       break;
     }
 
@@ -30026,6 +30327,80 @@ rs6000_elf_file_end (void)
     file_end_indicate_exec_stack ();
 #endif
 }
+
+void
+rs6000_elf_asm_named_section (const char *name, unsigned int flags,
+			       tree decl ATTRIBUTE_UNUSED)
+{
+  char flagchars[11], *f = flagchars;
+
+  /* If we have already declared this section, we can use an
+     abbreviated form to switch back to it -- unless this section is
+     part of a COMDAT groups, in which case GAS requires the full
+     declaration every time.  */
+  if (!(HAVE_COMDAT_GROUP && (flags & SECTION_LINKONCE))
+      && (flags & SECTION_DECLARED))
+    {
+      fprintf (asm_out_file, "\t.section\t%s\n", name);
+      return;
+    }
+
+  if (!(flags & SECTION_DEBUG))
+    *f++ = 'a';
+  if (flags & SECTION_EXCLUDE)
+    *f++ = 'e';
+  if (flags & SECTION_WRITE)
+    *f++ = 'w';
+  if (flags & SECTION_CODE) {
+    *f++ = 'x';
+    if (vle_code)
+        *f++ = 'v';
+  }
+  if (flags & SECTION_SMALL)
+    *f++ = 's';
+  if (flags & SECTION_MERGE)
+    *f++ = 'M';
+  if (flags & SECTION_STRINGS)
+    *f++ = 'S';
+  if (flags & SECTION_TLS)
+    *f++ = 'T';
+  if (HAVE_COMDAT_GROUP && (flags & SECTION_LINKONCE))
+    *f++ = 'G';
+  *f = '\0';
+
+  fprintf (asm_out_file, "\t.section\t%s,\"%s\"", name, flagchars);
+
+  if (!(flags & SECTION_NOTYPE))
+    {
+      const char *type;
+      const char *format;
+
+      if (flags & SECTION_BSS)
+	type = "nobits";
+      else
+	type = "progbits";
+
+      format = ",@%s";
+      /* On platforms that use "@" as the assembly comment character,
+	 use "%" instead.  */
+      if (strcmp (ASM_COMMENT_START, "@") == 0)
+	format = ",%%%s";
+      fprintf (asm_out_file, format, type);
+
+      if (flags & SECTION_ENTSIZE)
+	fprintf (asm_out_file, ",%d", flags & SECTION_ENTSIZE);
+      if (HAVE_COMDAT_GROUP && (flags & SECTION_LINKONCE))
+	{
+	  if (TREE_CODE (decl) == IDENTIFIER_NODE)
+	    fprintf (asm_out_file, ",%s,comdat", IDENTIFIER_POINTER (decl));
+	  else
+	    fprintf (asm_out_file, ",%s,comdat",
+		     IDENTIFIER_POINTER (DECL_COMDAT_GROUP (decl)));
+	}
+    }
+
+  putc ('\n', asm_out_file);
+}
 #endif
 
 #if TARGET_XCOFF
@@ -30373,50 +30748,96 @@ rs6000_rtx_costs (rtx x, int code, int outer_code, int opno ATTRIBUTE_UNUSED,
     {
       /* On the RS/6000, if it is valid in the insn, it is free.  */
     case CONST_INT:
-      if (((outer_code == SET
-	    || outer_code == PLUS
-	    || outer_code == MINUS)
-	   && (satisfies_constraint_I (x)
-	       || satisfies_constraint_L (x)))
-	  || (outer_code == AND
-	      && (satisfies_constraint_K (x)
-		  || (mode == SImode
-		      ? satisfies_constraint_L (x)
-		      : satisfies_constraint_J (x))
-		  || mask_operand (x, mode)
-		  || (mode == DImode
-		      && mask64_operand (x, DImode))))
-	  || ((outer_code == IOR || outer_code == XOR)
-	      && (satisfies_constraint_K (x)
-		  || (mode == SImode
-		      ? satisfies_constraint_L (x)
-		      : satisfies_constraint_J (x))))
-	  || outer_code == ASHIFT
-	  || outer_code == ASHIFTRT
-	  || outer_code == LSHIFTRT
-	  || outer_code == ROTATE
-	  || outer_code == ROTATERT
-	  || outer_code == ZERO_EXTRACT
-	  || (outer_code == MULT
-	      && satisfies_constraint_I (x))
-	  || ((outer_code == DIV || outer_code == UDIV
-	       || outer_code == MOD || outer_code == UMOD)
-	      && exact_log2 (INTVAL (x)) >= 0)
-	  || (outer_code == COMPARE
-	      && (satisfies_constraint_I (x)
-		  || satisfies_constraint_K (x)))
-	  || ((outer_code == EQ || outer_code == NE)
-	      && (satisfies_constraint_I (x)
-		  || satisfies_constraint_K (x)
-		  || (mode == SImode
-		      ? satisfies_constraint_L (x)
-		      : satisfies_constraint_J (x))))
-	  || (outer_code == GTU
-	      && satisfies_constraint_I (x))
-	  || (outer_code == LTU
-	      && satisfies_constraint_P (x)))
-	{
-	  *total = 0;
+      if (TARGET_VLE
+	      && ((outer_code == SET
+	      && (satisfies_constraint_kuim7 (x)
+		   || satisfies_constraint_kbit5 (x)
+		   || satisfies_constraint_kmsk5 (x)))
+	      || ((outer_code == PLUS || outer_code == MINUS)
+		  && satisfies_constraint_koim5 (x))
+	      || (outer_code == AND
+		  && (satisfies_constraint_kuim5 (x)
+		     || satisfies_constraint_kbic5 (x)))
+	      || (outer_code == IOR
+		  && satisfies_constraint_kbit5 (x))
+	      || outer_code == ASHIFT
+	      || outer_code == ASHIFTRT
+	      || outer_code == LSHIFTRT
+	      || ((outer_code == DIV || outer_code == UDIV)
+		  && exact_log2 (INTVAL (x)) >= 0)
+	      || ((outer_code == MOD || outer_code == UMOD)
+		  && exact_log2 (INTVAL (x)) >= 0
+		  && satisfies_constraint_kuim5 (GEN_INT (INTVAL (x) - 1)))
+	      || (outer_code == COMPARE
+		  && (satisfies_constraint_koim5 (x)
+		      || satisfies_constraint_kuim5 (x)))))
+      {
+       *total = 0;
+       return true;
+      }
+      else if ((outer_code == SET
+		&& ((!TARGET_VLE && satisfies_constraint_I (x))
+		    || (TARGET_VLE
+			&& (satisfies_constraint_kli20 (x)
+			    || satisfies_constraint_K (x)))
+		    || satisfies_constraint_L (x)))
+	       || ((outer_code == PLUS
+		    || outer_code == MINUS)
+		   && ((TARGET_VLE && satisfies_constraint_ksci8 (x))
+		       || satisfies_constraint_I (x)
+		       || satisfies_constraint_L (x)))
+	       || (outer_code == AND
+		   && ((TARGET_VLE && satisfies_constraint_ksci8 (x))
+		       || satisfies_constraint_K (x)
+		       || (mode == SImode
+			   ? satisfies_constraint_L (x)
+			   : satisfies_constraint_J (x))
+		       || mask_operand (x, mode)
+		       || (mode == DImode
+			   && mask64_operand (x, DImode))))
+	       || (outer_code == IOR
+		   && ((TARGET_VLE && satisfies_constraint_ksci8 (x))
+		       || satisfies_constraint_K (x)
+		       || (mode == SImode
+			   ? satisfies_constraint_L (x)
+			   : satisfies_constraint_J (x))))
+	       || (outer_code == XOR
+		   && (TARGET_VLE
+		       ? satisfies_constraint_ksci8 (x)
+		       : (satisfies_constraint_K (x)
+			  || (mode == SImode
+			      ? satisfies_constraint_L (x)
+			      : satisfies_constraint_J (x)))))
+	       || outer_code == ASHIFT
+	       || outer_code == ASHIFTRT
+	       || outer_code == LSHIFTRT
+	       || outer_code == ROTATE
+	       || outer_code == ROTATERT
+	       || outer_code == ZERO_EXTRACT
+	       || (outer_code == MULT
+		   && ((TARGET_VLE && satisfies_constraint_ksci8 (x))
+		       || satisfies_constraint_I (x)))
+	       || ((outer_code == DIV || outer_code == UDIV
+		    || outer_code == MOD || outer_code == UMOD)
+		   && exact_log2 (INTVAL (x)) >= 0)
+	       || (outer_code == COMPARE
+		   && ((TARGET_VLE && satisfies_constraint_ksci8 (x))
+		       || satisfies_constraint_I (x)
+		       || satisfies_constraint_K (x)))
+	       || ((outer_code == EQ || outer_code == NE)
+		   && (TARGET_VLE
+		       ? satisfies_constraint_ksci8 (x)
+		       : (satisfies_constraint_I (x)
+			  || satisfies_constraint_K (x)
+			  || (mode == SImode
+			      ? satisfies_constraint_L (x)
+			      : satisfies_constraint_J (x)))))
+	       || (outer_code == GTU
+		   && satisfies_constraint_kscI8 (x))
+	       || (outer_code == LTU
+		   && satisfies_constraint_kscP8 (x)))
+	{
+	  *total = TARGET_VLE ? COSTS_N_INSNS (1) / 2 : 0;
 	  return true;
 	}
       else if ((outer_code == PLUS
@@ -30763,7 +31184,12 @@ rs6000_register_move_cost (enum machine_mode mode,
     {
       reg_class_t rclass = from;
 
-      if (! reg_classes_intersect_p (to, GENERAL_REGS))
+      if (TARGET_VLE)
+	{
+	  if (from != VLE_ALT_REGS && ! reg_classes_intersect_p (to, GENERAL_REGS))
+	    rclass = to;
+  	}
+      else if (! reg_classes_intersect_p (to, GENERAL_REGS))
 	rclass = to;
 
       if (rclass == FLOAT_REGS || rclass == ALTIVEC_REGS || rclass == VSX_REGS)
@@ -30783,7 +31209,22 @@ rs6000_register_move_cost (enum machine_mode mode,
 	       && reg_classes_intersect_p (rclass, LINK_OR_CTR_REGS))
         ret = 6 * hard_regno_nregs[0][mode];
 
-      else
+      else if (TARGET_VLE
+	       && (from == VLE_ALT_REGS
+		   && (to == VLE_ALT_REGS
+		       || to == LINK_REGS
+		       || to == CTR_REGS
+                       || to == LINK_OR_CTR_REGS)))
+	   ret = 8;
+
+      else if (TARGET_VLE
+	       && (to == VLE_ALT_REGS
+		   && (from == LINK_REGS
+		       || from == CTR_REGS
+                       || from == LINK_OR_CTR_REGS)))
+	   ret = 8;
+
+     else
 	/* A move will cost one instruction per GPR moved.  */
 	ret = 2 * hard_regno_nregs[0][mode];
     }
@@ -32044,7 +32485,7 @@ rs6000_dwarf_register_span (rtx reg)
   enum machine_mode mode = GET_MODE (reg);
 
   if (TARGET_SPE
-      && regno < 32
+      && regno < 31
       && (SPE_VECTOR_MODE (GET_MODE (reg))
 	  || (TARGET_E500_DOUBLE && FLOAT_MODE_P (mode)
 	      && mode != SFmode && mode != SDmode && mode != SCmode)))
@@ -32256,6 +32697,91 @@ rs6000_final_prescan_insn (rtx insn, rtx *operand ATTRIBUTE_UNUSED,
     }
 }
 
+bool
+valid_vle_sd4_field (rtx mem, enum machine_mode mode)
+{
+  int high = 0;
+  /* Address inside MEM.  */
+  rtx op = XEXP (mem, 0);
+  rtx base, addend;
+
+  if (mode == QImode)
+    high = 0xf;
+  else if (mode == HImode)
+    high = 0x1e;
+  else if (mode == SImode)
+    high = 0x3c;
+
+  if (REG_P (op))
+    {
+      base = op;
+      addend = const0_rtx;
+    }
+  else if (GET_CODE (op) == PLUS)
+    {
+      base = XEXP (op, 0);
+      addend = XEXP (op, 1);
+    }
+  else
+    return false;
+
+  if (!REG_P (base)
+      || (REGNO (base) > 7 && REGNO (base) <= 23)
+      || (REGNO (base) > 31 && REGNO (base) <= LAST_VIRTUAL_REGISTER))
+    return false;
+
+  if (GET_CODE (addend) != CONST_INT)
+    return false;
+
+  if (INTVAL (addend) % GET_MODE_SIZE (mode) != 0)
+    return false;
+
+  if (INTVAL (addend) < 0
+      || INTVAL (addend) > high)
+    return false;
+
+  return true;
+}
+
+/* Check if IVAL can be SCI8-encoded.  According to VLEPEM immediates
+   such encoded are 32-bit words, hence we allow zero-extended 32-bit
+   values universally and then sign-extended 32-bit values on 32-bit
+   targets only as they will truncate the operation performed to 32
+   bits anyway.  */
+
+bool
+valid_sci8_immediate (HOST_WIDE_INT ival)
+{
+  if ((ival & ~(unsigned HOST_WIDE_INT) 0xffffffff) == 0
+      || (TARGET_32BIT
+	  && ((ival & ~(unsigned HOST_WIDE_INT) 0x7fffffff)
+	      == ~(unsigned HOST_WIDE_INT) 0x7fffffff)))
+    {
+      unsigned int ival32 = ival & 0xffffffff;
+
+      if ((ival32 & 0x000000ff) == ival32)
+	return true;
+      if ((ival32 & 0x0000ff00) == ival32)
+	return true;
+      if ((ival32 & 0x00ff0000) == ival32)
+	return true;
+      if ((ival32 & 0xff000000) == ival32)
+	return true;
+
+      if ((ival32 | 0xffffff00) == ival32)
+	return true;
+      if ((ival32 | 0xffff00ff) == ival32)
+	return true;
+      if ((ival32 | 0xff00ffff) == ival32)
+	return true;
+      if ((ival32 | 0x00ffffff) == ival32)
+	return true;
+    }
+
+  return false;
+}
+
+
 /* Implement the TARGET_ASAN_SHADOW_OFFSET hook.  */
 
 #if TARGET_ELF
@@ -32311,6 +32837,7 @@ static struct rs6000_opt_mask const rs6000_opt_masks[] =
   { "update",			OPTION_MASK_NO_UPDATE,		true , true  },
   { "upper-regs-df",		OPTION_MASK_UPPER_REGS_DF,	false, true  },
   { "upper-regs-sf",		OPTION_MASK_UPPER_REGS_SF,	false, true  },
+  { "vle",			OPTION_MASK_VLE,		false, true  },
   { "vsx",			OPTION_MASK_VSX,		false, true  },
   { "vsx-timode",		OPTION_MASK_VSX_TIMODE,		false, true  },
 #ifdef OPTION_MASK_64BIT
@@ -33069,7 +33596,7 @@ rs6000_allocate_stack_temp (enum machine_mode mode,
   if (!legitimate_indirect_address_p (addr, strict_p))
     {
       if (offsettable_p
-	  && !rs6000_legitimate_offset_address_p (mode, addr, strict_p, true))
+	  && !rs6000_legitimate_offset_address_p (mode, addr, strict_p, true, false))
 	stack = replace_equiv_address (stack, copy_addr_to_reg (addr));
 
       else if (reg_reg_p && !legitimate_indexed_address_p (addr, strict_p))
@@ -33573,6 +34100,10 @@ rs6000_split_logical_di (rtx operands[3],
 	      if (code == AND && sub_value != -1 && sub_value != 0
 		  && !and_operand (op2_hi_lo[i], SImode))
 		op2_hi_lo[i] = force_reg (SImode, op2_hi_lo[i]);
+	      if (code == XOR && TARGET_VLE && !vle_xor_operand(op2_hi_lo[i], SImode))
+	  		op2_hi_lo[i] = force_reg (SImode, op2_hi_lo[i]);
+	      if (code == IOR && TARGET_VLE && !vle_or_operand(op2_hi_lo[i], SImode))
+	  		op2_hi_lo[i] = force_reg (SImode, op2_hi_lo[i]);
 	    }
 	}
     }
@@ -33580,7 +34111,7 @@ rs6000_split_logical_di (rtx operands[3],
   for (i = 0; i < 2; i++)
     {
       /* Split large IOR/XOR operations.  */
-      if ((code == IOR || code == XOR)
+      if ((code == IOR || code == XOR) && !TARGET_VLE
 	  && GET_CODE (op2_hi_lo[i]) == CONST_INT
 	  && !complement_final_p
 	  && !complement_op1_p
diff --git a/gcc/config/rs6000/rs6000.h b/gcc/config/rs6000/rs6000.h
index 4e313f0..d16bee5 100644
--- a/gcc/config/rs6000/rs6000.h
+++ b/gcc/config/rs6000/rs6000.h
@@ -157,12 +157,21 @@
 %{mcpu=G5: -mpower4 -maltivec} \
 %{mcpu=8540: -me500} \
 %{mcpu=8548: -me500} \
+%{mcpu=e200z0: %{mno-vle: -mspe} %{!mno-vle: -mvle}} \
+%{mcpu=e200z2: %{mno-vle: -mspe} %{!mno-vle: -mvle}} \
+%{mcpu=e200z3: %{mno-vle: -mspe} %{!mno-vle: -mvle}} \
+%{mcpu=e200z4: %{mno-vle: -mspe -me200z4 -mno-vle} %{!mno-vle: -mvle -me200z4}} \
+%{mcpu=e200z6: %{mno-vle: -mspe} %{!mno-vle: -mvle}} \
+%{mcpu=e200z7: %{mno-vle: -mspe} %{!mno-vle: -mvle}} \
 %{mcpu=e300c2: -me300} \
 %{mcpu=e300c3: -me300} \
 %{mcpu=e500mc: -me500mc} \
 %{mcpu=e500mc64: -me500mc64} \
 %{mcpu=e5500: -me5500} \
 %{mcpu=e6500: -me6500} \
+%{mvle: -mvle} \
+%{mno-vle: -mspe} \
+%{mlsp: -mvle} \
 %{maltivec: -maltivec} \
 %{mvsx: -mvsx %{!maltivec: -maltivec} %{!mcpu*: %(asm_cpu_power7)}} \
 %{mpower8-vector|mcrypto|mdirect-move|mhtm: %{!mcpu*: %(asm_cpu_power8)}} \
@@ -582,6 +591,7 @@ extern int rs6000_vector_align[];
 #define MASK_STRICT_ALIGN		OPTION_MASK_STRICT_ALIGN
 #define MASK_STRING			OPTION_MASK_STRING
 #define MASK_UPDATE			OPTION_MASK_UPDATE
+#define MASK_VLE			OPTION_MASK_VLE
 #define MASK_VSX			OPTION_MASK_VSX
 #define MASK_VSX_TIMODE			OPTION_MASK_VSX_TIMODE
 
@@ -632,7 +642,20 @@ extern int rs6000_vector_align[];
 
 /* E500 cores only support plain "sync", not lwsync.  */
 #define TARGET_NO_LWSYNC (rs6000_cpu == PROCESSOR_PPC8540 \
-			  || rs6000_cpu == PROCESSOR_PPC8548)
+			  || rs6000_cpu == PROCESSOR_PPC8548 \
+			  || TARGET_VLE)
+
+
+/* The VLE instruction set includes some optional standard ISA
+   instructions unconditionally.  Provide some macros to make checking
+   for their presence easier.  */
+#define TARGET_VLE_MULTIPLE	(TARGET_VLE || TARGET_MULTIPLE)
+#define TARGET_VLE_POWERPC	(TARGET_VLE || !TARGET_POWERPC64)
+
+
+/* Most Power-specific instructions are not there in the VLE instruction
+   set.  */
+#define TARGET_POWER_NOVLE	(!TARGET_POWERPC64 && !TARGET_VLE)
 
 
 /* Whether SF/DF operations are supported on the E500.  */
@@ -852,7 +875,7 @@ extern unsigned rs6000_pointer_size;
     ? 64 : 128)
 
 /* Allocation boundary (in *bits*) for the code of a function.  */
-#define FUNCTION_BOUNDARY 32
+#define FUNCTION_BOUNDARY (TARGET_VLE ? 16 : 32)
 
 /* No data type wants to be aligned rounder than this.  */
 #define BIGGEST_ALIGNMENT 128
@@ -1148,6 +1171,21 @@ enum data_align { align_abi, align_opt, align_both };
 /* True if register is a condition register, but not cr0.  */
 #define CR_REGNO_NOT_CR0_P(N) ((N) >= CR1_REGNO && (N) <= CR7_REGNO)
 
+/* True if register is condition register cr0.  */
+#define CR0_REGNO_P(N) ((N) == CR0_REGNO)
+
+/* True if register is a condition register between 4 and 7.  */
+#define CR_REGNO4_THRU_7_P(N) ((N) >= CR4_REGNO && (N) <= CR7_REGNO)
+
+/* True if register is a valid VLE condition register.  */
+#define VLE_CR_REGNO_P(N) ((N) >= CR0_REGNO && (N) <= CR3_REGNO)
+
+/* True if register is a valid VLE condition register, but not cr0.  */
+#define VLE_CR_REGNO_NOT_CR0_P(N) ((N) >= CR1_REGNO && (N) <= CR3_REGNO)
+
+/* True if register is a valid VLE alternate register.  */
+#define VLE_ALT_REGNO_P(N) ((N) >= 8 && (N) < 24)
+
 /* True if register is an integer register.  */
 #define INT_REGNO_P(N) \
   ((N) <= 31 || (N) == ARG_POINTER_REGNUM || (N) == FRAME_POINTER_REGNUM)
@@ -1372,6 +1410,9 @@ enum reg_class
   NON_FLOAT_REGS,
   CA_REGS,
   SPE_HIGH_REGS,
+  VLE_REGS,
+  VLE_ALT_REGS,
+  VLE_CR_REGS,
   ALL_REGS,
   LIM_REG_CLASSES
 };
@@ -1404,6 +1445,9 @@ enum reg_class
   "NON_FLOAT_REGS",							\
   "CA_REGS",								\
   "SPE_HIGH_REGS",							\
+  "VLE_REGS",								\
+  "VLE_ALT_REGS",							\
+  "VLE_CR_REGS",							\
   "ALL_REGS"								\
 }
 
@@ -1457,6 +1501,12 @@ enum reg_class
   { 0x00000000, 0x00000000, 0x00001000, 0x00000000, 0x00000000 },	\
   /* SPE_HIGH_REGS.  */							\
   { 0x00000000, 0x00000000, 0x00000000, 0xffe00000, 0x001fffff },	\
+  /* VLE_REGS */         \
+  { 0xff0000ff, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },   \
+  /* VLE_ALT_REGS */     \
+  { 0x00ffff00, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },   \
+  /* VLE_CR_REGS */	     \
+  { 0x00000000, 0x00000000, 0x000000f0, 0x00000000, 0x00000000 },   \
   /* ALL_REGS.  */							\
   { 0xffffffff, 0xffffffff, 0xfffffffe, 0xffe7ffff, 0x001fffff }	\
 }
@@ -1502,6 +1552,7 @@ enum r6000_reg_class_enum {
   RS6000_CONSTRAINT_wx,		/* FPR register for STFIWX */
   RS6000_CONSTRAINT_wy,		/* VSX register for SF */
   RS6000_CONSTRAINT_wz,		/* FPR register for LFIWZX */
+  RS6000_CONSTRAINT_kcrxx,	/* CRs for cmpi/cmpli/bc instructions */
   RS6000_CONSTRAINT_MAX
 };
 
@@ -1859,7 +1910,11 @@ typedef struct rs6000_args
 
 /* Length in units of the trampoline for entering a nested function.  */
 
+#define VLE_TRAMPOLINE_SIZE		32
+#define TARGET_32BIT_TRAMPOLINE_SIZE	40
+#define TARGET_64BIT_TRAMPOLINE_SIZE	48
 #define TRAMPOLINE_SIZE rs6000_trampoline_size ()
+
 
 /* Definitions for __builtin_return_address and __builtin_frame_address.
    __builtin_return_address (0) should give link register (65), enable
@@ -2127,7 +2182,8 @@ extern unsigned rs6000_pmode;
 
 #define SELECT_CC_MODE(OP,X,Y) \
   (SCALAR_FLOAT_MODE_P (GET_MODE (X)) ? CCFPmode	\
-   : (OP) == GTU || (OP) == LTU || (OP) == GEU || (OP) == LEU ? CCUNSmode \
+   : (OP) == GTU || (OP) == LTU || (OP) == GEU || (OP) == LEU || \
+	 (TARGET_VLE && GET_CODE (X) == ZERO_EXTRACT) ? CCUNSmode \
    : (((OP) == EQ || (OP) == NE) && COMPARISON_P (X)			  \
       ? CCEQmode : CCmode))
 
@@ -2554,7 +2610,13 @@ extern char rs6000_reg_names[][8];	/* register names (0 vs. %r0).  */
 
 /* Define which CODE values are valid.  */
 
-#define PRINT_OPERAND_PUNCT_VALID_P(CODE)  ((CODE) == '&')
+#define PRINT_OPERAND_PUNCT_VALID_P(CODE)  \
+  ((CODE) == '.'     \
+    || (CODE) == '&' \
+    || (CODE) == '^' \
+    || (CODE) == '+' \
+    || (CODE) == '-' \
+    || (CODE) == '?')
 
 /* Print a memory address as an operand to reference that memory location.  */
 
@@ -2571,6 +2633,9 @@ extern char rs6000_reg_names[][8];	/* register names (0 vs. %r0).  */
 /* General flags.  */
 extern int frame_pointer_needed;
 
+/* Nonzero if generating VLE code.  */
+extern int vle_code;
+
 /* Classification of the builtin functions as to which switches enable the
    builtin, and what attributes it should have.  We used to use the target
    flags macros, but we've run out of bits, so we now map the options into new
diff --git a/gcc/config/rs6000/rs6000.md b/gcc/config/rs6000/rs6000.md
index 3ac3e69..470484c 100644
--- a/gcc/config/rs6000/rs6000.md
+++ b/gcc/config/rs6000/rs6000.md
@@ -166,6 +166,8 @@
 ;; Define floating point instruction sub-types for use with Xfpu.md
 (define_attr "fp_type" "fp_default,fp_addsub_s,fp_addsub_d,fp_mul_s,fp_mul_d,fp_div_s,fp_div_d,fp_maddsub_s,fp_maddsub_d,fp_sqrt_s,fp_sqrt_d" (const_string "fp_default"))
 
+(define_attr "is_vle" "no,yes" (const (symbol_ref "vle_code")))
+
 ;; Length (in bytes).
 ; '(pc)' in the following doesn't include the instruction itself; it is
 ; calculated as if the instruction had zero size.
@@ -179,6 +181,15 @@
 			      (const_int 8))
 		(const_int 4)))
 
+;; Used to control the "enabled" attribute on a per-instruction basis.
+(define_attr "isa" "common,novle,vle"
+  (const_string "common"))
+
+(define_attr "enabled" ""
+  (cond [(eq_attr "isa" "vle") (symbol_ref "TARGET_VLE")
+         (eq_attr "isa" "novle") (symbol_ref "!TARGET_VLE")]
+        (const_int 1)))
+
 ;; Processor type -- this attribute must exactly match the processor_type
 ;; enumeration in rs6000-opts.h.
 (define_attr "cpu"
@@ -187,7 +198,9 @@
    ppc403,ppc405,ppc440,ppc476,
    ppc8540,ppc8548,ppce300c2,ppce300c3,ppce500mc,ppce500mc64,ppce5500,ppce6500,
    power4,power5,power6,power7,power8,
-   rs64a,mpccore,cell,ppca2,titan"
+   rs64a,mpccore,cell,ppca2,titan,
+   ppce200z0,ppce200z2,ppce200z3,
+   ppce200z4,ppce200z6,ppce200z7"
   (const (symbol_ref "rs6000_cpu_attr")))
 
 
@@ -870,38 +883,45 @@
 	(zero_extend:SI (match_operand:QI 1 "gpc_reg_operand" "")))]
   ""
   "")
-
-(define_insn ""
-  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
-	(zero_extend:SI (match_operand:QI 1 "reg_or_mem_operand" "m,r")))]
+ 
+ (define_insn ""
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r,kregs,r")
+	(zero_extend:SI (match_operand:QI 1 "reg_or_mem_operand" "kmsd4,m,0,r")))]
   ""
   "@
-   lbz%U1%X1 %0,%1
-   rlwinm %0,%1,0,0xff"
+   se_lbz %0,%1
+   %e1lbz%U1%X1 %0,%1
+   se_extzb %0
+   %^rlwinm %0,%1,0,0xff"
   [(set_attr_alternative "type"
-      [(if_then_else
-	 (match_test "update_indexed_address_mem (operands[1], VOIDmode)")
-	 (const_string "load_ux")
-	 (if_then_else
-	   (match_test "update_address_mem (operands[1], VOIDmode)")
-	   (const_string "load_u")
-	   (const_string "load")))
-       (const_string "*")])])
+      [(const_string "load")
+       (if_then_else
+	     (match_test "update_indexed_address_mem (operands[1], VOIDmode)")
+	     (const_string "load_ux")
+	     (if_then_else
+	       (match_test "update_address_mem (operands[1], VOIDmode)")
+	       (const_string "load_u")
+	       (const_string "load")))
+       (const_string "*")
+       (const_string "*")])
+   (set_attr "length" "2,4,2,4")
+   (set_attr "isa" "vle,*,vle,*")])
+
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (zero_extend:SI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 "=r,r"))]
   ""
   "@
-   andi. %2,%1,0xff
+   %^andi. %2,%1,0xff
    #"
   [(set_attr "type" "fast_compare,compare")
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:SI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 ""))]
@@ -914,20 +934,20 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (zero_extend:SI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(zero_extend:SI (match_dup 1)))]
   ""
   "@
-   andi. %0,%1,0xff
+   %^andi. %0,%1,0xff
    #"
   [(set_attr "type" "fast_compare,compare")
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:SI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
@@ -941,14 +961,18 @@
   "")
 
 (define_insn "extendqisi2"
-  [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
-	(sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" "r")))]
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r")
+	(sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" "0,r")))]
   ""
-  "extsb %0,%1"
-  [(set_attr "type" "exts")])
+  "@
+   se_extsb %0
+   extsb %0,%1"
+  [(set_attr "type" "exts")
+   (set_attr "length" "2,4")
+   (set_attr "isa" "vle,*")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 "=r,r"))]
@@ -960,7 +984,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 ""))]
@@ -973,7 +997,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
@@ -986,7 +1010,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (sign_extend:SI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
@@ -999,7 +1023,20 @@
 		    (const_int 0)))]
   "")
 
-(define_insn ""
+ (define_insn ""
+  [(set (match_operand:HI 0 "gpc_reg_operand" "=kregs,r,kregs,r")
+	(zero_extend:HI (match_operand:QI 1 "reg_or_mem_operand" "kmsd4,m,0,r")))]
+   "TARGET_VLE"
+   "@
+   se_lbz %0,%1
+   %e1lbz%U1%X1 %0,%1
+   se_extzb %0
+   %^rlwinm %0,%1,0,0xff"
+  [(set_attr "type" "load,load,*,*")
+   (set_attr "length" "2,4,2,4")
+   (set_attr "isa" "vle,*,vle,*")])
+ 
+ (define_insn ""
   [(set (match_operand:HI 0 "gpc_reg_operand" "=r,r")
 	(zero_extend:HI (match_operand:QI 1 "reg_or_mem_operand" "m,r")))]
   ""
@@ -1017,19 +1054,19 @@
        (const_string "*")])])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (zero_extend:HI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:HI 2 "=r,r"))]
   ""
   "@
-   andi. %2,%1,0xff
+   %^andi. %2,%1,0xff
    #"
   [(set_attr "type" "fast_compare,compare")
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:HI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:HI 2 ""))]
@@ -1042,20 +1079,20 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (zero_extend:HI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:HI 0 "gpc_reg_operand" "=r,r")
 	(zero_extend:HI (match_dup 1)))]
   ""
   "@
-   andi. %0,%1,0xff
+   %^andi. %0,%1,0xff
    #"
   [(set_attr "type" "fast_compare,compare")
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:HI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:HI 0 "gpc_reg_operand" "")
@@ -1076,7 +1113,7 @@
   [(set_attr "type" "exts")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:HI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:HI 2 "=r,r"))]
@@ -1088,7 +1125,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (sign_extend:HI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:HI 2 ""))]
@@ -1101,7 +1138,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:HI (match_operand:QI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:HI 0 "gpc_reg_operand" "=r,r")
@@ -1114,7 +1151,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (sign_extend:HI (match_operand:QI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:HI 0 "gpc_reg_operand" "")
@@ -1134,36 +1171,45 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
-	(zero_extend:SI (match_operand:HI 1 "reg_or_mem_operand" "m,r")))]
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r,kregs,r")
+	(zero_extend:SI (match_operand:HI 1 "reg_or_mem_operand" "kmsd4,m,0,r")))]
   ""
   "@
-   lhz%U1%X1 %0,%1
-   rlwinm %0,%1,0,0xffff"
-  [(set_attr_alternative "type"
-      [(if_then_else
-	 (match_test "update_indexed_address_mem (operands[1], VOIDmode)")
-	 (const_string "load_ux")
-	 (if_then_else
+   se_lhz %0,%1
+   %e1lhz%U1%X1 %0,%1
+   se_extzh %0
+   %^rlwinm %0,%1,0,0xffff"
+  [(set_attr "type" "load,load,*,*")
+   (set_attr "length" "2,4,2,4")
+   (set_attr "isa" "vle,*,vle,*")
+   (set_attr_alternative "type"
+   [(if_then_else
+	(match_test "update_indexed_address_mem (operands[1], VOIDmode)")
+	(const_string "load_ux")
+	(if_then_else
 	   (match_test "update_address_mem (operands[1], VOIDmode)")
 	   (const_string "load_u")
 	   (const_string "load")))
-       (const_string "*")])])
+   (const_string "*")
+   (const_string "*")
+   (const_string "*")])])
 
-(define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
-	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" "r,r"))
+(define_insn "*cmphi_logical_powerpc"
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,?kcrxx")
+	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" "r,r,r"))
 		    (const_int 0)))
-   (clobber (match_scratch:SI 2 "=r,r"))]
+   (clobber (match_scratch:SI 2 "=X,r,r"))]
   ""
   "@
+   e_cmphl16i %1,0
    andi. %2,%1,0xffff
    #"
-  [(set_attr "type" "fast_compare,compare")
-   (set_attr "length" "4,8")])
+  [(set_attr "type" "fast_compare,fast_compare,compare")
+   (set_attr "length" "4,4,8")
+   (set_attr "isa" "vle,novle,*")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 ""))]
@@ -1176,20 +1222,25 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
-	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" "r,r"))
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,x,?kcrxx")
+	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" "0,r,r"))
 		    (const_int 0)))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r")
 	(zero_extend:SI (match_dup 1)))]
   ""
   "@
+   e_and2i. %0,0xffff
    andi. %0,%1,0xffff
    #"
-  [(set_attr "type" "fast_compare,compare")
-   (set_attr "length" "4,8")])
+  [(set_attr "type" "fast_compare,fast_compare,compare")
+   (set_attr "length" "4,4,8")
+   (set_attr "isa" "vle,novle,*")])
 
+;; Need to include cr0 here in the VLE mode to handle the limitation
+;; of e_and2i. capable of operating on the same source and destination
+;; register only.
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_vle_or_not_micro_cr0_operand" "")
 	(compare:CC (zero_extend:SI (match_operand:HI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
@@ -1208,6 +1259,17 @@
   ""
   "")
 
+(define_insn "*extendhisi2_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,kregs,r")
+	(sign_extend:SI (match_operand:HI 1 "reg_or_mem_operand" "m,0,r")))]
+  "TARGET_VLE"
+  "@
+   %e1lha%U1%X1 %0,%1
+   se_extsh %0
+   extsh %0,%1"
+  [(set_attr "type" "load_ext,exts,exts")
+   (set_attr "length" "4,2,4")])
+
 (define_insn ""
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(sign_extend:SI (match_operand:HI 1 "reg_or_mem_operand" "m,r")))]
@@ -1233,7 +1295,7 @@
   [(set_attr "type" "exts")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:SI (match_operand:HI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 "=r,r"))]
@@ -1245,7 +1307,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (sign_extend:SI (match_operand:HI 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 2 ""))]
@@ -1258,7 +1320,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (sign_extend:SI (match_operand:HI 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
@@ -1825,11 +1887,27 @@
 {
   if (<MODE>mode == DImode && ! TARGET_POWERPC64)
     {
-      if (non_short_cint_operand (operands[2], DImode))
+      if (!TARGET_VLE && non_short_cint_operand (operands[2], DImode))
 	FAIL;
+      else if (TARGET_VLE && GET_CODE (operands[2]) == CONST_INT) {
+    	  /* if (satisfies_constraint_ksci8 (operands[2])) {
+			  operands[2] = force_reg (DImode, operands[2]);
+    	  } else */ {
+			  rtx tmp = (!(can_create_pseudo_p () || rtx_equal_p (operands[0], operands[1]))
+						  ? operands[0] : gen_reg_rtx (DImode));
+
+		      emit_move_insn (tmp, operands[2]);
+		      emit_insn (gen_adddi3 (operands[0], operands[1],tmp));
+    	  }
+	  DONE;
+      }
     }
   else if (GET_CODE (operands[2]) == CONST_INT
-	   && ! add_operand (operands[2], <MODE>mode))
+	   && (TARGET_VLE
+	       ? !(vle_add3_operand (operands[2], <MODE>mode)
+		   || (vle_add_operand (operands[2], <MODE>mode)
+		       && rtx_equal_p (operands[0], operands[1])))
+	       : !add_operand (operands[2], <MODE>mode)))
     {
       rtx tmp = ((!can_create_pseudo_p ()
 		  || rtx_equal_p (operands[0], operands[1]))
@@ -1839,18 +1917,46 @@
       HOST_WIDE_INT low = ((val & 0xffff) ^ 0x8000) - 0x8000;
       HOST_WIDE_INT rest = trunc_int_for_mode (val - low, <MODE>mode);
 
-      if (<MODE>mode == DImode && !satisfies_constraint_L (GEN_INT (rest)))
+      rtx opr = GEN_INT (rest);
+      rtx opl = GEN_INT (low);
+
+      if (<MODE>mode == DImode && !satisfies_constraint_L (opr))
 	FAIL;
 
+      if (TARGET_VLE
+	  && !vle_add3_operand (opr, <MODE>mode)
+	  && !(vle_add_operand (opr, <MODE>mode)
+	       && rtx_equal_p (tmp, operands[1])))
+	{
+	  gcc_assert (!rtx_equal_p (tmp, operands[1]));
+	  emit_move_insn (tmp, operands[2]);
+	  emit_insn (gen_add<mode>3 (operands[0], tmp, operands[1]));
+	  DONE;
+	}
+
       /* The ordering here is important for the prolog expander.
 	 When space is allocated from the stack, adding 'low' first may
 	 produce a temporary deallocation (which would be bad).  */
-      emit_insn (gen_add<mode>3 (tmp, operands[1], GEN_INT (rest)));
-      emit_insn (gen_add<mode>3 (operands[0], tmp, GEN_INT (low)));
+      emit_insn (gen_add<mode>3 (tmp, operands[1], opr));
+      emit_insn (gen_add<mode>3 (operands[0], tmp, opl));
       DONE;
     }
 })
 
+(define_insn "*addsi3_vle1"
+  [(set (match_operand: GPR 0 "gpc_reg_operand" "=kregs,kregs,r,r,r,r")
+	(plus:GPR (match_operand:GPR 1 "gpc_reg_operand" "0,0,r,r,0,r")
+		  (match_operand:GPR 2 "vle_add_operand" "koim5,kregs,ksci8,I,L,r")))]
+  "TARGET_VLE"
+  "@
+   se_addi %0,%2
+   se_add %0,%2
+   e_addi %0,%1,%2
+   e_add16i %0,%1,%2
+   e_add2is %0,%v2
+   add %0,%1,%2"
+  [(set_attr "length" "2,2,4,4,4,4")])
+ 
 ;; Discourage ai/addic because of carry but provide it in an alternative
 ;; allowing register zero as source.
 (define_insn "*add<mode>3_internal1"
@@ -1861,9 +1967,10 @@
   "@
    add %0,%1,%2
    addi %0,%1,%2
-   addic %0,%1,%2
+   %^addic %0,%1,%2
    addis %0,%1,%v2"
   [(set_attr "length" "4,4,4,4")
+   (set_attr "isa" "*,*,novle,*")
    (set (attr "type")
         (if_then_else (match_test "rs6000_cpu_attr == CPU_PPCE500MC")
                       (const_string "two") (const_string "*")))])
@@ -1877,22 +1984,27 @@
   [(set_attr "length" "4")])
 
 (define_insn "*add<mode>3_internal2"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y,?y")
-	(compare:CC (plus:P (match_operand:P 1 "gpc_reg_operand" "%r,r,r,r")
-			    (match_operand:P 2 "reg_or_short_operand" "r,I,r,I"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,x,x,?kcrxx,?kcrxx")
+	(compare:CC (plus:P (match_operand:P 1 "gpc_reg_operand" "%r,r,r,r,r,r")
+			    (match_operand:P 2 "reg_or_short_operand" "r,I,I,ksci8,r,I"))
 		    (const_int 0)))
-   (clobber (match_scratch:P 3 "=r,r,r,r"))]
+   (clobber (match_scratch:P 3 "=r,r,1,r,r,r"))]
   ""
   "@
    add. %3,%1,%2
-   addic. %3,%1,%2
+   %^addic. %3,%1,%2
+   e_add2i. %1,%2
+   e_addi. %3,%1,%2
    #
    #"
-  [(set_attr "type" "fast_compare,compare,compare,compare")
-   (set_attr "length" "4,4,8,8")])
+  [(set_attr "type" "fast_compare,compare,compare,compare,compare,compare")
+   (set_attr "length" "4,4,4,4,8,8")
+   (set_attr "isa" "*,novle,vle,vle,*,*")])
 
+;; Need to include cr0 here to handle the limitation of e_add2i. capable
+;; of operating on the same source and destination register only.
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "")
 	(compare:CC (plus:GPR (match_operand:GPR 1 "gpc_reg_operand" "")
 			      (match_operand:GPR 2 "reg_or_short_operand" ""))
 		    (const_int 0)))
@@ -1907,24 +2019,29 @@
   "")
 
 (define_insn "*add<mode>3_internal3"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,?y,?y")
-	(compare:CC (plus:P (match_operand:P 1 "gpc_reg_operand" "%r,r,r,r")
-			    (match_operand:P 2 "reg_or_short_operand" "r,I,r,I"))
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,x,x,?kcrxx,?kcrxx")
+	(compare:CC (plus:P (match_operand:P 1 "gpc_reg_operand" "%r,r,0,r,r,r")
+			    (match_operand:P 2 "reg_or_short_operand" "r,I,I,ksci8,r,I"))
 		    (const_int 0)))
-   (set (match_operand:P 0 "gpc_reg_operand" "=r,r,r,r")
+   (set (match_operand:P 0 "gpc_reg_operand" "=r,r,r,r,r,r")
 	(plus:P (match_dup 1)
 		(match_dup 2)))]
   ""
   "@
    add. %0,%1,%2
-   addic. %0,%1,%2
+   %^addic. %0,%1,%2
+   e_add2i. %0,%2
+   e_addi. %0,%1,%2
    #
    #"
-  [(set_attr "type" "fast_compare,compare,compare,compare")
-   (set_attr "length" "4,4,8,8")])
+  [(set_attr "type" "fast_compare,compare,compare,compare,compare,compare")
+   (set_attr "length" "4,4,4,4,8,8")
+   (set_attr "isa" "*,novle,vle,vle,*,*")])
 
+;; Need to include cr0 here to handle the limitation of e_add2i. capable
+;; of operating on the same source and destination register only.
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "")
 	(compare:CC (plus:P (match_operand:P 1 "gpc_reg_operand" "")
 			    (match_operand:P 2 "reg_or_short_operand" ""))
 		    (const_int 0)))
@@ -1954,10 +2071,26 @@
   HOST_WIDE_INT val = INTVAL (operands[2]);
   HOST_WIDE_INT low = ((val & 0xffff) ^ 0x8000) - 0x8000;
   HOST_WIDE_INT rest = trunc_int_for_mode (val - low, <MODE>mode);
-
-  operands[4] = GEN_INT (low);
-  if (<MODE>mode == SImode || satisfies_constraint_L (GEN_INT (rest)))
-    operands[3] = GEN_INT (rest);
+  rtx opr = GEN_INT (rest);
+  rtx opl = GEN_INT (low);
+
+  operands[4] = opl;
+  if (TARGET_VLE
+      ? (vle_add3_operand (opr, <MODE>mode)
+	 || (vle_add_operand (opr, <MODE>mode)
+	     && rtx_equal_p (operands[0], operands[1])))
+      : (<MODE>mode == SImode || satisfies_constraint_L (opr)))
+    operands[3] = opr;
+  else if (TARGET_VLE
+	   && (<MODE>mode == SImode || satisfies_constraint_L (opr)))
+    {
+      gcc_assert (!rtx_equal_p (operands[0], operands[1]));
+      operands[3] = (can_create_pseudo_p ()
+		     ? gen_reg_rtx (<MODE>mode) : operands[0]);
+      emit_move_insn (operands[3], operands[2]);
+      emit_insn (gen_add<mode>3 (operands[0], operands[1], operands[3]));
+      DONE;
+    }
   else if (can_create_pseudo_p ())
     {
       operands[3] = gen_reg_rtx (DImode);
@@ -1969,6 +2102,34 @@
     FAIL;
 })
 
+(define_split
+  [(set (match_operand:DI 0 "gpc_reg_operand" "")
+	(plus:DI (match_operand:DI 1 "gpc_reg_operand" "")
+		  (match_operand:DI 2 "non_add_cint_operand" "")))]
+  "TARGET_VLE"
+  [(set (match_dup 0) (plus:DI (match_dup 1) (match_dup 3)))
+   (set (match_dup 0) (plus:DI (match_dup 0) (match_dup 4)))]
+{
+  HOST_WIDE_INT val = INTVAL (operands[2]);
+  HOST_WIDE_INT low = ((val & 0xffff) ^ 0x8000) - 0x8000;
+  HOST_WIDE_INT rest = trunc_int_for_mode (val - low, DImode);
+  rtx opr = GEN_INT (rest);
+  rtx opl = GEN_INT (low);
+
+  operands[4] = opl;
+  if (vle_add3_operand (opr, DImode)
+	 || (vle_add_operand (opr, DImode) && rtx_equal_p (operands[0], operands[1])))
+    operands[3] = opr;
+  else
+    {
+      gcc_assert (!rtx_equal_p (operands[0], operands[1]));
+      operands[3] = (can_create_pseudo_p () ? gen_reg_rtx (DImode) : operands[0]);
+      emit_move_insn (operands[3], operands[2]);
+      emit_insn (gen_adddi3 (operands[0], operands[1], operands[3]));
+      DONE;
+    }
+})
+
 (define_expand "one_cmpl<mode>2"
   [(set (match_operand:SDI 0 "gpc_reg_operand" "")
 	(not:SDI (match_operand:SDI 1 "gpc_reg_operand" "")))]
@@ -1982,16 +2143,20 @@
 })
 
 (define_insn "*one_cmpl<mode>2"
-  [(set (match_operand:GPR 0 "gpc_reg_operand" "=r")
-	(not:GPR (match_operand:GPR 1 "gpc_reg_operand" "r")))]
+  [(set (match_operand:GPR 0 "gpc_reg_operand" "=kregs,r")
+	(not:GPR (match_operand:GPR 1 "gpc_reg_operand" "0,r")))]
   ""
-  "nor %0,%1,%1"
-  [(set (attr "type")
-        (if_then_else (match_test "rs6000_cpu_attr == CPU_PPCE500MC")
+  "@
+   se_not %0
+   nor %0,%1,%1"
+  [(set_attr "length" "2,4")
+   (set_attr "isa" "vle,*")
+   (set (attr "type")
+         (if_then_else (match_test "rs6000_cpu_attr == CPU_PPCE500MC")
                       (const_string "two") (const_string "*")))])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (not:P (match_operand:P 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:P 2 "=r,r"))]
@@ -2003,7 +2168,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (not:P (match_operand:P 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:P 2 ""))]
@@ -2016,7 +2181,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (not:P (match_operand:P 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:P 0 "gpc_reg_operand" "=r,r")
@@ -2029,7 +2194,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (not:P (match_operand:P 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:P 0 "gpc_reg_operand" "")
@@ -2042,17 +2207,37 @@
 		    (const_int 0)))]
   "")
 
+(define_insn "*subsi3_vle1"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,kregs,kregs,r,r")
+	(minus:SI (match_operand:SI 1 "vle_sub_operand1" "0,kregs,0,ksci8,r")
+		  (match_operand:SI 2 "vle_sub_operand2" "kregs,0,koim5,r,r")))]
+  "TARGET_VLE"
+  "@
+  se_sub %0, %2
+  se_subf %0, %1
+  se_subi %0, %2
+  e_subfic %0, %2, %1
+  subf %0, %2, %1"
+  [(set_attr "length" "2,2,2,4,4")])
+
+(define_insn ""
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
+	(minus:SI (match_operand:SI 1 "reg_or_short_operand" "rI")
+		  (match_operand:SI 2 "gpc_reg_operand" "r")))]
+  "!TARGET_VLE_POWERPC"
+  "subf%I1c %0,%2,%1")
+
 (define_insn ""
   [(set (match_operand:GPR 0 "gpc_reg_operand" "=r,r")
-	(minus:GPR (match_operand:GPR 1 "reg_or_short_operand" "r,I")
+	(minus:GPR (match_operand:GPR 1 "reg_or_short_operand" "r,kscI8")
 		   (match_operand:GPR 2 "gpc_reg_operand" "r,r")))]
   ""
   "@
    subf %0,%2,%1
-   subfic %0,%2,%1")
+   %^subfic %0,%2,%1")
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?y")
 	(compare:CC (minus:P (match_operand:P 1 "gpc_reg_operand" "r,r")
 			     (match_operand:P 2 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
@@ -2065,7 +2250,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (minus:P (match_operand:P 1 "gpc_reg_operand" "")
 			     (match_operand:P 2 "gpc_reg_operand" ""))
 		    (const_int 0)))
@@ -2080,7 +2265,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (minus:P (match_operand:P 1 "gpc_reg_operand" "r,r")
 			     (match_operand:P 2 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
@@ -2095,7 +2280,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (minus:P (match_operand:P 1 "gpc_reg_operand" "")
 			     (match_operand:P 2 "gpc_reg_operand" ""))
 		    (const_int 0)))
@@ -2124,6 +2309,12 @@
 				 negate_rtx (<MODE>mode, operands[2])));
       DONE;
     }
+  else if (TARGET_VLE)
+    {
+      if (GET_CODE (operands[1]) == CONST_INT
+	  && !satisfies_constraint_ksci8 (operands[1]))
+	operands[1] = force_reg (<MODE>mode, operands[1]);
+    }
 }")
 
 (define_expand "neg<mode>2"
@@ -2133,13 +2324,17 @@
   "")
 
 (define_insn "*neg<mode>2_internal"
-  [(set (match_operand:GPR 0 "gpc_reg_operand" "=r")
-	(neg:GPR (match_operand:GPR 1 "gpc_reg_operand" "r")))]
+  [(set (match_operand:GPR 0 "gpc_reg_operand" "=kregs,r")
+	(neg:GPR (match_operand:GPR 1 "gpc_reg_operand" "0,r")))]
   ""
-  "neg %0,%1")
+  "@
+   se_neg %0
+   neg %0,%1"
+  [(set_attr "length" "2,4")
+   (set_attr "isa" "vle,*")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (neg:P2 (match_operand:P2 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:P2 2 "=r,r"))]
@@ -2151,7 +2346,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (neg:P2 (match_operand:P2 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:P2 2 ""))]
@@ -2164,7 +2359,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 2 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (neg:P2 (match_operand:P2 1 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (set (match_operand:P2 0 "gpc_reg_operand" "=r,r")
@@ -2177,7 +2372,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 2 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 2 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (neg:P2 (match_operand:P2 1 "gpc_reg_operand" ""))
 		    (const_int 0)))
    (set (match_operand:P2 0 "gpc_reg_operand" "")
@@ -2725,11 +2920,38 @@
   DONE;
 }")
 
-(define_insn "mulsi3"
+(define_expand "mulsi3"
+  [(use (match_operand:SI 0 "gpc_reg_operand" ""))
+   (use (match_operand:SI 1 "gpc_reg_operand" ""))
+   (use (match_operand:SI 2 "reg_or_short_operand" ""))]
+  ""
+  "
+{
+  if (TARGET_VLE)
+    emit_insn (gen_mulsi3_vle (operands[0], operands[1], operands[2]));
+  else
+    emit_insn (gen_mulsi3_power (operands[0], operands[1], operands[2]));
+  DONE;
+}")
+
+(define_insn "mulsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r,r,r")
+	(mult:SI (match_operand:SI 1 "gpc_reg_operand" "%0,r,r,0")
+		 (match_operand:SI 2 "reg_or_short_operand" "kregs,r,ksci8,I")))]
+  "TARGET_VLE"
+  "@
+   se_mullw %0,%2
+   mullw %0,%1,%2
+   e_mulli %0,%1,%2
+   e_mull2i %0,%2"
+   [(set_attr "length" "2,4,4,4")
+    (set_attr "type" "imul")])
+
+(define_insn "mulsi3_power"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(mult:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
 		 (match_operand:SI 2 "reg_or_short_operand" "r,I")))]
-  ""
+  "!TARGET_VLE"
   "@
    mullw %0,%1,%2
    mulli %0,%1,%2"
@@ -2741,7 +2963,7 @@
 	(const_string "imul")))])
 
 (define_insn "*mulsi3_internal1"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (mult:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
 			     (match_operand:SI 2 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
@@ -2754,7 +2976,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (mult:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			     (match_operand:SI 2 "gpc_reg_operand" ""))
 		    (const_int 0)))
@@ -2768,7 +2990,7 @@
   "")
 
 (define_insn "*mulsi3_internal2"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (mult:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
 			     (match_operand:SI 2 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
@@ -2782,7 +3004,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (mult:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			     (match_operand:SI 2 "gpc_reg_operand" ""))
 		    (const_int 0)))
@@ -2796,16 +3018,14 @@
 		    (const_int 0)))]
   "")
 
-
 (define_insn "udiv<mode>3"
   [(set (match_operand:GPR 0 "gpc_reg_operand" "=r")
         (udiv:GPR (match_operand:GPR 1 "gpc_reg_operand" "r")
-		  (match_operand:GPR 2 "gpc_reg_operand" "r")))]
+                  (match_operand:GPR 2 "gpc_reg_operand" "r")))]
   ""
   "div<wd>u %0,%1,%2"
    [(set_attr "type" "<idiv_ldiv>")])
 
-
 ;; For powers of two we can do srai/aze for divide and then adjust for
 ;; modulus.  If it isn't a power of two, force operands into register and do
 ;; a normal divide.
@@ -2855,30 +3075,36 @@
 }")
 
 (define_insn ""
-  [(set (match_operand:GPR 0 "gpc_reg_operand" "=r")
-	(div:GPR (match_operand:GPR 1 "gpc_reg_operand" "r")
-		 (match_operand:GPR 2 "exact_log2_cint_operand" "N")))]
+  [(set (match_operand:GPR 0 "gpc_reg_operand" "=kregs,r")
+	(div:GPR (match_operand:GPR 1 "gpc_reg_operand" "0,r")
+		 (match_operand:GPR 2 "exact_log2_cint_operand" "N,N")))]
   ""
-  "sra<wd>i %0,%1,%p2\;addze %0,%0"
+  "@
+   se_sra<wd>i %0,%p2\;addze %0,%0
+   sra<wd>i %0,%1,%p2\;addze %0,%0"
   [(set_attr "type" "two")
-   (set_attr "length" "8")])
+   (set_attr "length" "6,8")
+   (set_attr "isa" "vle,*")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
-	(compare:CC (div:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-			   (match_operand:P 2 "exact_log2_cint_operand" "N,N"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,=x,?kcreg,?kcrxx")
+	(compare:CC (div:P (match_operand:P 1 "gpc_reg_operand" "kregs,r,kregs,r")
+			   (match_operand:P 2 "exact_log2_cint_operand" "N,N,N,N"))
 		    (const_int 0)))
-   (clobber (match_scratch:P 3 "=r,r"))]
+   (clobber (match_scratch:P 3 "=1,r,1,r"))]
   ""
   "@
+   se_sra<wd>i %1,%p2\;addze. %1,%1
    sra<wd>i %3,%1,%p2\;addze. %3,%3
+   #
    #"
   [(set_attr "type" "compare")
-   (set_attr "length" "8,12")
-   (set_attr "cell_micro" "not")])
+   (set_attr "length" "6,8,10,12")
+   (set_attr "cell_micro" "not")
+   (set_attr "isa" "vle,*,vle,*")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (div:GPR (match_operand:GPR 1 "gpc_reg_operand" "")
 			     (match_operand:GPR 2 "exact_log2_cint_operand"
 			      ""))
@@ -2893,22 +3119,25 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
-	(compare:CC (div:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-			   (match_operand:P 2 "exact_log2_cint_operand" "N,N"))
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcreg,?kcrxx")
+	(compare:CC (div:P (match_operand:P 1 "gpc_reg_operand" "0,r,0,r")
+			   (match_operand:P 2 "exact_log2_cint_operand" "N,N,N,N"))
 		    (const_int 0)))
-   (set (match_operand:P 0 "gpc_reg_operand" "=r,r")
+   (set (match_operand:P 0 "gpc_reg_operand" "=kregs,r,kregs,r")
 	(div:P (match_dup 1) (match_dup 2)))]
   ""
   "@
+   se_sra<wd>i %0,%p2\;addze. %0,%0
    sra<wd>i %0,%1,%p2\;addze. %0,%0
+   #
    #"
   [(set_attr "type" "compare")
-   (set_attr "length" "8,12")
-   (set_attr "cell_micro" "not")])
+   (set_attr "length" "6,8,10,12")
+   (set_attr "cell_micro" "not")
+   (set_attr "isa" "vle,*,vle,*")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (div:GPR (match_operand:GPR 1 "gpc_reg_operand" "")
 			     (match_operand:GPR 2 "exact_log2_cint_operand"
 			      ""))
@@ -2922,6 +3151,7 @@
 	(compare:CC (match_dup 0)
 		    (const_int 0)))]
   "")
+
 
 ;; Logical instructions
 ;; The logical instructions are mostly combined by using match_operator,
@@ -2938,12 +3168,65 @@
   ""
   "")
 
+(define_insn "*andsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r,kregs,kregs,r,r,r,r")
+        (and:SI (match_operand:SI 1 "gpc_reg_operand" "%0,r,0,0,r,r,0,0")
+                (match_operand:SI 2 "vle_and_operand" "?kregs,?r,kuim5,kbic5,ksci8,T,K,L")))
+   (clobber (match_scratch:CC 3 "=X,X,X,X,X,X,x,x"))]
+  "TARGET_VLE"
+  "@
+   se_and %0,%2
+   and %0,%1,%2
+   se_andi %0,%2
+   se_bclri %0,%g2
+   e_andi %0,%1,%2
+   e_rlwinm %0,%1,0,%m2,%M2
+   e_and2i. %0,%b2
+   e_and2is. %0,%u2"
+  [(set_attr "length" "2,4,2,2,4,4,4,4")])
+
+(define_insn "*andsi3_vle2"
+  [(set (match_operand:CC 0 "cc_reg_cr0_operand" "=x,x,x,x,x")
+	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "%kregs,r,r,r,r")
+			    (match_operand:SI 2 "vle_andcmp_operand" "?1,?r,K,L,ksci8"))
+		    (const_int 0)))
+   (clobber (match_scratch:SI 3 "=1,r,1,1,r"))
+   (clobber (match_scratch:CC 4 "=X,X,X,X,X"))]
+  "TARGET_VLE"
+  "@
+   se_and. %1,%2
+   and. %3,%1,%2
+   e_and2i. %1,%b2
+   e_and2is. %1,%u2
+   e_andi. %3,%1,%2"
+  [(set_attr "type" "compare,compare,fast_compare,fast_compare,fast_compare")
+   (set_attr "length" "2,4,4,4,4")])
+
+(define_insn "*andsi3_vle3"
+  [(set (match_operand:CC 3 "cc_reg_cr0_operand" "=x,x,x,x,x")
+	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "0,r,r,0,0")
+			    (match_operand:SI 2 "vle_andcmp_operand" "?kregs,?r,ksci8,K,L"))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r,r,r,r")
+	(and:SI (match_dup 1)
+		(match_dup 2)))
+   (clobber (match_scratch:CC 4 "=X,X,X,X,X"))]
+  "TARGET_VLE"
+  "@
+   se_and. %0,%2
+   and. %0,%1,%2
+   e_andi. %0,%1,%2
+   e_and2i. %0,%b2
+   e_and2is. %0,%u2"
+  [(set_attr "type" "compare,compare,fast_compare,fast_compare,fast_compare")
+   (set_attr "length" "2,4,4,4,4")])
+
 (define_insn "andsi3_mc"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
 	(and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r,r")
 		(match_operand:SI 2 "and_operand" "?r,T,K,L")))
    (clobber (match_scratch:CC 3 "=X,X,x,x"))]
-  "rs6000_gen_cell_microcode"
+  "!TARGET_VLE && rs6000_gen_cell_microcode"
   "@
    and %0,%1,%2
    rlwinm %0,%1,0,%m2,%M2
@@ -2956,7 +3239,7 @@
 	(and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
 		(match_operand:SI 2 "and_operand" "?r,T")))
    (clobber (match_scratch:CC 3 "=X,X"))]
-  "!rs6000_gen_cell_microcode"
+  "!TARGET_VLE && !rs6000_gen_cell_microcode"
   "@
    and %0,%1,%2
    rlwinm %0,%1,0,%m2,%M2")
@@ -2965,7 +3248,7 @@
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
         (and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
                 (match_operand:SI 2 "and_operand" "?r,T")))]
-  "!rs6000_gen_cell_microcode"
+  "!TARGET_VLE && !rs6000_gen_cell_microcode"
   "@
    and %0,%1,%2
    rlwinm %0,%1,0,%m2,%M2")
@@ -2976,25 +3259,36 @@
 ;; machines causes an execution serialization
 
 (define_insn "*andsi3_internal2_mc"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,x,?y,??y,??y,?y")
-	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r,r,r,r,r,r")
-			    (match_operand:SI 2 "and_operand" "r,K,L,T,r,K,L,T"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,x,x,x,x,x,?kcreg,?kcrxx,?kcreg,?kcreg,??kcreg,??y,??kcreg,??y,?kcrxx")
+	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r,r,r,r,r,kregs,r,kregs,r,r,r,r,r,r")
+			    (match_operand:SI 2 "and_operand" "r,ksci8,K,K,L,L,T,kregs,r,kuim5,ksci8,K,K,L,L,T"))
 		    (const_int 0)))
-   (clobber (match_scratch:SI 3 "=r,r,r,r,r,r,r,r"))
-   (clobber (match_scratch:CC 4 "=X,X,X,X,X,x,x,X"))]
-  "TARGET_32BIT && rs6000_gen_cell_microcode"
+   (clobber (match_scratch:SI 3 "=r,r,1,r,1,r,r,1,r,1,r,1,r,1,r,r"))
+   (clobber (match_scratch:CC 4 "=X,X,X,X,X,X,X,X,X,X,X,x,x,x,x,X"))]
+  "TARGET_32BIT && !TARGET_VLE && rs6000_gen_cell_microcode"
   "@
    and. %3,%1,%2
+   e_andi. %3,%1,%2
+   e_and2i. %1,%b2
    andi. %3,%1,%b2
+   e_and2is. %1,%u2
    andis. %3,%1,%u2
    rlwinm. %3,%1,0,%m2,%M2
    #
    #
    #
+   #
+   #
+   #
+   #
+   #
    #"
-  [(set_attr "type" "fast_compare,fast_compare,fast_compare,delayed_compare,\
-		     compare,compare,compare,compare")
-   (set_attr "length" "4,4,4,4,8,8,8,8")])
+  [(set_attr "type" "fast_compare,fast_compare,fast_compare,fast_compare,\
+		     fast_compare,fast_compare,delayed_compare,compare,\
+		     compare,compare,compare,compare,compare,compare,compare,\
+		     compare")
+   (set_attr "length" "4,4,4,4,4,4,4,6,8,6,8,8,8,8,8,8")
+   (set_attr "isa" "*,vle,vle,novle,vle,novle,novle,vle,*,vle,vle,vle,novle,vle,novle,*")])
 
 (define_insn "*andsi3_internal3_mc"
   [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,x,?y,??y,??y,?y")
@@ -3018,7 +3312,7 @@
    (set_attr "length" "8,4,4,4,8,8,8,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (and:GPR (match_operand:GPR 1 "gpc_reg_operand" "")
 			     (match_operand:GPR 2 "and_operand" ""))
 		    (const_int 0)))
@@ -3055,27 +3349,38 @@
   "")
 
 (define_insn "*andsi3_internal4"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,x,x,?y,??y,??y,?y")
-	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r,r,r,r,r,r")
-			    (match_operand:SI 2 "and_operand" "r,K,L,T,r,K,L,T"))
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,x,x,x,x,x,?kcreg,?kcrxx,?kcreg,?kcreg,??kcreg,??y,??kcreg,??y,?kcrxx")
+	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,0,r,0,r,r,0,r,0,r,0,r,0,r,r")
+			    (match_operand:SI 2 "and_operand" "r,ksci8,K,K,L,L,T,kregs,r,kuim5,ksci8,K,K,L,L,T"))
 		    (const_int 0)))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r,r,r,r,r")
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r,r,r,r,kregs,r,kregs,r,r,r,r,r,r")
 	(and:SI (match_dup 1)
 		(match_dup 2)))
-   (clobber (match_scratch:CC 4 "=X,X,X,X,X,x,x,X"))]
-  "TARGET_32BIT && rs6000_gen_cell_microcode"
+   (clobber (match_scratch:CC 4 "=X,X,X,X,X,X,X,X,X,X,X,x,x,x,x,X"))]
+  "TARGET_32BIT && !TARGET_VLE && rs6000_gen_cell_microcode"
   "@
    and. %0,%1,%2
+   e_andi. %0,%1,%2
+   e_and2i. %0,%b2
    andi. %0,%1,%b2
+   e_and2is. %0,%u2
    andis. %0,%1,%u2
    rlwinm. %0,%1,0,%m2,%M2
    #
    #
    #
+   #
+   #
+   #
+   #
+   #
    #"
-  [(set_attr "type" "fast_compare,fast_compare,fast_compare,delayed_compare,\
-		     compare,compare,compare,compare")
-   (set_attr "length" "4,4,4,4,8,8,8,8")])
+  [(set_attr "type" "fast_compare,fast_compare,fast_compare,fast_compare,\
+		     fast_compare,fast_compare,delayed_compare,compare,\
+		     compare,compare,compare,compare,compare,compare,compare,\
+		     compare")
+   (set_attr "length" "4,4,4,4,4,4,4,6,8,6,8,8,8,8,8,8")
+   (set_attr "isa" "*,vle,vle,novle,vle,novle,novle,vle,*,vle,vle,vle,novle,vle,novle,*")])
 
 (define_insn "*andsi3_internal5_mc"
   [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,x,x,?y,??y,??y,?y")
@@ -3101,7 +3406,7 @@
    (set_attr "length" "8,4,4,4,8,8,8,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (and:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			    (match_operand:SI 2 "and_operand" ""))
 		    (const_int 0)))
@@ -3191,8 +3496,14 @@
   ""
   "
 {
-  if (GET_CODE (operands[2]) == CONST_INT
-      && ! logical_operand (operands[2], SImode))
+  if (TARGET_VLE)
+    {
+      if ((GET_CODE (operands[2]) == CONST_INT)
+          && (!satisfies_constraint_ksci8 (operands[2])))
+	operands[2] = force_reg (SImode, operands[2]);
+    }
+  else if (GET_CODE (operands[2]) == CONST_INT
+	   && ! logical_operand (operands[2], SImode))
     {
       HOST_WIDE_INT value = INTVAL (operands[2]);
       rtx tmp = ((!can_create_pseudo_p ()
@@ -3206,19 +3517,52 @@
     }
 }")
 
+(define_insn "*andcsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,r")
+	(and:SI (not:SI (match_operand:SI 1 "vle_andc_operand" "kregs,r"))
+	        (match_operand:SI 2 "gpc_reg_operand" "0,r")))]
+  "TARGET_VLE"
+  "@
+   se_andc %0,%1
+   andc %0,%2,%1"
+  [(set_attr "length" "2,4")])
+
+(define_insn "*xorsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
+	(xor:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r")
+	        (match_operand:SI 2 "vle_xor_operand" "ksci8,r")))]
+  "TARGET_VLE"
+  "@
+   e_xori %0,%1,%2
+   xor %0,%1,%2")
+
+(define_insn "*iorsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,kregs,r,r,r,r")
+	(ior:SI (match_operand:SI 1 "gpc_reg_operand" "%0,0,r,0,0,r")
+	        (match_operand:SI 2 "vle_or_operand" "kbit5,kregs,ksci8,K,L,r")))]
+  "TARGET_VLE"
+  "@
+   se_bseti %0,%o2
+   se_or %0,%2
+   e_ori %0,%1,%2
+   e_or2i %0,%2
+   e_or2is %0,%u2
+   or %0,%1,%2"
+  [(set_attr "length" "2,2,4,4,4,4")])
+
 (define_insn "*boolsi3_internal1"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r")
 	(match_operator:SI 3 "boolean_or_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "%r,r,r")
 	  (match_operand:SI 2 "logical_operand" "r,K,L")]))]
-  ""
+  "!TARGET_VLE"
   "@
    %q3 %0,%1,%2
    %q3i %0,%1,%b2
    %q3is %0,%1,%u2")
 
 (define_insn "*boolsi3_internal2"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_or_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "%r,r")
 	  (match_operand:SI 2 "gpc_reg_operand" "r,r")])
@@ -3232,7 +3576,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "")
 	  (match_operand:SI 2 "gpc_reg_operand" "")])
@@ -3246,7 +3590,7 @@
   "")
 
 (define_insn "*boolsi3_internal3"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "%r,r")
 	  (match_operand:SI 2 "gpc_reg_operand" "r,r")])
@@ -3261,7 +3605,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "")
 	  (match_operand:SI 2 "gpc_reg_operand" "")])
@@ -3283,7 +3627,7 @@
 	(match_operator:SI 3 "boolean_or_operator"
 	 [(match_operand:SI 1 "gpc_reg_operand" "")
 	  (match_operand:SI 2 "non_logical_cint_operand" "")]))]
-  ""
+  "!TARGET_VLE"
   [(set (match_dup 0) (match_dup 4))
    (set (match_dup 0) (match_dup 5))]
 "
@@ -3306,7 +3650,7 @@
   "%q3 %0,%2,%1")
 
 (define_insn "*boolcsi3_internal2"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" "r,r"))
 	  (match_operand:SI 2 "gpc_reg_operand" "r,r")])
@@ -3320,7 +3664,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" ""))
 	  (match_operand:SI 2 "gpc_reg_operand" "")])
@@ -3334,7 +3678,7 @@
   "")
 
 (define_insn "*boolcsi3_internal3"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r"))
 	  (match_operand:SI 2 "gpc_reg_operand" "r,r")])
@@ -3349,7 +3693,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" ""))
 	  (match_operand:SI 2 "gpc_reg_operand" "")])
@@ -3372,7 +3716,7 @@
   "%q3 %0,%1,%2")
 
 (define_insn "*boolccsi3_internal2"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" "r,r"))
 	  (not:SI (match_operand:SI 2 "gpc_reg_operand" "r,r"))])
@@ -3386,7 +3730,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" ""))
 	  (not:SI (match_operand:SI 2 "gpc_reg_operand" ""))])
@@ -3400,7 +3744,7 @@
   "")
 
 (define_insn "*boolccsi3_internal3"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r"))
 	  (not:SI (match_operand:SI 2 "gpc_reg_operand" "r,r"))])
@@ -3415,7 +3759,7 @@
    (set_attr "length" "4,8")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (match_operator:SI 4 "boolean_operator"
 	 [(not:SI (match_operand:SI 1 "gpc_reg_operand" ""))
 	  (not:SI (match_operand:SI 2 "gpc_reg_operand" ""))])
@@ -3428,6 +3772,7 @@
 	(compare:CC (match_dup 0)
 		    (const_int 0)))]
   "")
+
 
 ;; Rotate and shift insns, in all their variants.  These support shifts,
 ;; field inserts and extracts, and various combinations thereof.
@@ -3471,7 +3816,7 @@
 
   operands[4] = GEN_INT (32 - start - size);
   operands[1] = GEN_INT (start + size - 1);
-  return \"rlwimi %0,%3,%h4,%h2,%h1\";
+  return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3490,7 +3835,7 @@
 
   operands[4] = GEN_INT (shift - start - size);
   operands[1] = GEN_INT (start + size - 1);
-  return \"rlwimi %0,%3,%h4,%h2,%h1\";
+  return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3509,7 +3854,7 @@
 
   operands[4] = GEN_INT (32 - shift - start - size);
   operands[1] = GEN_INT (start + size - 1);
-  return \"rlwimi %0,%3,%h4,%h2,%h1\";
+  return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3528,7 +3873,7 @@
 
   operands[4] = GEN_INT (32 - shift - start - size);
   operands[1] = GEN_INT (start + size - 1);
-  return \"rlwimi %0,%3,%h4,%h2,%h1\";
+  return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3550,7 +3895,7 @@
 /* Align extract field with insert field */
   operands[5] = GEN_INT (extract_start + extract_size - insert_start - insert_size);
   operands[1] = GEN_INT (insert_start + insert_size - 1);
-  return \"rlwimi %0,%3,%h5,%h2,%h1\";
+  return \"%^rlwimi %0,%3,%h5,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3570,7 +3915,7 @@
  operands[4] = GEN_INT(32 - INTVAL(operands[2]));
  operands[2] = GEN_INT(mb);
  operands[1] = GEN_INT(me);
- return \"rlwimi %0,%3,%h4,%h2,%h1\";
+ return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3589,7 +3934,7 @@
  operands[4] = GEN_INT(32 - INTVAL(operands[2]));
  operands[2] = GEN_INT(mb);
  operands[1] = GEN_INT(me);
- return \"rlwimi %0,%3,%h4,%h2,%h1\";
+ return \"%^rlwimi %0,%3,%h4,%h2,%h1\";
 }"
   [(set_attr "type" "insert_word")])
 
@@ -3688,9 +4033,21 @@
     operands[3] = const0_rtx;
   else
     operands[3] = GEN_INT (start + size);
-  return \"rlwinm %0,%1,%3,%s2,31\";
+  return \"%^rlwinm %0,%1,%3,%s2,31\";
 }")
 
+(define_insn "*extzvsi_vle"
+  [(set (match_operand:CCUNS 0 "cc_reg_cr0_operand" "=x")
+	(compare:CCUNS
+	    (zero_extract:SI (match_operand:SI 1 "gpc_reg_operand" "kregs")
+			     (match_operand:SI 2 "one_constant" "kone1")
+			     (match_operand:SI 3 "const_int_operand" "i"))
+	    (const_int 0)))]
+  "TARGET_VLE"
+  "se_btsti %1,%h3"
+  [(set_attr "type" "fast_compare")
+   (set_attr "length" "2")])
+
 (define_insn "*extzvsi_internal1"
   [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
 	(compare:CC (zero_extract:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
@@ -3698,7 +4055,7 @@
 			 (match_operand:SI 3 "const_int_operand" "i,i"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 4 "=r,r"))]
-  ""
+  "!TARGET_VLE"
   "*
 {
   int start = INTVAL (operands[3]) & 31;
@@ -3757,7 +4114,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(zero_extract:SI (match_dup 1) (match_dup 2) (match_dup 3)))]
-  ""
+  "!TARGET_VLE"
   "*
 {
   int start = INTVAL (operands[3]) & 31;
@@ -3865,14 +4222,17 @@
   [(set_attr "type" "compare")])
 
 (define_insn "rotlsi3"
-  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
-	(rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
-		   (match_operand:SI 2 "reg_or_cint_operand" "r,i")))]
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
+	(rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
+		   (match_operand:SI 2 "reg_or_cint_operand" "r,r,i,i")))]
   ""
   "@
+   e_rlw %0,%1,%2
    rlwnm %0,%1,%2,0xffffffff
+   e_rlwi %0,%1,%h2
    rlwinm %0,%1,%h2,0xffffffff"
-  [(set_attr "type" "var_shift_rotate,integer")])
+  [(set_attr "type" "var_shift_rotate,var_shift_rotate,integer,integer")
+   (set_attr "isa" "vle,novle,vle,novle")])
 
 (define_insn "*rotlsi3_64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=r,r")
@@ -3886,22 +4246,25 @@
   [(set_attr "type" "var_shift_rotate,integer")])
 
 (define_insn "*rotlsi3_internal2"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y,?y")
-	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			       (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,x,x,?kcrxx,?kcrxx")
+	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,r")
+			       (match_operand:SI 2 "reg_or_cint_operand" "r,r,i,i,r,i"))
 		    (const_int 0)))
-   (clobber (match_scratch:SI 3 "=r,r,r,r"))]
+   (clobber (match_scratch:SI 3 "=r,r,r,r,r,r"))]
   ""
   "@
+   e_rlw. %0,%1,%2
    rlwnm. %3,%1,%2,0xffffffff
+   e_rlwi. %0,%1,%h2
    rlwinm. %3,%1,%h2,0xffffffff
    #
    #"
-  [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
-   (set_attr "length" "4,4,8,8")])
+  [(set_attr "type" "var_delayed_compare,var_delayed_compare,delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,4,4,8,8")
+   (set_attr "isa" "vle,novle,vle,novle,*,*")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			       (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
@@ -3915,23 +4278,26 @@
   "")
 
 (define_insn "*rotlsi3_internal3"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,?y,?y")
-	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			       (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,x,x,?kcrxx,?kcrxx")
+	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,r")
+			       (match_operand:SI 2 "reg_or_cint_operand" "r,r,i,i,r,i"))
 		    (const_int 0)))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r,r,r")
 	(rotate:SI (match_dup 1) (match_dup 2)))]
   ""
   "@
+   e_rlw. %0,%1,%2
    rlwnm. %0,%1,%2,0xffffffff
+   e_rlwi. %0,%1,%h2
    rlwinm. %0,%1,%h2,0xffffffff
    #
    #"
-  [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
-   (set_attr "length" "4,4,8,8")])
+  [(set_attr "type" "var_delayed_compare,var_delayed_compare,delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,4,4,8,8")
+   (set_attr "isa" "vle,novle,vle,novle,*,*")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (rotate:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			       (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
@@ -3953,8 +4319,9 @@
   ""
   "@
    rlwnm %0,%1,%2,%m3,%M3
-   rlwinm %0,%1,%h2,%m3,%M3"
-  [(set_attr "type" "var_shift_rotate,integer")])
+   %^rlwinm %0,%1,%h2,%m3,%M3"
+  [(set_attr "type" "var_shift_rotate,integer")
+   (set_attr "isa" "novle,*")])
 
 (define_insn "*rotlsi3_internal5"
   [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y,?y")
@@ -3964,7 +4331,7 @@
 		     (match_operand:SI 3 "mask_operand" "n,n,n,n"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 4 "=r,r,r,r"))]
-  ""
+  "!TARGET_VLE"
   "@
    rlwnm. %4,%1,%2,%m3,%M3
    rlwinm. %4,%1,%h2,%m3,%M3
@@ -3981,7 +4348,7 @@
 		     (match_operand:SI 3 "mask_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 4 ""))]
-  "reload_completed"
+  "!TARGET_VLE && reload_completed"
   [(set (match_dup 4)
 	(and:SI (rotate:SI (match_dup 1)
 				(match_dup 2))
@@ -4000,7 +4367,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
 	(and:SI (rotate:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  ""
+  "!TARGET_VLE"
   "@
    rlwnm. %0,%1,%2,%m3,%M3
    rlwinm. %0,%1,%h2,%m3,%M3
@@ -4018,7 +4385,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(and:SI (rotate:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "reload_completed"
+  "!TARGET_VLE && reload_completed"
   [(set (match_dup 0)
 	(and:SI (rotate:SI (match_dup 1) (match_dup 2)) (match_dup 3)))
    (set (match_dup 4)
@@ -4201,8 +4568,9 @@
   "!BYTES_BIG_ENDIAN"
   "@
    rlwnm %0,%1,%2,0xffff
-   rlwinm %0,%1,%h2,0xffff"
-  [(set_attr "type" "var_shift_rotate,integer")])
+   %^rlwinm %0,%1,%h2,0xffff"
+  [(set_attr "type" "var_shift_rotate,integer")
+   (set_attr "isa" "novle,*")])
 
 (define_insn "*rotlsi3_internal10be"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
@@ -4356,15 +4724,45 @@
 		    (const_int 0)))]
   "")
 
-(define_insn "ashlsi3"
+;; Note that we use "slw." instead of "sl." so that we can set
+;; SHIFT_COUNT_TRUNCATED.
+
+(define_expand "ashlsi3"
+  [(use (match_operand:SI 0 "gpc_reg_operand" ""))
+   (use (match_operand:SI 1 "gpc_reg_operand" ""))
+   (use (match_operand:SI 2 "reg_or_cint_operand" ""))]
+  ""
+  "
+{
+  if (TARGET_POWER_NOVLE)
+    emit_insn (gen_ashlsi3_power (operands[0], operands[1], operands[2]));
+  else
+    emit_insn (gen_ashlsi3_vle (operands[0], operands[1], operands[2]));
+  DONE;
+}")
+
+(define_insn "ashlsi3_power"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(ashift:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
 		   (match_operand:SI 2 "reg_or_cint_operand" "r,i")))]
-  ""
+  "TARGET_POWER_NOVLE"
   "@
    slw %0,%1,%2
-   slwi %0,%1,%h2"
-  [(set_attr "type" "var_shift_rotate,shift")])
+   slwi %0,%1,%h2")
+
+(define_insn "ashlsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,kregs,r,r")
+	(ashift:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,r,r")
+		   (match_operand:SI 2 "reg_or_cint_operand" "kregs,kuim5,r,i")))]
+  "!TARGET_POWER_NOVLE"
+  "@
+   se_slw %0, %2
+   se_slwi %0, %2
+   slw %0,%1,%2
+   %^slwi %0,%1,%h2"
+  [(set_attr "type" "var_shift_rotate,shift,var_shift_rotate,shift")
+   (set_attr "length" "2,2,4,4")
+   (set_attr "isa" "vle,vle,*,*")])
 
 (define_insn "*ashlsi3_64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=r,r")
@@ -4383,7 +4781,7 @@
 			       (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 3 "=r,r,r,r"))]
-  "TARGET_32BIT"
+  "TARGET_POWER_NOVLE"
   "@
    slw. %3,%1,%2
    slwi. %3,%1,%h2
@@ -4398,7 +4796,36 @@
 			       (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 3 ""))]
-  "TARGET_32BIT && reload_completed"
+  "TARGET_POWER_NOVLE && reload_completed"
+  [(set (match_dup 3)
+	(ashift:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+	(compare:CC (match_dup 3)
+		    (const_int 0)))]
+  "")
+
+(define_insn ""
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
+	(compare:CC (ashift:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
+			       (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
+		    (const_int 0)))
+   (clobber (match_scratch:SI 3 "=r,r,r,r"))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT"
+  "@
+   slw. %3,%1,%2
+   %^slwi. %3,%1,%h2
+   #
+   #"
+  [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,8,8")])
+
+(define_split
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
+	(compare:CC (ashift:SI (match_operand:SI 1 "gpc_reg_operand" "")
+			       (match_operand:SI 2 "reg_or_cint_operand" ""))
+		    (const_int 0)))
+   (clobber (match_scratch:SI 3 ""))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT && reload_completed"
   [(set (match_dup 3)
 	(ashift:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 0)
@@ -4413,7 +4840,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
 	(ashift:SI (match_dup 1) (match_dup 2)))]
-  "TARGET_32BIT"
+  "TARGET_POWER_NOVLE"
   "@
    slw. %0,%1,%2
    slwi. %0,%1,%h2
@@ -4428,8 +4855,40 @@
 			       (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
+	(ashift:SI (match_dup 1) (match_dup 2)))
+   ]
+  "TARGET_POWER_NOVLE && reload_completed"
+  [(set (match_dup 0)
+	(ashift:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 3)
+	(compare:CC (match_dup 0)
+		    (const_int 0)))]
+  "")
+
+(define_insn ""
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
+	(compare:CC (ashift:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
+			       (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
+	(ashift:SI (match_dup 1) (match_dup 2)))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT"
+  "@
+   slw. %0,%1,%2
+   %^slwi. %0,%1,%h2
+   #
+   #"
+  [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,8,8")])
+
+(define_split
+  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+	(compare:CC (ashift:SI (match_operand:SI 1 "gpc_reg_operand" "")
+			       (match_operand:SI 2 "reg_or_cint_operand" ""))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(ashift:SI (match_dup 1) (match_dup 2)))]
-  "TARGET_32BIT && reload_completed"
+  "!TARGET_POWER_NOVLE && TARGET_32BIT && reload_completed"
   [(set (match_dup 0)
 	(ashift:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 3)
@@ -4443,7 +4902,7 @@
 			   (match_operand:SI 2 "const_int_operand" "i"))
 		(match_operand:SI 3 "mask_operand" "n")))]
   "includes_lshift_p (operands[2], operands[3])"
-  "rlwinm %0,%1,%h2,%m3,%M3")
+  "%^rlwinm %0,%1,%h2,%m3,%M3")
 
 (define_insn ""
   [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
@@ -4453,7 +4912,7 @@
 		 (match_operand:SI 3 "mask_operand" "n,n"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=r,r"))]
-  "includes_lshift_p (operands[2], operands[3])"
+  "!TARGET_VLE && includes_lshift_p (operands[2], operands[3])"
   "@
    rlwinm. %4,%1,%h2,%m3,%M3
    #"
@@ -4468,7 +4927,8 @@
 		 (match_operand:SI 3 "mask_operand" ""))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 ""))]
-  "includes_lshift_p (operands[2], operands[3]) && reload_completed"
+  "!TARGET_VLE && includes_lshift_p (operands[2], operands[3])
+   && reload_completed"
   [(set (match_dup 4)
 	(and:SI (ashift:SI (match_dup 1) (match_dup 2))
 		 (match_dup 3)))
@@ -4486,7 +4946,7 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(and:SI (ashift:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "includes_lshift_p (operands[2], operands[3])"
+  "!TARGET_VLE && includes_lshift_p (operands[2], operands[3])"
   "@
    rlwinm. %0,%1,%h2,%m3,%M3
    #"
@@ -4502,7 +4962,8 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(and:SI (ashift:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "includes_lshift_p (operands[2], operands[3]) && reload_completed"
+  "!TARGET_VLE && includes_lshift_p (operands[2], operands[3])
+   && reload_completed"
   [(set (match_dup 0)
 	(and:SI (ashift:SI (match_dup 1) (match_dup 2)) (match_dup 3)))
    (set (match_dup 4)
@@ -4510,17 +4971,51 @@
 		    (const_int 0)))]
   "")
 
-(define_insn "lshrsi3"
+;; The AIX assembler mis-handles "sri x,x,0", so write that case as
+;; "sli x,x,0".
+(define_expand "lshrsi3"
+  [(use (match_operand:SI 0 "gpc_reg_operand" ""))
+   (use (match_operand:SI 1 "gpc_reg_operand" ""))
+   (use (match_operand:SI 2 "reg_or_cint_operand" ""))]
+  ""
+  "
+{
+  if (TARGET_POWER_NOVLE)
+    emit_insn (gen_lshrsi3_power (operands[0], operands[1], operands[2]));
+  else
+    emit_insn (gen_lshrsi3_vle (operands[0], operands[1], operands[2]));
+  DONE;
+}")
+
+(define_insn "lshrsi3_power"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r")
 	(lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r")
 		     (match_operand:SI 2 "reg_or_cint_operand" "O,r,i")))]
-  ""
+  "TARGET_POWER_NOVLE"
   "@
   mr %0,%1
   srw %0,%1,%2
   srwi %0,%1,%h2"
   [(set_attr "type" "integer,var_shift_rotate,shift")])
 
+(define_insn "lshrsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,kregs,kareg,r,kregs,kregs,r,r")
+	(lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "kregs,kareg,kregs,r,0,0,r,r")
+		     (match_operand:SI 2 "reg_or_cint_operand" "O,O,O,O,kregs,kuim5,r,i")))]
+  "!TARGET_POWER_NOVLE"
+  "@
+  se_mr %0,%1
+  se_mfar %0,%1
+  se_mtar %0,%1
+  mr %0,%1
+  se_srw %0,%2
+  se_srwi %0,%h2
+  srw %0,%1,%2
+  %^srwi %0,%1,%h2"
+  [(set_attr "type" "integer,integer,integer,integer,var_shift_rotate,shift,var_shift_rotate,shift")
+   (set_attr "length" "2,2,2,4,2,2,4,4")
+   (set_attr "isa" "vle,vle,vle,*,vle,vle,*,*")])
+
 (define_insn "*lshrsi3_64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=r,r")
   	(zero_extend:DI
@@ -4533,29 +5028,33 @@
   [(set_attr "type" "var_shift_rotate,shift")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,?y,?y,?y")
-	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,r")
-				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,r,i"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,x,kcreg,y,?kcreg,?kcrxx,?kcreg,?kcrxx")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,kregs,r,kregs,r")
+				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,O,kregs,r,kuim5,i"))
 		    (const_int 0)))
-   (clobber (match_scratch:SI 3 "=X,r,r,X,r,r"))]
+   (clobber (match_scratch:SI 3 "=X,r,r,X,X,1,r,1,r"))]
   "TARGET_32BIT"
   "@
    mr. %1,%1
    srw. %3,%1,%2
-   srwi. %3,%1,%h2
+   %^srwi. %3,%1,%h2
+   e_cmpi %0,%1,0
+   cmpwi %0,%1,0
+   #
    #
    #
    #"
-  [(set_attr "type" "fast_compare,var_delayed_compare,delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
-   (set_attr "length" "4,4,4,8,8,8")])
+  [(set_attr "type" "fast_compare,var_delayed_compare,delayed_compare,compare,compare,var_delayed_compare,var_delayed_compare,delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,4,4,4,6,8,6,8")
+   (set_attr "isa" "*,*,*,vle,novle,vle,*,vle,*")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
 				 (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 3 ""))]
-  "TARGET_32BIT && reload_completed"
+  "TARGET_POWER_NOVLE && reload_completed"
   [(set (match_dup 3)
 	(lshiftrt:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 0)
@@ -4564,23 +5063,66 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,x,?y,?y,?y")
-	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,r")
-				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,r,i"))
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,x,kcreg,y,?kcreg,?kcrxx,?kcreg,?kcrxx")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r,r,kregs,r,kregs,r")
+				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,O,kregs,r,kuim5,i"))
 		    (const_int 0)))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r,r,r")
+   (clobber (match_scratch:SI 3 "=X,r,r,X,X,1,r,1,r"))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT"
+  "@
+   mr. %1,%1
+   srw. %3,%1,%2
+   %^srwi. %3,%1,%h2
+   e_cmpi %0,%1,0
+   cmpwi %0,%1,0
+   #
+   #
+   #
+   #"
+  [(set_attr "type" "delayed_compare,var_delayed_compare,delayed_compare,compare,compare,var_delayed_compare,var_delayed_compare,delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,4,4,4,6,8,6,8")
+   (set_attr "isa" "*,*,*,vle,novle,vle,*,vle,*")])
+
+(define_split
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
+				 (match_operand:SI 2 "reg_or_cint_operand" ""))
+		    (const_int 0)))
+   (clobber (match_scratch:SI 3 ""))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT && reload_completed"
+  [(set (match_dup 3)
+	(lshiftrt:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 0)
+	(compare:CC (match_dup 3)
+		    (const_int 0)))]
+  "")
+
+(define_insn ""
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,x,?kcreg,?kcreg,?kcrxx,?kcreg,?kcrxx,?kcreg,?kcrxx")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,kregs,kareg,r,0,r,0,r")
+				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,O,O,kregs,r,kuim5,i"))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,kregskareg,kregs,r,kregs,r,kregs,r")
 	(lshiftrt:SI (match_dup 1) (match_dup 2)))]
   "TARGET_32BIT"
   "@
    mr. %0,%1
    srw. %0,%1,%2
-   srwi. %0,%1,%h2
+   %^srwi. %0,%1,%h2
+   #
+   #
+   #
+   #
    #
    #
    #"
-  [(set_attr "type" "fast_compare,var_delayed_compare,delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
-   (set_attr "length" "4,4,4,8,8,8")])
-
+  [(set_attr "type" "fast_compare,var_delayed_compare,delayed_compare,\
+		     delayed_compare,delayed_compare,delayed_compare,\
+		     var_delayed_compare,var_delayed_compare,delayed_compare,\
+		     delayed_compare")
+   (set_attr "length" "4,4,4,6,6,8,6,8,6,8")
+   (set_attr "isa" "*,*,*,vle,vle,*,vle,*,vle,*")])
+ 
 (define_split
   [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
 	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
@@ -4588,7 +5130,48 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(lshiftrt:SI (match_dup 1) (match_dup 2)))]
-  "TARGET_32BIT && reload_completed"
+  "TARGET_POWER_NOVLE && reload_completed"
+  [(set (match_dup 0)
+	(lshiftrt:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 3)
+	(compare:CC (match_dup 0)
+		    (const_int 0)))]
+  "")
+
+(define_insn ""
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,x,?kcreg,?kcreg,?kcrxx,?kcreg,?kcrxx,?kcreg,?kcrxx")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,kregs,kareg,r,0,r,0,r")
+				 (match_operand:SI 2 "reg_or_cint_operand" "O,r,i,O,O,O,kregs,r,kuim5,i"))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,kregskareg,kregs,r,kregs,r,kregs,r")
+	(lshiftrt:SI (match_dup 1) (match_dup 2)))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT"
+  "@
+   mr. %0,%1
+   srw. %0,%1,%2
+   %^srwi. %0,%1,%h2
+   #
+   #
+   #
+   #
+   #
+   #
+   #"
+  [(set_attr "type" "delayed_compare,var_delayed_compare,delayed_compare,\
+		     delayed_compare,delayed_compare,delayed_compare,\
+		     var_delayed_compare,var_delayed_compare,delayed_compare,\
+		     delayed_compare")
+   (set_attr "length" "4,4,4,6,6,8,6,8,6,8")
+   (set_attr "isa" "*,*,*,vle,vle,*,vle,*,vle,*")])
+
+(define_split
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_cr0_operand" "")
+	(compare:CC (lshiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
+				 (match_operand:SI 2 "reg_or_cint_operand" ""))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "")
+	(lshiftrt:SI (match_dup 1) (match_dup 2)))]
+  "!TARGET_POWER_NOVLE && TARGET_32BIT && reload_completed"
   [(set (match_dup 0)
 	(lshiftrt:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 3)
@@ -4602,7 +5185,7 @@
 			     (match_operand:SI 2 "const_int_operand" "i"))
 		(match_operand:SI 3 "mask_operand" "n")))]
   "includes_rshift_p (operands[2], operands[3])"
-  "rlwinm %0,%1,%s2,%m3,%M3")
+  "%^rlwinm %0,%1,%s2,%m3,%M3")
 
 (define_insn ""
   [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
@@ -4612,7 +5195,7 @@
 		 (match_operand:SI 3 "mask_operand" "n,n"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=r,r"))]
-  "includes_rshift_p (operands[2], operands[3])"
+  "!TARGET_VLE && includes_rshift_p (operands[2], operands[3])"
   "@
    rlwinm. %4,%1,%s2,%m3,%M3
    #"
@@ -4627,7 +5210,8 @@
 		 (match_operand:SI 3 "mask_operand" ""))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 ""))]
-  "includes_rshift_p (operands[2], operands[3]) && reload_completed"
+  "!TARGET_VLE && includes_rshift_p (operands[2], operands[3])
+   && reload_completed"
   [(set (match_dup 4)
 	(and:SI (lshiftrt:SI (match_dup 1) (match_dup 2))
 		 (match_dup 3)))
@@ -4645,7 +5229,7 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(and:SI (lshiftrt:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "includes_rshift_p (operands[2], operands[3])"
+  "!TARGET_VLE && includes_rshift_p (operands[2], operands[3])"
   "@
    rlwinm. %0,%1,%s2,%m3,%M3
    #"
@@ -4661,7 +5245,8 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(and:SI (lshiftrt:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "includes_rshift_p (operands[2], operands[3]) && reload_completed"
+  "!TARGET_VLE && includes_rshift_p (operands[2], operands[3])
+   && reload_completed"
   [(set (match_dup 0)
 	(and:SI (lshiftrt:SI (match_dup 1) (match_dup 2)) (match_dup 3)))
    (set (match_dup 4)
@@ -4985,15 +5570,44 @@
 		    (const_int 0)))]
   "")
 
-(define_insn "ashrsi3"
+(define_expand "ashrsi3"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "")
+	(ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
+		     (match_operand:SI 2 "reg_or_cint_operand" "")))]
+  ""
+  "
+{
+  if (TARGET_POWER_NOVLE)
+    emit_insn (gen_ashrsi3_power (operands[0], operands[1], operands[2]));
+  else
+    emit_insn (gen_ashrsi3_vle (operands[0], operands[1], operands[2]));
+  DONE;
+}")
+
+
+(define_insn "ashrsi3_power"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
 		     (match_operand:SI 2 "reg_or_cint_operand" "r,i")))]
-  ""
+  "TARGET_POWER_NOVLE"
   "@
    sraw %0,%1,%2
    srawi %0,%1,%h2"
-  [(set_attr "type" "var_shift_rotate,shift")])
+  [(set_attr "type" "shift")])
+
+(define_insn "ashrsi3_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=kregs,kregs,r,r")
+	(ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,r,r")
+		     (match_operand:SI 2 "reg_or_cint_operand" "kregs,kuim5,r,i")))]
+  "!TARGET_POWER_NOVLE"
+  "@
+   se_sraw %0, %2
+   se_srawi %0, %2
+   sraw %0,%1,%2
+   srawi %0,%1,%h2"
+  [(set_attr "type" "var_shift_rotate,shift,var_shift_rotate,shift")
+   (set_attr "length" "2,2,4,4")
+   (set_attr "isa" "vle,vle,*,*")])
 
 (define_insn "*ashrsi3_64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=r,r")
@@ -5012,7 +5626,7 @@
 				 (match_operand:SI 2 "reg_or_cint_operand" "r,i,r,i"))
 		    (const_int 0)))
    (clobber (match_scratch:SI 3 "=r,r,r,r"))]
-  ""
+  "TARGET_POWER_NOVLE"
   "@
    sraw. %3,%1,%2
    srawi. %3,%1,%h2
@@ -5027,7 +5641,7 @@
 				 (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
    (clobber (match_scratch:SI 3 ""))]
-  "reload_completed"
+  "TARGET_POWER_NOVLE && reload_completed"
   [(set (match_dup 3)
 	(ashiftrt:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 0)
@@ -5042,7 +5656,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,r,r")
 	(ashiftrt:SI (match_dup 1) (match_dup 2)))]
-  ""
+  "TARGET_POWER_NOVLE"
   "@
    sraw. %0,%1,%2
    srawi. %0,%1,%h2
@@ -5050,6 +5664,21 @@
    #"
   [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,delayed_compare")
    (set_attr "length" "4,4,8,8")])
+
+(define_split
+  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+        (compare:CC (ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
+                                 (match_operand:SI 2 "reg_or_cint_operand" ""))
+                    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "")
+        (ashiftrt:SI (match_dup 1) (match_dup 2)))]
+  "TARGET_POWER_NOVLE && reload_completed"
+  [(set (match_dup 0)
+        (ashiftrt:SI (match_dup 1) (match_dup 2)))
+   (set (match_dup 3)
+        (compare:CC (match_dup 0)
+                    (const_int 0)))]
+  "")
 
 ;; Builtins to replace a division to generate FRE reciprocal estimate
 ;; instructions and the necessary fixup instructions
@@ -5090,14 +5719,33 @@
   DONE;
 })
 
+(define_insn ""
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcreg,?kcrxx,?kcreg,?kcrxx")
+	(compare:CC (ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,0,r,0,r")
+				 (match_operand:SI 2 "reg_or_cint_operand" "r,i,kregs,r,kuim5,i"))
+		    (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r,kregs,r,kregs,r")
+	(ashiftrt:SI (match_dup 1) (match_dup 2)))]
+  "!TARGET_POWER_NOVLE"
+  "@
+   sraw. %0,%1,%2
+   srawi. %0,%1,%h2
+   #
+   #
+   #
+   #"
+  [(set_attr "type" "var_delayed_compare,delayed_compare,var_delayed_compare,var_delayed_compare,delayed_compare,delayed_compare")
+   (set_attr "length" "4,4,6,8,6,8")
+   (set_attr "isa" "*,*,vle,*,vle,*")])
+
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC (ashiftrt:SI (match_operand:SI 1 "gpc_reg_operand" "")
 				 (match_operand:SI 2 "reg_or_cint_operand" ""))
 		    (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(ashiftrt:SI (match_dup 1) (match_dup 2)))]
-  "reload_completed"
+  "!TARGET_POWER_NOVLE && reload_completed"
   [(set (match_dup 0)
 	(ashiftrt:SI (match_dup 1) (match_dup 2)))
    (set (match_dup 3)
@@ -6628,14 +7276,14 @@
 (define_insn "*adddi3_noppc64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=&r,&r,r,r")
 	(plus:DI (match_operand:DI 1 "gpc_reg_operand" "%r,r,0,0")
-		 (match_operand:DI 2 "reg_or_short_operand" "r,I,r,I")))]
+		 (match_operand:DI 2 "reg_or_short_operand_vle_sci8" "r,I,r,I")))]
   "! TARGET_POWERPC64"
   "*
 {
   if (WORDS_BIG_ENDIAN)
     return (GET_CODE (operands[2])) != CONST_INT
 	    ? \"addc %L0,%L1,%L2\;adde %0,%1,%2\"
-	    : \"addic %L0,%L1,%2\;add%G2e %0,%1\";
+	    : \"%^addic %L0,%L1,%2\;add%G2e %0,%1\";
   else
     return (GET_CODE (operands[2])) != CONST_INT
 	    ? \"addc %0,%1,%2\;adde %L0,%L1,%L2\"
@@ -6646,7 +7294,7 @@
 
 (define_insn "*subdi3_noppc64"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=&r,&r,r,r,r")
-	(minus:DI (match_operand:DI 1 "reg_or_short_operand" "r,I,0,r,I")
+	(minus:DI (match_operand:DI 1 "reg_or_short_operand_vle_sci8" "r,I,0,r,I")
 		  (match_operand:DI 2 "gpc_reg_operand" "r,r,r,0,0")))]
   "! TARGET_POWERPC64"
   "*
@@ -6654,7 +7302,7 @@
   if (WORDS_BIG_ENDIAN)
     return (GET_CODE (operands[1]) != CONST_INT)
 	    ? \"subfc %L0,%L2,%L1\;subfe %0,%2,%1\"
-	    : \"subfic %L0,%L2,%1\;subf%G1e %0,%2\";
+	    : \"%^subfic %L0,%L2,%1\;subf%G1e %0,%2\";
   else
     return (GET_CODE (operands[1]) != CONST_INT)
 	    ? \"subfc %0,%2,%1\;subfe %L0,%L2,%L1\"
@@ -6670,7 +7318,7 @@
   "*
 {
   return (WORDS_BIG_ENDIAN)
-    ? \"subfic %L0,%L1,0\;subfze %0,%1\"
+    ? \"%^subfic %L0,%L1,0\;subfze %0,%1\"
     : \"subfic %0,%1,0\;subfze %L0,%L1\";
 }"
   [(set_attr "type" "two")
@@ -6678,8 +7326,8 @@
 
 (define_insn "mulsidi3"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=&r")
-	(mult:DI (sign_extend:DI (match_operand:SI 1 "gpc_reg_operand" "%r"))
-		 (sign_extend:DI (match_operand:SI 2 "gpc_reg_operand" "r"))))]
+        (mult:DI (sign_extend:DI (match_operand:SI 1 "gpc_reg_operand" "%r"))
+                 (sign_extend:DI (match_operand:SI 2 "gpc_reg_operand" "r"))))]
   "! TARGET_POWERPC64"
 {
   return (WORDS_BIG_ENDIAN)
@@ -6691,17 +7339,17 @@
 
 (define_split
   [(set (match_operand:DI 0 "gpc_reg_operand" "")
-	(mult:DI (sign_extend:DI (match_operand:SI 1 "gpc_reg_operand" ""))
-		 (sign_extend:DI (match_operand:SI 2 "gpc_reg_operand" ""))))]
+        (mult:DI (sign_extend:DI (match_operand:SI 1 "gpc_reg_operand" ""))
+                 (sign_extend:DI (match_operand:SI 2 "gpc_reg_operand" ""))))]
   "! TARGET_POWERPC64 && reload_completed"
   [(set (match_dup 3)
-	(truncate:SI
-	 (lshiftrt:DI (mult:DI (sign_extend:DI (match_dup 1))
-			       (sign_extend:DI (match_dup 2)))
-		      (const_int 32))))
+        (truncate:SI
+         (lshiftrt:DI (mult:DI (sign_extend:DI (match_dup 1))
+                               (sign_extend:DI (match_dup 2)))
+                      (const_int 32))))
    (set (match_dup 4)
-	(mult:SI (match_dup 1)
-		 (match_dup 2)))]
+        (mult:SI (match_dup 1)
+                 (match_dup 2)))]
   "
 {
   int endian = (WORDS_BIG_ENDIAN == 0);
@@ -6711,8 +7359,8 @@
 
 (define_insn "umulsidi3"
   [(set (match_operand:DI 0 "gpc_reg_operand" "=&r")
-	(mult:DI (zero_extend:DI (match_operand:SI 1 "gpc_reg_operand" "%r"))
-		 (zero_extend:DI (match_operand:SI 2 "gpc_reg_operand" "r"))))]
+        (mult:DI (zero_extend:DI (match_operand:SI 1 "gpc_reg_operand" "%r"))
+                 (zero_extend:DI (match_operand:SI 2 "gpc_reg_operand" "r"))))]
   "! TARGET_POWERPC64"
   "*
 {
@@ -6725,17 +7373,17 @@
 
 (define_split
   [(set (match_operand:DI 0 "gpc_reg_operand" "")
-	(mult:DI (zero_extend:DI (match_operand:SI 1 "gpc_reg_operand" ""))
-		 (zero_extend:DI (match_operand:SI 2 "gpc_reg_operand" ""))))]
+        (mult:DI (zero_extend:DI (match_operand:SI 1 "gpc_reg_operand" ""))
+                 (zero_extend:DI (match_operand:SI 2 "gpc_reg_operand" ""))))]
   "! TARGET_POWERPC64 && reload_completed"
   [(set (match_dup 3)
-	(truncate:SI
-	 (lshiftrt:DI (mult:DI (zero_extend:DI (match_dup 1))
-			       (zero_extend:DI (match_dup 2)))
-		      (const_int 32))))
+        (truncate:SI
+         (lshiftrt:DI (mult:DI (zero_extend:DI (match_dup 1))
+                               (zero_extend:DI (match_dup 2)))
+                      (const_int 32))))
    (set (match_dup 4)
-	(mult:SI (match_dup 1)
-		 (match_dup 2)))]
+        (mult:SI (match_dup 1)
+                 (match_dup 2)))]
   "
 {
   int endian = (WORDS_BIG_ENDIAN == 0);
@@ -6745,24 +7393,24 @@
 
 (define_insn "smulsi3_highpart"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
-	(truncate:SI
-	 (lshiftrt:DI (mult:DI (sign_extend:DI
-				(match_operand:SI 1 "gpc_reg_operand" "%r"))
-			       (sign_extend:DI
-				(match_operand:SI 2 "gpc_reg_operand" "r")))
-		      (const_int 32))))]
+        (truncate:SI
+         (lshiftrt:DI (mult:DI (sign_extend:DI
+                                (match_operand:SI 1 "gpc_reg_operand" "%r"))
+                               (sign_extend:DI
+                                (match_operand:SI 2 "gpc_reg_operand" "r")))
+                      (const_int 32))))]
   ""
   "mulhw %0,%1,%2"
   [(set_attr "type" "imul")])
 
 (define_insn "umulsi3_highpart"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
-	(truncate:SI
-	 (lshiftrt:DI (mult:DI (zero_extend:DI
-				(match_operand:SI 1 "gpc_reg_operand" "%r"))
-			       (zero_extend:DI
-				(match_operand:SI 2 "gpc_reg_operand" "r")))
-		      (const_int 32))))]
+        (truncate:SI
+         (lshiftrt:DI (mult:DI (zero_extend:DI
+                                (match_operand:SI 1 "gpc_reg_operand" "%r"))
+                               (zero_extend:DI
+                                (match_operand:SI 2 "gpc_reg_operand" "r")))
+                      (const_int 32))))]
   ""
   "mulhwu %0,%1,%2"
   [(set_attr "type" "imul")])
@@ -6787,7 +7435,7 @@
         return \"srawi %L0,%L1,31\;srawi %0,%L1,%h2\";
     case 1:
       if (WORDS_BIG_ENDIAN)
-	return \"srwi %L0,%L1,%h2\;insrwi %L0,%1,%h2,0\;srawi %0,%1,%h2\";
+	return \"%^srwi %L0,%L1,%h2\;%^insrwi %L0,%1,%h2,0\;srawi %0,%1,%h2\";
       else
 	return \"srwi %0,%1,%h2\;insrwi %0,%L1,%h2,0\;srawi %L0,%L1,%h2\";
     }
@@ -8863,10 +9511,19 @@
 	(unspec:SI [(match_operand:SI 1 "got_no_const_operand" "")
 		    (match_operand:SI 2 "gpc_reg_operand" "b")]
 		   UNSPEC_MOVSI_GOT))]
-  "DEFAULT_ABI == ABI_V4 && flag_pic == 1"
+  "!TARGET_VLE && DEFAULT_ABI == ABI_V4 && flag_pic == 1"
   "lwz %0,%a1@got(%2)"
   [(set_attr "type" "load")])
 
+(define_insn "*movsi_got_internal"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
+	(unspec:SI [(match_operand:SI 1 "got_no_const_operand" "")
+		    (match_operand:SI 2 "gpc_reg_operand" "b")]
+		   UNSPEC_MOVSI_GOT))]
+  "TARGET_VLE && DEFAULT_ABI == ABI_V4 && flag_pic == 1"
+  "e_lwz %0,%a1@got(%2)"
+  [(set_attr "type" "load")])
+
 ;; Used by sched, shorten_branches and final when the GOT pseudo reg
 ;; didn't get allocated to a hard register.
 (define_split
@@ -8882,6 +9539,84 @@
 				 UNSPEC_MOVSI_GOT))]
   "")
 
+(define_insn "*movsi_vle"
+  [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "=kregs,kareg,kregs,r,cl,kregs,?cl,?r,kregs,r,kmsd4,m,kregs,kregs,kregs,r,r,r,r")
+	(match_operand:SI 1 "input_operand" "kregs,kregs,kareg,r,kregs,cl,r,cl,kmsd4,m,kregs,r,kuim7,kbit5,kmsk5,kli20,L,K,n"))]
+  "TARGET_VLE
+   && (gpc_reg_operand (operands[0], SImode)
+       || gpc_reg_operand (operands[1], SImode))"
+  "@
+   se_mr %0,%1
+   se_mtar %0,%1
+   se_mfar %0,%1
+   mr %0,%1
+   se_mt%0 %1
+   se_mf%1 %0
+   mt%0 %1
+   mf%1 %0
+   se_lwz %0,%1
+   %e1lwz%U1%X1 %0,%1
+   se_stw %1,%0
+   %e0stw%U0%X0 %1,%0
+   se_li %0,%1
+   se_bgeni %0,%o1
+   se_bmaski %0,%r1
+   e_li %0,%1
+   e_lis %0,%v1
+   e_li %0,%u1
+   #"
+  [(set_attr "length" "2,2,2,4,2,2,4,4,2,4,2,4,2,2,2,4,4,4,4")])
+
+(define_insn "*movhi_vle"
+  [(set (match_operand:HI 0 "nonimmediate_operand" "=kregs,kareg,kregs,r,cl,kregs,?cl,?r,kregs,r,kmsd4,m,kregs,kregs,kregs,r")
+	(match_operand:HI 1 "input_operand" "kregs,kregs,kareg,r,kregs,cl,r,cl,kmsd4,m,kregs,r,kuim7,kbit5,kmsk5,i"))]
+  "TARGET_VLE
+   && (gpc_reg_operand (operands[0], HImode)
+       || gpc_reg_operand (operands[1], HImode))"
+  "@
+   se_mr %0,%1
+   se_mtar %0,%1
+   se_mfar %0,%1
+   mr %0,%1
+   se_mt%0 %1
+   se_mf%1 %0
+   mt%0 %1
+   mf%1 %0
+   se_lhz %0,%1
+   %e1lhz%U1%X1 %0,%1
+   se_sth %1,%0
+   %e0sth%U0%X0 %1,%0
+   se_li %0,%1
+   se_bgeni %0,%o1
+   se_bmaski %0,%r1
+   e_li %0,%1"
+  [(set_attr "length" "2,2,2,4,2,2,4,4,2,4,2,4,2,2,2,4")])
+
+(define_insn "*movqi_vle"
+  [(set (match_operand:QI 0 "nonimmediate_operand" "=kregs,kareg,kregs,r,cl,kregs,?cl,?r,kregs,r,kmsd4,m,kregs,kregs,kregs,r")
+	(match_operand:QI 1 "input_operand" "kregs,kregs,kareg,r,kregs,cl,r,cl,kmsd4,m,kregs,r,kuim7,kbit5,kmsk5,i"))]
+  "TARGET_VLE
+   && (gpc_reg_operand (operands[0], QImode)
+       || gpc_reg_operand (operands[1], QImode))"
+  "@
+   se_mr %0,%1
+   se_mtar %0,%1
+   se_mfar %0,%1
+   mr %0,%1
+   se_mt%0 %1
+   se_mf%1 %0
+   mt%0 %1
+   mf%1 %0
+   se_lbz %0,%1
+   %e1lbz%U1%X1 %0,%1
+   se_stb %1,%0
+   %e0stb%U0%X0 %1,%0
+   se_li %0,%1
+   se_bgeni %0,%o1
+   se_bmaski %0,%r1
+   e_li %0,%1"
+  [(set_attr "length" "2,2,2,4,2,2,4,4,2,4,2,4,2,2,2,4")])
+
 ;; For SI, we special-case integers that can't be loaded in one insn.  We
 ;; do the load 16-bits at a time.  We could do this by loading from memory,
 ;; and this is even supposed to be faster, but it is simpler not to get
@@ -8896,8 +9631,8 @@
    (set_attr "length" "4")])
 
 (define_insn "*movsi_internal1"
-  [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "=r,r,r,m,r,r,r,r,*c*l,*h,*h")
-	(match_operand:SI 1 "input_operand" "r,U,m,r,I,L,n,*h,r,r,0"))]
+  [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "=r,r,r,m,r,r,r,r,r,*c*l,*h,*h")
+	(match_operand:SI 1 "input_operand" "r,U,m,r,I,L,n,R,*h,r,r,0"))]
   "!TARGET_SINGLE_FPU &&
    (gpc_reg_operand (operands[0], SImode) || gpc_reg_operand (operands[1], SImode))"
   "@
@@ -8908,6 +9643,7 @@
    li %0,%1
    lis %0,%v1
    #
+   la %0,%a1
    mf%1 %0
    mt%0 %1
    mt%0 %1
@@ -8932,16 +9668,17 @@
        (const_string "*")
        (const_string "*")
        (const_string "*")
+       (const_string "*")
        (const_string "mfjmpr")
        (const_string "mtjmpr")
        (const_string "*")
        (const_string "*")])
 
-   (set_attr "length" "4,4,4,4,4,4,8,4,4,4,4")])
+   (set_attr "length" "4,4,4,4,4,4,4,8,4,4,4,4")])
 
 (define_insn "*movsi_internal1_single"
-  [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "=r,r,r,m,r,r,r,r,*c*l,*h,*h,m,*f")
-        (match_operand:SI 1 "input_operand" "r,U,m,r,I,L,n,*h,r,r,0,f,m"))]
+  [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "=r,r,r,m,r,r,r,r,r,*c*l,*h,*h,m,*f")
+        (match_operand:SI 1 "input_operand" "r,U,m,r,I,L,n,R,*h,r,r,0,f,m"))]
   "TARGET_SINGLE_FPU &&
    (gpc_reg_operand (operands[0], SImode) || gpc_reg_operand (operands[1], SImode))"
   "@
@@ -8951,7 +9688,8 @@
    stw%U0%X0 %1,%0
    li %0,%1
    lis %0,%v1
-   #
+   nop
+   la %0,%a1
    mf%1 %0
    mt%0 %1
    mt%0 %1
@@ -8978,9 +9716,10 @@
        (const_string "*")
        (const_string "*")
        (const_string "*")
+       (const_string "*")
        (const_string "mfjmpr")
        (const_string "mtjmpr")
-       (const_string "*")
+       (const_string "mtjmpr")
        (const_string "*")
        (if_then_else
 	 (match_test "update_indexed_address_mem (operands[0], VOIDmode)")
@@ -8996,7 +9735,7 @@
 	   (match_test "update_address_mem (operands[1], VOIDmode)")
 	   (const_string "fpload_u")
 	   (const_string "fpload")))])
-   (set_attr "length" "4,4,4,4,4,4,8,4,4,4,4,4,4")])
+   (set_attr "length" "4,4,4,4,4,4,4,8,4,4,4,4,4,4")])
 
 ;; Split a load of a large constant into the appropriate two-insn
 ;; sequence.
@@ -9005,7 +9744,12 @@
   [(set (match_operand:SI 0 "gpc_reg_operand" "")
 	(match_operand:SI 1 "const_int_operand" ""))]
   "(unsigned HOST_WIDE_INT) (INTVAL (operands[1]) + 0x8000) >= 0x10000
-   && (INTVAL (operands[1]) & 0xffff) != 0"
+   && (INTVAL (operands[1]) & 0xffff) != 0
+   && !(TARGET_VLE
+	&& vle_reg_operand (operands[0], SImode)
+	&& (satisfies_constraint_kbit5 (operands[1])
+	    || satisfies_constraint_kmsk5 (operands[1])
+	    || satisfies_constraint_kli20 (operands[1])))"
   [(set (match_dup 0)
 	(match_dup 2))
    (set (match_dup 0)
@@ -9020,12 +9764,22 @@
     FAIL;
 }")
 
+(define_insn "*movsi_vle2"
+  [(set (match_operand:CC 2 "cc_reg_cr0_operand" "=x")
+	(compare:CC (match_operand:P 1 "vle_reg_operand" "0")
+		    (const_int 0)))
+   (set (match_operand:P 0 "vle_reg_operand" "=kregs") (match_dup 1))]
+  "TARGET_VLE"
+  "se_cmpi %1,0"
+  [(set_attr "type" "cmp")
+   (set_attr "length" "2")])
+
 (define_insn "*mov<mode>_internal2"
   [(set (match_operand:CC 2 "cc_reg_operand" "=y,x,?y")
 	(compare:CC (match_operand:P 1 "gpc_reg_operand" "0,r,r")
 		    (const_int 0)))
    (set (match_operand:P 0 "gpc_reg_operand" "=r,r,r") (match_dup 1))]
-  ""
+  "!TARGET_VLE"
   "@
    cmp<wd>i %2,%0,0
    mr. %0,%1
@@ -9052,8 +9806,8 @@
    || gpc_reg_operand (operands[1], HImode)"
   "@
    mr %0,%1
-   lhz%U1%X1 %0,%1
-   sth%U0%X0 %1,%0
+   %e1lhz%U1%X1 %0,%1
+   %e0sth%U0%X0 %1,%0
    li %0,%w1
    mf%1 %0
    mt%0 %1
@@ -9092,8 +9846,8 @@
    || gpc_reg_operand (operands[1], QImode)"
   "@
    mr %0,%1
-   lbz%U1%X1 %0,%1
-   stb%U0%X0 %1,%0
+   %e1lbz%U1%X1 %0,%1
+   %e0stb%U0%X0 %1,%0
    li %0,%1
    mf%1 %0
    mt%0 %1
@@ -9128,6 +9882,48 @@
   ""
   "")
 
+(define_insn "*movcc_vle"
+  [(set (match_operand:CC 0 "nonimmediate_operand" "=y,x,?y,y,r,r,kregs,kareg,kregs,r,?r,?cl,r,m")
+	(match_operand:CC 1 "general_operand" "y,r,r,O,x,y,kregs,kregs,kareg,I,cl,r,m,r"))]
+  "TARGET_VLE
+   && (register_operand (operands[0], CCmode)
+       || register_operand (operands[1], CCmode))"
+  "@
+   e_mcrf %0,%1
+   mtcrf 128,%1
+   e_rlwinm %1,%1,%F0,0xffffffff\;mtcrf %R0,%1\;e_rlwinm %1,%1,%f0,0xffffffff
+   e_crxor %0,%0,%0
+   mfcr %0%Q1
+   mfcr %0%Q1\;e_rlwinm %0,%0,%f1,0xf0000000
+   se_mr %0,%1
+   se_mtar %0, %1
+   se_mfar %0, %1
+   e_li %0,%1
+   mf%1 %0
+   mt%0 %1
+   %e1lwz%U1%X1 %0,%1
+   %e0stw%U0%U1 %1,%0"
+  [(set (attr "type")
+     (cond [(eq_attr "alternative" "0,3")
+		(const_string "cr_logical")
+	    (eq_attr "alternative" "1,2")
+		(const_string "mtcr")
+	    (eq_attr "alternative" "6,7,8,9")
+		(const_string "integer")
+	    (eq_attr "alternative" "10")
+		(const_string "mfjmpr")
+	    (eq_attr "alternative" "11")
+		(const_string "mtjmpr")
+	    (eq_attr "alternative" "12")
+		(const_string "load")
+	    (eq_attr "alternative" "13")
+		(const_string "store")
+	    (ne (symbol_ref "TARGET_MFCRF") (const_int 0))
+		(const_string "mfcrf")
+	   ]
+	(const_string "mfcr")))
+   (set_attr "length" "4,4,12,4,4,8,2,2,2,4,4,4,4,4")])
+
 (define_insn "*movcc_internal1"
   [(set (match_operand:CC 0 "nonimmediate_operand" "=y,x,?y,y,r,r,r,r,r,cl,r,m")
 	(match_operand:CC 1 "general_operand" "y,r,r,O,x,y,r,I,h,r,m,r"))]
@@ -9287,6 +10083,30 @@
        (const_string "*")])
    (set_attr "length" "4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,8")])
 
+(define_insn "*movsf_softfloat_vle"
+  [(set (match_operand:SF 0 "nonimmediate_operand" "=kregs,kareg,kregs,r,kregs,cl,cl,r,r,m,r,r,*cl,r,r")
+		(match_operand:SF 1 "input_operand" "kregs,kregs,kareg,r,cl,kregs,r,cl,m,r,kli20,L,0,G,Fn"))]
+  "(gpc_reg_operand (operands[0], SFmode)
+   || gpc_reg_operand (operands[1], SFmode))
+   && (TARGET_VLE && (TARGET_SOFT_FLOAT || !TARGET_FPRS))"
+  "@
+   se_mr %0,%1
+   se_mtar %0,%1
+   se_mfar %0,%1
+   mr %0,%1
+   se_mf%1 %0
+   se_mt%0 %1
+   mt%0 %1
+   mf%1 %0
+   %e1lwz%U1%X1 %0,%1
+   %e0stw%U0%X0 %1,%0
+   e_li %0,%1
+   e_lis %0,%1
+   se_nop
+   #
+   #"
+  [(set_attr "length" "2,2,2,4,2,2,4,4,4,4,4,4,2,4,8")])
+
 (define_insn "*mov<mode>_softfloat"
   [(set (match_operand:FMOVE32 0 "nonimmediate_operand" "=r,cl,r,r,m,r,r,r,r,*h")
 	(match_operand:FMOVE32 1 "input_operand" "r,r,h,m,r,I,L,G,Fn,0"))]
@@ -11036,18 +11856,20 @@
   [(set_attr "type" "store_ux,store_u")])
 
 (define_insn "*movsi_update1"
-  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r")
-	(mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I"))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r,r")
+	(mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I"))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lwzux %3,%0,%2
+   e_lwzu %3,%2(%0)
    lwzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movsi_update2"
   [(set (match_operand:DI 3 "gpc_reg_operand" "=r")
@@ -11062,10 +11884,10 @@
   [(set_attr "type" "load_ext_ux")])
 
 (define_insn "movsi_update"
-  [(set (mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I")))
-	(match_operand:SI 3 "gpc_reg_operand" "r,r"))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))
+	(match_operand:SI 3 "gpc_reg_operand" "r,r,r"))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
@@ -11074,123 +11896,142 @@
 	   && REGNO (operands[0]) == STACK_POINTER_REGNUM))"
   "@
    stwux %3,%0,%2
+   e_stwu %3,%2(%0)
    stwu %3,%2(%0)"
-  [(set_attr "type" "store_ux,store_u")])
+  [(set_attr "type" "store_ux,store_u,store_u")
+   (set_attr "isa" "*,vle,novle")])
 
 ;; This is an unconditional pattern; needed for stack allocation, even
 ;; if the user passes -mno-update.
 (define_insn "movsi_update_stack"
-  [(set (mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I")))
-	(match_operand:SI 3 "gpc_reg_operand" "r,r"))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (mem:SI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))
+	(match_operand:SI 3 "gpc_reg_operand" "r,r,r"))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   ""
   "@
    stwux %3,%0,%2
+   e_stwu %3,%2(%0)
    stwu %3,%2(%0)"
-  [(set_attr "type" "store_ux,store_u")])
+  [(set_attr "type" "store_ux,store_u,store_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movhi_update1"
-  [(set (match_operand:HI 3 "gpc_reg_operand" "=r,r")
-	(mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I"))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (match_operand:HI 3 "gpc_reg_operand" "=r,r,r")
+	(mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I"))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lhzux %3,%0,%2
+   e_lhzu %3,%2(%0)
    lhzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movhi_update2"
-  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r")
+  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r,r")
 	(zero_extend:SI
-	 (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			  (match_operand:SI 2 "reg_or_short_operand" "r,I")))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+	 (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			  (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lhzux %3,%0,%2
+   e_lhzu %3,%2(%0)
    lhzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movhi_update3"
-  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r")
+  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r,r")
 	(sign_extend:SI
-	 (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			  (match_operand:SI 2 "reg_or_short_operand" "r,I")))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+	 (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			  (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE && rs6000_gen_cell_microcode
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lhaux %3,%0,%2
+   e_lhau %3,%2(%0)
    lhau %3,%2(%0)"
-  [(set_attr "type" "load_ext_ux,load_ext_u")])
+  [(set_attr "type" "load_ext_ux,load_ext_u,load_ext_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movhi_update4"
-  [(set (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I")))
-	(match_operand:HI 3 "gpc_reg_operand" "r,r"))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (mem:HI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))
+	(match_operand:HI 3 "gpc_reg_operand" "r,r,r"))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
-  "TARGET_UPDATE
+  "!TARGET_VLE
+   && TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    sthux %3,%0,%2
+   e_sthu %3,%2(%0)
    sthu %3,%2(%0)"
-  [(set_attr "type" "store_ux,store_u")])
+  [(set_attr "type" "store_ux,store_u,store_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movqi_update1"
-  [(set (match_operand:QI 3 "gpc_reg_operand" "=r,r")
-	(mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I"))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (match_operand:QI 3 "gpc_reg_operand" "=r,r,r")
+	(mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I"))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lbzux %3,%0,%2
+   e_lbzu %3,%2(%0)
    lbzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movqi_update2"
-  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r")
+  [(set (match_operand:SI 3 "gpc_reg_operand" "=r,r,r")
 	(zero_extend:SI
-	 (mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			  (match_operand:SI 2 "reg_or_short_operand" "r,I")))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+	 (mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			  (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lbzux %3,%0,%2
+   e_lbzu %3,%2(%0)
    lbzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movqi_update3"
-  [(set (mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I")))
-	(match_operand:QI 3 "gpc_reg_operand" "r,r"))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (mem:QI (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))
+	(match_operand:QI 3 "gpc_reg_operand" "r,r,r"))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    stbux %3,%0,%2
+   e_stbu %3,%2(%0)
    stbu %3,%2(%0)"
-  [(set_attr "type" "store_ux,store_u")])
+  [(set_attr "type" "store_ux,store_u,store_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movsf_update1"
   [(set (match_operand:SF 3 "gpc_reg_operand" "=f,f")
@@ -11221,32 +12062,36 @@
   [(set_attr "type" "fpstore_ux,fpstore_u")])
 
 (define_insn "*movsf_update3"
-  [(set (match_operand:SF 3 "gpc_reg_operand" "=r,r")
-	(mem:SF (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I"))))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (match_operand:SF 3 "gpc_reg_operand" "=r,r,r")
+	(mem:SF (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,r")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I"))))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "(TARGET_SOFT_FLOAT || !TARGET_FPRS) && TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    lwzux %3,%0,%2
+   e_lwzu %3,%2(%0)
    lwzu %3,%2(%0)"
-  [(set_attr "type" "load_ux,load_u")])
+  [(set_attr "type" "load_ux,load_u,load_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movsf_update4"
-  [(set (mem:SF (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0")
-			 (match_operand:SI 2 "reg_or_short_operand" "r,I")))
-	(match_operand:SF 3 "gpc_reg_operand" "r,r"))
-   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b")
+  [(set (mem:SF (plus:SI (match_operand:SI 1 "gpc_reg_operand" "0,0,0")
+			 (match_operand:SI 2 "reg_or_short_operand" "r,kmmd8,I")))
+	(match_operand:SF 3 "gpc_reg_operand" "r,r,r"))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=b,b,b")
 	(plus:SI (match_dup 1) (match_dup 2)))]
   "(TARGET_SOFT_FLOAT || !TARGET_FPRS) && TARGET_UPDATE
    && (!avoiding_indexed_address_p (SImode)
        || !gpc_reg_operand (operands[2], SImode))"
   "@
    stwux %3,%0,%2
+   e_stwu %3,%2(%0)
    stwu %3,%2(%0)"
-  [(set_attr "type" "store_ux,store_u")])
+  [(set_attr "type" "store_ux,store_u,store_u")
+   (set_attr "isa" "*,vle,novle")])
 
 (define_insn "*movdf_update1"
   [(set (match_operand:DF 3 "gpc_reg_operand" "=d,d")
@@ -11683,12 +12528,14 @@
 ;; optimization.  The linker may edit the instructions emitted by a
 ;; tls_got_tprel/tls_tls pair to addis,addi.
 (define_insn_and_split "tls_got_tprel_<TLSmode:tls_abi_suffix>"
-  [(set (match_operand:TLSmode 0 "gpc_reg_operand" "=b")
-	(unspec:TLSmode [(match_operand:TLSmode 1 "gpc_reg_operand" "b")
+  [(set (match_operand:TLSmode 0 "gpc_reg_operand" "=b,b")
+	(unspec:TLSmode [(match_operand:TLSmode 1 "gpc_reg_operand" "b,b")
 			 (match_operand:TLSmode 2 "rs6000_tls_symbol_ref" "")]
 			UNSPEC_TLSGOTTPREL))]
   "HAVE_AS_TLS"
-  "l<TLSmode:tls_insn_suffix> %0,%2@got@tprel(%1)"
+  "@
+   l<TLSmode:tls_insn_suffix> %0,%2@got@tprel(%1)
+   e_l<TLSmode:tls_insn_suffix> %0,%2@got@tprel(%1)"
   "&& TARGET_CMODEL != CMODEL_SMALL"
   [(set (match_dup 3)
 	(high:TLSmode
@@ -11700,7 +12547,8 @@
 {
   operands[3] = gen_reg_rtx (TARGET_64BIT ? DImode : SImode);
 }"
-  [(set (attr "length")
+  [(set_attr "isa" "novle,vle")
+   (set (attr "length")
      (if_then_else (ne (symbol_ref "TARGET_CMODEL") (symbol_ref "CMODEL_SMALL"))
      		   (const_int 8)
      		   (const_int 4)))])
@@ -11716,14 +12564,17 @@
   [(set_attr "length" "4")])
 
 (define_insn "*tls_got_tprel_low<TLSmode:tls_abi_suffix>"
-  [(set (match_operand:TLSmode 0 "gpc_reg_operand" "=r")
-     (lo_sum:TLSmode (match_operand:TLSmode 1 "gpc_reg_operand" "b")
-	 (unspec:TLSmode [(match_operand:TLSmode 3 "gpc_reg_operand" "b")
+  [(set (match_operand:TLSmode 0 "gpc_reg_operand" "=r,r")
+     (lo_sum:TLSmode (match_operand:TLSmode 1 "gpc_reg_operand" "b,b")
+	 (unspec:TLSmode [(match_operand:TLSmode 3 "gpc_reg_operand" "b,b")
 			  (match_operand:TLSmode 2 "rs6000_tls_symbol_ref" "")]
 			 UNSPEC_TLSGOTTPREL)))]
   "HAVE_AS_TLS && TARGET_CMODEL != CMODEL_SMALL"
-  "l<TLSmode:tls_insn_suffix> %0,%2@got@tprel@l(%1)"
-  [(set_attr "length" "4")])
+  "@
+   l<TLSmode:tls_insn_suffix> %0,%2@got@tprel@l(%1)
+   e_l<TLSmode:tls_insn_suffix> %0,%2@got@tprel@l(%1)"
+  [(set_attr "length" "4,4")
+   (set_attr "isa" "novle,vle")])
 
 (define_insn "tls_tls_<TLSmode:tls_abi_suffix>"
   [(set (match_operand:TLSmode 0 "gpc_reg_operand" "=r")
@@ -11972,7 +12823,7 @@
   [(set (reg:SI LR_REGNO)
 	(unspec:SI [(const_int 0)] UNSPEC_TOC))]
   "DEFAULT_ABI == ABI_V4 && flag_pic == 1 && TARGET_32BIT"
-  "bl _GLOBAL_OFFSET_TABLE_@local-4"
+  "%^bl _GLOBAL_OFFSET_TABLE_@local-4"
   [(set_attr "type" "branch")
    (set_attr "length" "4")])
 
@@ -11986,13 +12837,16 @@
 
 (define_insn "load_toc_v4_PIC_1_normal"
   [(set (reg:SI LR_REGNO)
-	(match_operand:SI 0 "immediate_operand" "s"))
+	(match_operand:SI 0 "immediate_operand" "s,s"))
    (use (unspec [(match_dup 0)] UNSPEC_TOC))]
   "!TARGET_LINK_STACK && TARGET_ELF && DEFAULT_ABI == ABI_V4
    && (flag_pic == 2 || (flag_pic && TARGET_SECURE_PLT))"
-  "bcl 20,31,%0\\n%0:"
+  "@
+   bcl 20,31,%0\\n%0:
+   e_bl %0\\n%0:"
   [(set_attr "type" "branch")
-   (set_attr "length" "4")])
+   (set_attr "isa" "novle,vle")
+   (set_attr "length" "4,4")])
 
 (define_insn "load_toc_v4_PIC_1_476"
   [(set (reg:SI LR_REGNO)
@@ -12023,14 +12877,17 @@
 
 (define_insn "load_toc_v4_PIC_1b_normal"
   [(set (reg:SI LR_REGNO)
-	(unspec:SI [(match_operand:SI 0 "immediate_operand" "s")
+	(unspec:SI [(match_operand:SI 0 "immediate_operand" "s,s")
 		    (label_ref (match_operand 1 "" ""))]
 		UNSPEC_TOCPTR))
    (match_dup 1)]
   "!TARGET_LINK_STACK && TARGET_ELF && DEFAULT_ABI == ABI_V4 && flag_pic == 2"
-  "bcl 20,31,$+8\;.long %0-$"
+  "@
+   bcl 20,31,$+8\;.long %0-$
+   e_bl $+8\;.long %0-$"
   [(set_attr "type" "branch")
-   (set_attr "length" "8")])
+   (set_attr "isa" "novle,vle")
+   (set_attr "length" "8,8")])
 
 (define_insn "load_toc_v4_PIC_1b_476"
   [(set (reg:SI LR_REGNO)
@@ -12057,7 +12914,7 @@
 		   (minus:SI (match_operand:SI 2 "immediate_operand" "s")
 			     (match_operand:SI 3 "immediate_operand" "s")))))]
   "TARGET_ELF && DEFAULT_ABI == ABI_V4 && flag_pic == 2"
-  "lwz %0,%2-%3(%1)"
+  "%^lwz %0,%2-%3(%1)"
   [(set_attr "type" "load")])
 
 (define_insn "load_toc_v4_PIC_3b"
@@ -12186,16 +13043,25 @@
   [(set (match_operand:SI 0 "gpc_reg_operand" "=b*r")
 	(high:SI (match_operand 1 "" "")))]
   "TARGET_ELF && ! TARGET_64BIT"
-  "lis %0,%1@ha")
+  "%^lis %0,%1@ha")
 
 (define_insn "elf_low"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
 	(lo_sum:SI (match_operand:SI 1 "gpc_reg_operand" "b,!*r")
 		   (match_operand 2 "" "")))]
-   "TARGET_ELF && ! TARGET_64BIT"
+   "TARGET_ELF && ! TARGET_64BIT && !TARGET_VLE"
+   "@
+    %^la %0,%2@l(%1)
+    %^addic %0,%1,%K2")
+
+(define_insn "elf_low_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
+	(lo_sum:SI (match_operand:SI 1 "gpc_reg_operand" "b,!*r")
+		   (match_operand 2 "" "")))]
+   "TARGET_ELF && ! TARGET_64BIT && TARGET_VLE"
    "@
-    la %0,%2@l(%1)
-    addic %0,%1,%K2")
+    %^la %0,%2@l(%1)
+    mr 23,%1\n\t%^add16i %0,23,%K2")
 
 ;; Call and call_value insns
 (define_expand "call"
@@ -12300,12 +13166,12 @@
   "*
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
-  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"bl %z0@local\" : \"bl %z0\";
+  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"%^bl %z0@local\" : \"%^bl %z0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8")])
@@ -12339,12 +13205,12 @@
   "*
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
-  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"bl %z1@local\" : \"bl %z1\";
+  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"%^bl %z1@local\" : \"%^bl %z1\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8")])
@@ -12386,12 +13252,12 @@
    || DEFAULT_ABI == ABI_DARWIN"
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
-  return "b%T0l";
+  return "%+b%T0l";
 }
   [(set_attr "type" "jmpreg,jmpreg,jmpreg,jmpreg")
    (set_attr "length" "4,4,8,8")])
@@ -12406,10 +13272,10 @@
        && (INTVAL (operands[2]) & CALL_LONG) == 0))"
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
 #if TARGET_MACHO
   return output_call(insn, operands, 0, 2);
@@ -12417,10 +13283,10 @@
   if (DEFAULT_ABI == ABI_V4 && flag_pic)
     {
       gcc_assert (!TARGET_SECURE_PLT);
-      return "bl %z0@plt";
+      return "%^bl %z0@plt";
     }
   else
-    return "bl %z0";
+    return "%^bl %z0";
 #endif
 }
   "DEFAULT_ABI == ABI_V4
@@ -12448,18 +13314,18 @@
     && (INTVAL (operands[2]) & CALL_LONG) == 0)"
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
   if (flag_pic == 2)
     /* The magic 32768 offset here and in the other sysv call insns
        corresponds to the offset of r30 in .got2, as given by LCTOC1.
        See sysv4.h:toc_section.  */
-    return "bl %z0+32768@plt";
+    return "%^bl %z0+32768@plt";
   else
-    return "bl %z0@plt";
+    return "%^bl %z0@plt";
 }
   [(set_attr "type" "branch,branch")
    (set_attr "length" "4,8")])
@@ -12474,12 +13340,12 @@
    || DEFAULT_ABI == ABI_DARWIN"
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
-  return "b%T1l";
+  return "%+b%T1l";
 }
   [(set_attr "type" "jmpreg,jmpreg,jmpreg,jmpreg")
    (set_attr "length" "4,4,8,8")])
@@ -12495,10 +13361,10 @@
        && (INTVAL (operands[3]) & CALL_LONG) == 0))"
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
 #if TARGET_MACHO
   return output_call(insn, operands, 1, 3);
@@ -12506,10 +13372,10 @@
   if (DEFAULT_ABI == ABI_V4 && flag_pic)
     {
       gcc_assert (!TARGET_SECURE_PLT);
-      return "bl %z1@plt";
+      return "%^bl %z1@plt";
     }
   else
-    return "bl %z1";
+    return "%^bl %z1";
 #endif
 }
   "DEFAULT_ABI == ABI_V4
@@ -12746,12 +13612,12 @@
   "*
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
-  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"b %z0@local\" : \"b %z0\";
+  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"%^b %z0@local\" : \"%^b %z0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8")])
@@ -12787,12 +13653,12 @@
   "*
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
-  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"b %z1@local\" : \"b %z1\";
+  return (DEFAULT_ABI == ABI_V4 && flag_pic) ? \"%^b %z1@local\" : \"%^b %z1\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8")])
@@ -12836,14 +13702,14 @@
     output_asm_insn (\"creqv 6,6,6\", operands);
 
   if (which_alternative >= 2)
-    return \"b%T0\";
+    return \"%+b%T0\";
   else if (DEFAULT_ABI == ABI_V4 && flag_pic)
     {
       gcc_assert (!TARGET_SECURE_PLT);
-      return \"b %z0@plt\";
+      return \"%^b %z0@plt\";
     }
   else
-    return \"b %z0\";
+    return \"%^b %z0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8,4,8")])
@@ -12867,14 +13733,14 @@
     output_asm_insn (\"creqv 6,6,6\", operands);
 
   if (which_alternative >= 2)
-    return \"b%T1\";
+    return \"%+b%T1\";
   else if (DEFAULT_ABI == ABI_V4 && flag_pic)
     {
       gcc_assert (!TARGET_SECURE_PLT);
-      return \"b %z1@plt\";
+      return \"%^b %z1@plt\";
     }
   else
-    return \"b %z1\";
+    return \"%^b %z1\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "4,8,4,8")])
@@ -12937,7 +13803,7 @@
 (define_insn "probe_stack_<mode>"
   [(set (match_operand:P 0 "memory_operand" "=m")
         (unspec:P [(const_int 0)] UNSPEC_PROBE_STACK))]
-  ""
+  "!TARGET_VLE"
 {
   operands[1] = gen_rtx_REG (Pmode, 0);
   return "st<wd>%U0%X0 %1,%0";
@@ -12952,6 +13818,24 @@
 	  (const_string "store"))))
    (set_attr "length" "4")])
 
+(define_insn "*probe_stack_<mode>_vle"
+  [(set (match_operand:P 0 "memory_operand" "=m")
+        (unspec:P [(const_int 0)] UNSPEC_PROBE_STACK))]
+  "TARGET_VLE"
+{
+  operands[1] = gen_rtx_REG (Pmode, 0);
+  return "e_st<wd>%U0%X0 %1,%0";
+}
+  [(set (attr "type")
+      (if_then_else
+	(match_test "update_indexed_address_mem (operands[0], VOIDmode)")
+	(const_string "store_ux")
+	(if_then_else
+	  (match_test "update_address_mem (operands[0], VOIDmode)")
+	  (const_string "store_u")
+	  (const_string "store"))))
+   (set_attr "length" "4")])
+
 (define_insn "probe_stack_range<P:mode>"
   [(set (match_operand:P 0 "register_operand" "=r")
 	(unspec_volatile:P [(match_operand:P 1 "register_operand" "0")
@@ -13132,11 +14016,65 @@
 
 
 ;; Here are the actual compare insns.
+(define_insn "*cmpsi_logical_vle"
+  [(set (match_operand:CCUNS 0 "cc_reg_operand" "=x,x,x,kcreg,?y")
+	(compare:CCUNS (match_operand:SI 1 "gpc_reg_operand" "kregs,kregs,r,r,r")
+		       (match_operand:SI 2 "vle_logical_cmpsi_operand" "kregs,koim5,K,ksci8,r")))]
+  "TARGET_VLE"
+  "@
+   se_cmpl %1,%2
+   se_cmpli %1,%2
+   e_cmpl16i %1,%b2
+   e_cmpli %0,%1,%2
+   cmpl %0,%1,%2"
+  [(set_attr "type" "cmp,cmp,cmp,cmp,cmp")
+   (set_attr "length" "2,2,4,4,4")])
+
+(define_insn "*cmpsi_arithmetic_vle"
+  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,kcreg,?y,?y,?y")
+	(compare:CC (match_operand:SI 1 "gpc_reg_operand" "kregs,kregs,r,r,r,r,r")
+		    (match_operand:SI 2 "vle_arith_cmpsi_operand" "kregs,kuim5,I,ksci8,r,kli20,ksci8")))]
+  "TARGET_VLE"
+  "@
+   se_cmp %1,%2
+   se_cmpi %1,%2
+   e_cmp16i %1,%2
+   e_cmpi %0,%1,%2
+   cmp %0,%1,%2
+   e_li 23,%2\n\tcmp %0,%1,23
+   e_lis 23,%2@h\n\te_or2i 23,%2@l\n\tcmp %0,%1,23"
+  [(set_attr "type" "cmp,cmp,cmp,cmp,cmp,cmp,cmp")
+   (set_attr "length" "2,2,4,4,4,8,12")])
+
+(define_insn "*cmphi_logical_vle"
+  [(set (match_operand:CCUNS 0 "cc_reg_operand" "=x,x,?y")
+	(compare:CCUNS (match_operand:HI 1 "gpc_reg_operand" "kregs,r,r")
+		       (match_operand:HI 2 "vle_logical_cmphi_operand" "kregs,K,r")))]
+  "TARGET_VLE"
+  "@
+   se_cmphl %1,%2
+   e_cmphl16i %1,%b2
+   e_cmphl %0,%1,%2"
+  [(set_attr "type" "cmp,cmp,cmp")
+   (set_attr "length" "2,4,4")])
+
+(define_insn "*cmphi_arithmetic_vle"
+  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y")
+	(compare:CC (match_operand:HI 1 "gpc_reg_operand" "kregs,r,r")
+		    (match_operand:HI 2 "vle_arith_cmphi_operand" "kregs,I,r")))]
+  "TARGET_VLE"
+  "@
+   se_cmph %1,%2
+   e_cmph16i %1,%2
+   e_cmph %0,%1,%2"
+  [(set_attr "type" "cmp,cmp,cmp")
+   (set_attr "length" "2,4,4")])
+
 (define_insn "*cmp<mode>_internal1"
   [(set (match_operand:CC 0 "cc_reg_operand" "=y")
 	(compare:CC (match_operand:GPR 1 "gpc_reg_operand" "r")
 		    (match_operand:GPR 2 "reg_or_short_operand" "rI")))]
-  ""
+  "!TARGET_VLE"
   "cmp<wd>%I2 %0,%1,%2"
   [(set_attr "type" "cmp")])
 
@@ -13162,7 +14100,7 @@
                        [(match_dup 4) (const_int 0)])
                       (match_operand 7 "" "")
                       (match_operand 8 "" "")))]
-  "peep2_reg_dead_p (3, operands[0])
+  "!TARGET_VLE && peep2_reg_dead_p (3, operands[0])
    && peep2_reg_dead_p (4, operands[4])"
  [(set (match_dup 0) (xor:SI (match_dup 5) (match_dup 9)))
   (set (match_dup 4) (compare:CC (match_dup 0) (match_dup 10)))
@@ -13210,7 +14148,7 @@
 		    (match_operand:SI 2 "short_cint_operand" "i")))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r")
 	(plus:SI (match_dup 1) (match_operand:SI 4 "short_cint_operand" "i")))]
-  ""
+  "!TARGET_VLE"
   "#"
   [(set_attr "length" "8")])
 
@@ -13220,7 +14158,7 @@
 		       (match_operand:SI 2 "u_short_cint_operand" "i")))
    (set (match_operand:SI 0 "gpc_reg_operand" "=r")
 	(plus:SI (match_dup 1) (match_operand:SI 4 "short_cint_operand" "i")))]
-  ""
+  "!TARGET_VLE"
   "#"
   [(set_attr "length" "8")])
 
@@ -13230,7 +14168,7 @@
 		    (match_operand:SI 2 "short_cint_operand" "")))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(plus:SI (match_dup 1) (match_operand:SI 4 "short_cint_operand" "")))]
-  ""
+  "!TARGET_VLE"
   [(set (match_dup 3) (compare:CC (match_dup 1) (match_dup 2)))
    (set (match_dup 0) (plus:SI (match_dup 1) (match_dup 4)))])
 
@@ -13240,7 +14178,7 @@
 		       (match_operand:SI 2 "u_short_cint_operand" "")))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(plus:SI (match_dup 1) (match_operand:SI 4 "short_cint_operand" "")))]
-  ""
+  "!TARGET_VLE"
   [(set (match_dup 3) (compare:CCUNS (match_dup 1) (match_dup 2)))
    (set (match_dup 0) (plus:SI (match_dup 1) (match_dup 4)))])
 
@@ -13329,7 +14267,7 @@
 			   [(match_operand 2 "cc_reg_operand" "y")
 			    (const_int 0)]))]
   ""
-  "mfcr %0%Q2\;rlwinm %0,%0,%J1,1"
+  "mfcr %0%Q2\;%^rlwinm %0,%0,%J1,1"
   [(set (attr "type")
      (cond [(match_test "TARGET_MFCRF")
 		(const_string "mfcrf")
@@ -13342,7 +14280,7 @@
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
 	(unspec:SI [(match_operand 1 "cc_reg_operand" "y")] UNSPEC_MV_CR_GT))]
   "TARGET_HARD_FLOAT && !TARGET_FPRS"
-  "mfcr %0\;rlwinm %0,%0,%D1,31,31"
+  "mfcr %0\;%^rlwinm %0,%0,%D1,31,31"
   [(set_attr "type" "mfcr")
    (set_attr "length" "8")])
 
@@ -13351,8 +14289,8 @@
   [(set (match_operand:SI 0 "gpc_reg_operand" "=r")
 	(unspec:SI [(match_operand:CC 1 "cc_reg_operand" "y")]
 		   UNSPEC_MV_CR_OV))]
-  "TARGET_ISEL"
-  "mfcr %0\;rlwinm %0,%0,%t1,1"
+  "TARGET_ISEL || TARGET_SPE"
+  "mfcr %0\;%^rlwinm %0,%0,%t1,1"
   [(set_attr "type" "mfcr")
    (set_attr "length" "8")])
 
@@ -13378,7 +14316,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 3 "gpc_reg_operand" "=r,r")
 	(match_op_dup 1 [(match_dup 2) (const_int 0)]))]
-  "TARGET_32BIT"
+  "TARGET_32BIT && !TARGET_VLE"
   "@
    mfcr %3%Q2\;rlwinm. %3,%3,%J1,1
    #"
@@ -13393,7 +14331,7 @@
 		    (const_int 0)))
    (set (match_operand:SI 3 "gpc_reg_operand" "")
 	(match_op_dup 1 [(match_dup 2) (const_int 0)]))]
-  "TARGET_32BIT && reload_completed"
+  "TARGET_32BIT && !TARGET_VLE && reload_completed"
   [(set (match_dup 3)
 	(match_op_dup 1 [(match_dup 2) (const_int 0)]))
    (set (match_dup 0)
@@ -13422,7 +14360,7 @@
   operands[4] = GEN_INT (count);
   operands[5] = GEN_INT (put_bit);
 
-  return \"mfcr %0%Q2\;rlwinm %0,%0,%4,%5,%5\";
+  return \"mfcr %0%Q2\;%^rlwinm %0,%0,%4,%5,%5\";
 }"
   [(set (attr "type")
      (cond [(match_test "TARGET_MFCRF")
@@ -13442,7 +14380,7 @@
    (set (match_operand:SI 4 "gpc_reg_operand" "=r,r")
 	(ashift:SI (match_op_dup 1 [(match_dup 2) (const_int 0)])
 		   (match_dup 3)))]
-  ""
+  "!TARGET_VLE"
   "*
 {
   int is_bit = ccr_bit (operands[1], 1);
@@ -13477,7 +14415,7 @@
    (set (match_operand:SI 4 "gpc_reg_operand" "")
 	(ashift:SI (match_op_dup 1 [(match_dup 2) (const_int 0)])
 		   (match_dup 3)))]
-  "reload_completed"
+  "!TARGET_VLE && reload_completed"
   [(set (match_dup 4)
 	(ashift:SI (match_op_dup 1 [(match_dup 2) (const_int 0)])
 		   (match_dup 3)))
@@ -13499,7 +14437,7 @@
 			   [(match_operand 5 "cc_reg_operand" "y")
 			    (const_int 0)]))]
   "REGNO (operands[2]) != REGNO (operands[5])"
-  "mfcr %3\;rlwinm %0,%3,%J1,1\;rlwinm %3,%3,%J4,1"
+  "mfcr %3\;%^rlwinm %0,%3,%J1,1\;%^rlwinm %3,%3,%J4,1"
   [(set_attr "type" "mfcr")
    (set_attr "length" "12")])
 
@@ -13538,9 +14476,9 @@
   [(set (match_operand:GPR 0 "gpc_reg_operand" "=r")
 	(eq:GPR (match_operand:GPR 1 "gpc_reg_operand" "r")
 		(match_operand:GPR 2 "scc_eq_operand" "<scc_eq_op2>")))]
-  ""
+  "!TARGET_POWER_NOVLE"
   "#"
-  ""
+  "!TARGET_POWER_NOVLE"
   [(set (match_dup 0)
 	(clz:GPR (match_dup 3)))
    (set (match_dup 0)
@@ -13551,7 +14489,8 @@
 	/* Use output operand as intermediate.  */
 	operands[3] = operands[0];
 
-	if (logical_operand (operands[2], <MODE>mode))
+	if ((!TARGET_VLE && logical_operand (operands[2], <MODE>mode))
+	   || (TARGET_VLE && vle_xor_operand (operands[2], <MODE>mode)))
 	  emit_insn (gen_rtx_SET (VOIDmode, operands[3],
 				  gen_rtx_XOR (<MODE>mode,
 					       operands[1], operands[2])));
@@ -13575,9 +14514,9 @@
 	 (const_int 0)))
    (set (match_operand:P 0 "gpc_reg_operand" "=r")
 	(eq:P (match_dup 1) (match_dup 2)))]
-  "optimize_size"
+  "!TARGET_POWER_NOVLE && optimize_size"
   "#"
-  "optimize_size"
+  "!TARGET_POWER_NOVLE && optimize_size"
   [(set (match_dup 0)
 	(clz:P (match_dup 4)))
    (parallel [(set (match_dup 3)
@@ -13591,7 +14530,8 @@
 	/* Use output operand as intermediate.  */
 	operands[4] = operands[0];
 
-	if (logical_operand (operands[2], <MODE>mode))
+	if ((!TARGET_VLE && logical_operand (operands[2], <MODE>mode))
+	   || (TARGET_VLE && vle_xor_operand (operands[2], <MODE>mode)))
 	  emit_insn (gen_rtx_SET (VOIDmode, operands[4],
 				  gen_rtx_XOR (<MODE>mode,
 					       operands[1], operands[2])));
@@ -13622,12 +14562,25 @@
    (set (match_dup 0) (plus:SI (match_op_dup 1 [(match_dup 5) (match_dup 3)])
 			       (match_dup 4)))])
 
+(define_insn "*plus_eqsi_vle"
+  [(set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r,&r")
+	(plus:SI (eq:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r")
+			(match_operand:SI 2 "scc_eq_operand" "r,O,ksci8"))
+		 (match_operand:SI 3 "gpc_reg_operand" "r,r,r")))]
+  "TARGET_VLE"
+  "@
+   xor %0,%1,%2\;e_subfic %0,%0,0\;addze %0,%3
+   e_subfic %0,%1,0\;addze %0,%3
+   e_xori %0,%1,%2\;e_subfic %0,%0,0\;addze %0,%3"
+  [(set_attr "type" "three,two,three")
+   (set_attr "length" "12,8,12")])
+
 (define_insn "*plus_eqsi"
   [(set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r,&r,&r,&r")
 	(plus:SI (eq:SI (match_operand:SI 1 "gpc_reg_operand" "%r,r,r,r,r")
 			(match_operand:SI 2 "scc_eq_operand" "r,O,K,L,I"))
 		 (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r,r")))]
-  "TARGET_32BIT"
+  "TARGET_32BIT && !TARGET_VLE"
   "@
    xor %0,%1,%2\;subfic %0,%0,0\;addze %0,%3
    subfic %0,%1,0\;addze %0,%3
@@ -13646,7 +14599,7 @@
 	  (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r,r,r,r,r,r,r"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=&r,&r,&r,&r,&r,&r,&r,&r,&r,&r"))]
-  "TARGET_32BIT && optimize_size"
+  "TARGET_32BIT && !TARGET_VLE && optimize_size"
   "@
    xor %4,%1,%2\;subfic %4,%4,0\;addze. %4,%3
    subfic %4,%1,0\;addze. %4,%3
@@ -13670,7 +14623,7 @@
 	  (match_operand:SI 3 "gpc_reg_operand" ""))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 ""))]
-  "TARGET_32BIT && optimize_size && reload_completed"
+  "TARGET_32BIT && !TARGET_VLE && optimize_size && reload_completed"
   [(set (match_dup 4)
 	(plus:SI (eq:SI (match_dup 1)
 		 (match_dup 2))
@@ -13690,7 +14643,7 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r,&r,&r,&r,&r,&r,&r,&r,&r")
 	(plus:SI (eq:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "TARGET_32BIT && optimize_size"
+  "TARGET_32BIT && !TARGET_VLE && optimize_size"
   "@
    xor %0,%1,%2\;subfic %0,%0,0\;addze. %0,%3
    subfic %0,%1,0\;addze. %0,%3
@@ -13715,7 +14668,7 @@
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "")
 	(plus:SI (eq:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
-  "TARGET_32BIT && optimize_size && reload_completed"
+  "TARGET_32BIT && !TARGET_VLE && optimize_size && reload_completed"
   [(set (match_dup 0)
 	(plus:SI (eq:SI (match_dup 1) (match_dup 2)) (match_dup 3)))
    (set (match_dup 4)
@@ -13728,7 +14681,7 @@
 	(neg:P (eq:P (match_operand:P 1 "gpc_reg_operand" "r")
 		     (const_int 0))))]
   ""
-  "addic %0,%1,-1\;subfe %0,%0,%0"
+  "%^addic %0,%1,-1\;subfe %0,%0,%0"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
@@ -13747,7 +14700,14 @@
 	operands[3] = operands[0];
 
 	if (logical_operand (operands[2], <MODE>mode))
-	  emit_insn (gen_rtx_SET (VOIDmode, operands[3],
+		if (TARGET_VLE && !vle_xor_operand (operands[2], <MODE>mode)) {
+		      emit_move_insn (operands[3], operands[2]);
+	  			emit_insn (gen_rtx_SET (VOIDmode, operands[3],
+				  gen_rtx_XOR (<MODE>mode,
+					       operands[1], operands[3])));
+		      }
+		else		
+	  		emit_insn (gen_rtx_SET (VOIDmode, operands[3],
 				  gen_rtx_XOR (<MODE>mode,
 					       operands[1], operands[2])));
 	else
@@ -13766,7 +14726,7 @@
 	      (const_int 0)))
    (clobber (match_scratch:P 2 "=&r"))]
   "!(TARGET_32BIT && TARGET_ISEL)"
-  "addic %2,%1,-1\;subfe %0,%2,%1"
+  "%^addic %2,%1,-1\;subfe %0,%2,%1"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
@@ -13777,7 +14737,7 @@
 		(match_operand:P 2 "gpc_reg_operand" "r")))
    (clobber (match_scratch:P 3 "=&r"))]
   ""
-  "addic %3,%1,-1\;addze %0,%2"
+  "%^addic %3,%1,-1\;addze %0,%2"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
@@ -13791,7 +14751,7 @@
    (clobber (match_scratch:P 4 "=X,&r"))]
   ""
   "@
-   addic %3,%1,-1\;addze. %3,%2
+   %^addic %3,%1,-1\;addze. %3,%2
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,12")])
@@ -13824,7 +14784,7 @@
    (clobber (match_scratch:P 4 "=X,&r"))]
   ""
   "@
-   addic %3,%1,-1\;addze. %3,%2
+   %^addic %3,%1,-1\;addze. %3,%2
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,12")])
@@ -13847,7 +14807,48 @@
 		    (const_int 0)))]
   "")
 
-(define_insn "*plus_ne0_<mode>_compare"
+(define_insn "*plus_ne0si_compare"
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,?kcrxx")
+	(compare:CC
+	 (plus:SI (lshiftrt:SI
+		   (neg:SI (abs:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")))
+		   (const_int 31))
+		  (match_operand:SI 2 "gpc_reg_operand" "r,r"))
+	 (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "=r,r")
+	(plus:SI (lshiftrt:SI (neg:SI (abs:SI (match_dup 1))) (const_int 31))
+		 (match_dup 2)))
+   (clobber (match_scratch:SI 3 "=&r,&r"))]
+  "TARGET_32BIT"
+  "@
+   %^addic %3,%1,-1\;addze. %0,%2
+   #"
+  [(set_attr "type" "compare")
+   (set_attr "length" "8,12")])
+
+(define_split
+  [(set (match_operand:CC 4 "cmpi_cc_reg_not_cr0_operand" "")
+	(compare:CC
+	 (plus:SI (lshiftrt:SI
+		   (neg:SI (abs:SI (match_operand:SI 1 "gpc_reg_operand" "")))
+		   (const_int 31))
+		  (match_operand:SI 2 "gpc_reg_operand" ""))
+	 (const_int 0)))
+   (set (match_operand:SI 0 "gpc_reg_operand" "")
+	(plus:SI (lshiftrt:SI (neg:SI (abs:SI (match_dup 1))) (const_int 31))
+		 (match_dup 2)))
+   (clobber (match_scratch:SI 3 ""))]
+  "TARGET_32BIT && reload_completed"
+  [(parallel [(set (match_dup 0)
+	(plus:SI (lshiftrt:SI (neg:SI (abs:SI (match_dup 1))) (const_int 31))
+		 (match_dup 2)))
+   (clobber (match_dup 3))])
+   (set (match_dup 4)
+	(compare:CC (match_dup 0)
+		    (const_int 0)))]
+  "")
+
+(define_insn "*plus_ne0di_compare"
   [(set (match_operand:CC 4 "cc_reg_operand" "=x,?y")
 	(compare:CC
 	 (plus:P (ne:P (match_operand:P 1 "gpc_reg_operand" "r,r")
@@ -13861,7 +14862,7 @@
    (clobber (match_scratch:P 3 "=&r,&r"))]
   ""
   "@
-   addic %3,%1,-1\;addze. %0,%2
+   %^addic %3,%1,-1\;addze. %0,%2
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,12")])
@@ -13889,32 +14890,37 @@
 		    (const_int 0)))]
   "")
 
-(define_insn "*leu<mode>"
-  [(set (match_operand:P 0 "gpc_reg_operand" "=r")
-	(leu:P (match_operand:P 1 "gpc_reg_operand" "r")
-	       (match_operand:P 2 "reg_or_short_operand" "rI")))]
-  ""
-  "subf%I2c %0,%1,%2\;li %0,0\;adde %0,%0,%0"
-  [(set_attr "type" "three")
-   (set_attr "length" "12")])
+  (define_insn "*leu<mode>"
+   [(set (match_operand:P 0 "gpc_reg_operand" "=kregs,r")
+         (leu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
+                (match_operand:P 2 "reg_or_short_operand" "rksci8,rkscI8")))]
+   ""
+   "@
+    %i2subf%I2c %0,%1,%2\;%+li %0,0\;adde %0,%0,%0
+    %i2subf%I2c %0,%1,%2\;%^li %0,0\;adde %0,%0,%0"
+   [(set_attr "type" "three")
+    (set_attr "length" "10,12")
+    (set_attr "isa" "vle,*")])
 
 (define_insn "*leu<mode>_compare"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcrxx")
 	(compare:CC
-	 (leu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-		(match_operand:P 2 "reg_or_short_operand" "rI,rI"))
+	 (leu:P (match_operand:P 1 "gpc_reg_operand" "r,r,r")
+		(match_operand:P 2 "reg_or_short_operand" "rksci8,rkscI8,rkscI8"))
 	 (const_int 0)))
-   (set (match_operand:P 0 "gpc_reg_operand" "=r,r")
+   (set (match_operand:P 0 "gpc_reg_operand" "=kregs,r,r")
 	(leu:P (match_dup 1) (match_dup 2)))]
   ""
   "@
-   subf%I2c %0,%1,%2\;li %0,0\;adde. %0,%0,%0
+   %i2subf%I2c %0,%1,%2\;%+li %0,0\;adde. %0,%0,%0
+   %i2subf%I2c %0,%1,%2\;%^li %0,0\;adde. %0,%0,%0
    #"
   [(set_attr "type" "compare")
-   (set_attr "length" "12,16")])
+   (set_attr "length" "10,12,16")
+   (set_attr "isa" "vle,*,*")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (leu:P (match_operand:P 1 "gpc_reg_operand" "")
 		(match_operand:P 2 "reg_or_short_operand" ""))
@@ -13932,30 +14938,30 @@
 (define_insn "*plus_leu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=&r")
 	(plus:P (leu:P (match_operand:P 1 "gpc_reg_operand" "r")
-		       (match_operand:P 2 "reg_or_short_operand" "rI"))
+		       (match_operand:P 2 "reg_or_short_operand" "rkscI8"))
 		(match_operand:P 3 "gpc_reg_operand" "r")))]
   ""
-  "subf%I2c %0,%1,%2\;addze %0,%3"
+  "%i2subf%I2c %0,%1,%2\;addze %0,%3"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (plus:SI (leu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
-			  (match_operand:SI 2 "reg_or_short_operand" "rI,rI"))
+			  (match_operand:SI 2 "reg_or_short_operand" "rkscI8,rkscI8"))
 		  (match_operand:SI 3 "gpc_reg_operand" "r,r"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=&r,&r"))]
   "TARGET_32BIT"
   "@
-   subf%I2c %4,%1,%2\;addze. %4,%3
+   %i2subf%I2c %4,%1,%2\;addze. %4,%3
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,12")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (leu:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			  (match_operand:SI 2 "reg_or_short_operand" ""))
@@ -13972,23 +14978,23 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (plus:SI (leu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
-			  (match_operand:SI 2 "reg_or_short_operand" "rI,rI"))
+			  (match_operand:SI 2 "reg_or_short_operand" "rkscI8,rkscI8"))
 		  (match_operand:SI 3 "gpc_reg_operand" "r,r"))
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r")
 	(plus:SI (leu:SI (match_dup 1) (match_dup 2)) (match_dup 3)))]
   "TARGET_32BIT"
   "@
-   subf%I2c %0,%1,%2\;addze. %0,%3
+   %i2subf%I2c %0,%1,%2\;addze. %0,%3
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,12")])
 
 (define_split
-  [(set (match_operand:CC 4 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (leu:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			  (match_operand:SI 2 "reg_or_short_operand" ""))
@@ -14007,9 +15013,9 @@
 (define_insn "*neg_leu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=r")
 	(neg:P (leu:P (match_operand:P 1 "gpc_reg_operand" "r")
-		      (match_operand:P 2 "reg_or_short_operand" "rI"))))]
+		      (match_operand:P 2 "reg_or_short_operand" "rkscI8"))))]
   ""
-  "subf%I2c %0,%1,%2\;subfe %0,%0,%0\;nand %0,%0,%0"
+  "%i2subf%I2c %0,%1,%2\;subfe %0,%0,%0\;nand %0,%0,%0"
    [(set_attr "type" "three")
     (set_attr "length" "12")])
 
@@ -14017,31 +15023,31 @@
   [(set (match_operand:P 0 "gpc_reg_operand" "=&r")
 	(and:P (neg:P
 		 (leu:P (match_operand:P 1 "gpc_reg_operand" "r")
-			(match_operand:P 2 "reg_or_short_operand" "rI")))
+			(match_operand:P 2 "reg_or_short_operand" "rkscI8")))
 		(match_operand:P 3 "gpc_reg_operand" "r")))]
   ""
-  "subf%I2c %0,%1,%2\;subfe %0,%0,%0\;andc %0,%3,%0"
+  "%i2subf%I2c %0,%1,%2\;subfe %0,%0,%0\;andc %0,%3,%0"
   [(set_attr "type" "three")
    (set_attr "length" "12")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (leu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
-			  (match_operand:SI 2 "reg_or_short_operand" "rI,rI")))
+			  (match_operand:SI 2 "reg_or_short_operand" "rkscI8,rkscI8")))
 		 (match_operand:SI 3 "gpc_reg_operand" "r,r"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=&r,&r"))]
   "TARGET_32BIT"
   "@
-   subf%I2c %4,%1,%2\;subfe %4,%4,%4\;andc. %4,%3,%4
+   %i2subf%I2c %4,%1,%2\;subfe %4,%4,%4\;andc. %4,%3,%4
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "12,16")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (leu:SI (match_operand:SI 1 "gpc_reg_operand" "")
@@ -14059,24 +15065,24 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (leu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
-			  (match_operand:SI 2 "reg_or_short_operand" "rI,rI")))
+			  (match_operand:SI 2 "reg_or_short_operand" "rkscI8,rkscI8")))
 		 (match_operand:SI 3 "gpc_reg_operand" "r,r"))
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r")
 	(and:SI (neg:SI (leu:SI (match_dup 1) (match_dup 2))) (match_dup 3)))]
   "TARGET_32BIT"
   "@
-   subf%I2c %0,%1,%2\;subfe %0,%0,%0\;andc. %0,%3,%0
+   %i2subf%I2c %0,%1,%2\;subfe %0,%0,%0\;andc. %0,%3,%0
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "12,16")])
 
 (define_split
-  [(set (match_operand:CC 4 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (leu:SI (match_operand:SI 1 "gpc_reg_operand" "")
@@ -14106,7 +15112,7 @@
   "")
 
 (define_insn_and_split "*ltu<mode>_compare"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (ltu:P (match_operand:P 1 "gpc_reg_operand" "r,r,r,r")
 		(match_operand:P 2 "reg_or_neg_short_operand" "r,P,r,P"))
@@ -14135,7 +15141,7 @@
   "")
 
 (define_insn_and_split "*plus_ltu<mode>_compare"
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (plus:P (ltu:P (match_operand:P 1 "gpc_reg_operand" "r,r,r,r")
 			(match_operand:P 2 "reg_or_neg_short_operand" "r,P,r,P"))
@@ -14156,44 +15162,44 @@
 (define_insn "*neg_ltu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=r,r")
 	(neg:P (ltu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-		      (match_operand:P 2 "reg_or_neg_short_operand" "r,P"))))]
+		      (match_operand:P 2 "vle_reg_or_neg_imm_operand" "r,kscP8"))))]
   ""
   "@
    subfc %0,%2,%1\;subfe %0,%0,%0
-   addic %0,%1,%n2\;subfe %0,%0,%0"
+   %^addic %0,%1,%n2\;subfe %0,%0,%0"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
 (define_insn "*geu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=r,r")
 	(geu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-	       (match_operand:P 2 "reg_or_neg_short_operand" "r,P")))]
+	       (match_operand:P 2 "vle_reg_or_neg_imm_operand" "r,P")))]
   ""
   "@
-   subfc %0,%2,%1\;li %0,0\;adde %0,%0,%0
-   addic %0,%1,%n2\;li %0,0\;adde %0,%0,%0"
+   subfc %0,%2,%1\;%^li %0,0\;adde %0,%0,%0
+   %^addic %0,%1,%n2\;%^li %0,0\;adde %0,%0,%0"
   [(set_attr "type" "three")
    (set_attr "length" "12")])
 
 (define_insn "*geu<mode>_compare"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (geu:P (match_operand:P 1 "gpc_reg_operand" "r,r,r,r")
-		(match_operand:P 2 "reg_or_neg_short_operand" "r,P,r,P"))
+		(match_operand:P 2 "vle_reg_or_neg_imm_operand" "r,kscP8,rkscP8,kscP8"))
 	 (const_int 0)))
    (set (match_operand:P 0 "gpc_reg_operand" "=r,r,r,r")
 	(geu:P (match_dup 1) (match_dup 2)))]
   ""
   "@
-   subfc %0,%2,%1\;li %0,0\;adde. %0,%0,%0
-   addic %0,%1,%n2\;li %0,0\;adde. %0,%0,%0
+   subfc %0,%2,%1\;%^li %0,0\;adde. %0,%0,%0
+   %^addic %0,%1,%n2\;%^li %0,0\;adde. %0,%0,%0
    #
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "12,12,16,16")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_micro_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_micro_cr0_operand" "")
 	(compare:CC
 	 (geu:P (match_operand:P 1 "gpc_reg_operand" "")
 		(match_operand:P 2 "reg_or_neg_short_operand" ""))
@@ -14211,34 +15217,34 @@
 (define_insn "*plus_geu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=&r,&r")
 	(plus:P (geu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-		       (match_operand:P 2 "reg_or_neg_short_operand" "r,P"))
+		       (match_operand:P 2 "vle_reg_or_neg_imm_operand" "r,kscP8"))
 		(match_operand:P 3 "gpc_reg_operand" "r,r")))]
   ""
   "@
    subfc %0,%2,%1\;addze %0,%3
-   addic %0,%1,%n2\;addze %0,%3"
+   %^addic %0,%1,%n2\;addze %0,%3"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (plus:SI (geu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			  (match_operand:SI 2 "reg_or_neg_short_operand" "r,P,r,P"))
+			  (match_operand:SI 2 "vle_reg_or_neg_imm_operand" "r,kscP8,rkscP8,kscP8"))
 		  (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=&r,&r,&r,&r"))]
   "TARGET_32BIT"
   "@
    subfc %4,%2,%1\;addze. %4,%3
-   addic %4,%1,%n2\;addze. %4,%3
+   %^addic %4,%1,%n2\;addze. %4,%3
    #
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,8,12,12")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (geu:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			  (match_operand:SI 2 "reg_or_neg_short_operand" ""))
@@ -14255,10 +15261,10 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (plus:SI (geu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			  (match_operand:SI 2 "reg_or_neg_short_operand" "r,P,r,P"))
+			  (match_operand:SI 2 "vle_reg_or_neg_imm_operand" "r,kscP8,rkscP8,kscP8"))
 		  (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r"))
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r,&r,&r")
@@ -14266,14 +15272,14 @@
   "TARGET_32BIT"
   "@
    subfc %0,%2,%1\;addze. %0,%3
-   addic %0,%1,%n2\;addze. %0,%3
+   %^addic %0,%1,%n2\;addze. %0,%3
    #
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "8,8,12,12")])
 
 (define_split
-  [(set (match_operand:CC 4 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (geu:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			  (match_operand:SI 2 "reg_or_neg_short_operand" ""))
@@ -14292,11 +15298,11 @@
 (define_insn "*neg_geu<mode>"
   [(set (match_operand:P 0 "gpc_reg_operand" "=r,r")
 	(neg:P (geu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-		      (match_operand:P 2 "reg_or_short_operand" "r,I"))))]
+		      (match_operand:P 2 "reg_or_short_operand" "r,kscI8"))))]
   ""
   "@
    subfc %0,%2,%1\;subfe %0,%0,%0\;nand %0,%0,%0
-   subfic %0,%1,-1\;add%I2c %0,%0,%2\;subfe %0,%0,%0"
+   %^subfic %0,%1,-1\;add%I2c %0,%0,%2\;subfe %0,%0,%0"
   [(set_attr "type" "three")
    (set_attr "length" "12")])
 
@@ -14304,35 +15310,35 @@
   [(set (match_operand:P 0 "gpc_reg_operand" "=&r,&r")
 	(and:P (neg:P
 		 (geu:P (match_operand:P 1 "gpc_reg_operand" "r,r")
-			(match_operand:P 2 "reg_or_neg_short_operand" "r,P")))
+			(match_operand:P 2 "vle_reg_or_neg_imm_operand" "r,kscP8")))
 		(match_operand:P 3 "gpc_reg_operand" "r,r")))]
   ""
   "@
    subfc %0,%2,%1\;subfe %0,%0,%0\;andc %0,%3,%0
-   addic %0,%1,%n2\;subfe %0,%0,%0\;andc %0,%3,%0"
+   %^addic %0,%1,%n2\;subfe %0,%0,%0\;andc %0,%3,%0"
   [(set_attr "type" "three")
    (set_attr "length" "12")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (geu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			  (match_operand:SI 2 "reg_or_neg_short_operand" "r,P,r,P")))
+			  (match_operand:SI 2 "vle_reg_or_neg_imm_operand" "r,kscP8,rkscP8,kscP8")))
 		 (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r"))
 	 (const_int 0)))
    (clobber (match_scratch:SI 4 "=&r,&r,&r,&r"))]
   "TARGET_32BIT"
   "@
    subfc %4,%2,%1\;subfe %4,%4,%4\;andc. %4,%3,%4
-   addic %4,%1,%n2\;subfe %4,%4,%4\;andc. %4,%3,%4
+   %^addic %4,%1,%n2\;subfe %4,%4,%4\;andc. %4,%3,%4
    #
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "12,12,16,16")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (geu:SI (match_operand:SI 1 "gpc_reg_operand" "")
@@ -14350,11 +15356,11 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (geu:SI (match_operand:SI 1 "gpc_reg_operand" "r,r,r,r")
-			  (match_operand:SI 2 "reg_or_neg_short_operand" "r,P,r,P")))
+			  (match_operand:SI 2 "vle_reg_or_neg_imm_operand" "r,kscP8,rkscP8,kscP8")))
 		 (match_operand:SI 3 "gpc_reg_operand" "r,r,r,r"))
 	 (const_int 0)))
    (set (match_operand:SI 0 "gpc_reg_operand" "=&r,&r,&r,&r")
@@ -14362,14 +15368,14 @@
   "TARGET_32BIT"
   "@
    subfc %0,%2,%1\;subfe %0,%0,%0\;andc. %0,%3,%0
-   addic %0,%1,%n2\;subfe %0,%0,%0\;andc. %0,%3,%0
+   %^addic %0,%1,%n2\;subfe %0,%0,%0\;andc. %0,%3,%0
    #
    #"
   [(set_attr "type" "compare")
    (set_attr "length" "12,12,16,16")])
 
 (define_split
-  [(set (match_operand:CC 4 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (and:SI (neg:SI
 		  (geu:SI (match_operand:SI 1 "gpc_reg_operand" "")
@@ -14397,7 +15403,7 @@
    (set_attr "length" "12")])
 
 (define_insn ""
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (plus:SI (gt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
 			 (const_int 0))
@@ -14412,7 +15418,7 @@
    (set_attr "length" "12,16")])
 
 (define_split
-  [(set (match_operand:CC 0 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 0 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (gt:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			 (const_int 0))
@@ -14461,7 +15467,7 @@
   "")
 
 (define_insn ""
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (plus:SI (gt:SI (match_operand:SI 1 "gpc_reg_operand" "r,r")
 			 (const_int 0))
@@ -14477,7 +15483,7 @@
    (set_attr "length" "12,16")])
 
 (define_split
-  [(set (match_operand:CC 3 "cc_reg_not_cr0_operand" "")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_not_cr0_operand" "")
 	(compare:CC
 	 (plus:SI (gt:SI (match_operand:SI 1 "gpc_reg_operand" "")
 			 (const_int 0))
@@ -14538,7 +15544,7 @@
   "")
 
 (define_insn_and_split "*gtu<mode>_compare"
-  [(set (match_operand:CC 3 "cc_reg_operand" "=x,?y")
+  [(set (match_operand:CC 3 "cmpi_cc_reg_operand" "=x,?kcrxx")
 	(compare:CC
 	 (gtu:P2 (match_operand:P2 1 "gpc_reg_operand" "r,r")
 		 (match_operand:P2 2 "reg_or_short_operand" "rI,rI"))
@@ -14567,7 +15573,7 @@
   "")
 
 (define_insn_and_split "*plus_gtu<mode>_compare"
-  [(set (match_operand:CC 4 "cc_reg_operand" "=x,x,?y,?y")
+  [(set (match_operand:CC 4 "cmpi_cc_reg_operand" "=x,x,?kcrxx,?kcrxx")
 	(compare:CC
 	 (plus:P (gtu:P (match_operand:P 1 "gpc_reg_operand" "r,r,r,r")
 			(match_operand:P 2 "reg_or_short_operand" "I,r,I,r"))
@@ -14588,9 +15594,9 @@
 (define_insn "*neg_gtu<mode>"
   [(set (match_operand:P2 0 "gpc_reg_operand" "=r")
 	(neg:P2 (gtu:P2 (match_operand:P2 1 "gpc_reg_operand" "r")
-		      	(match_operand:P2 2 "reg_or_short_operand" "rI"))))]
+		      	(match_operand:P2 2 "reg_or_short_operand" "rkscI8"))))]
   ""
-  "subf%I2c %0,%1,%2\;subfe %0,%0,%0"
+  "%i2subf%I2c %0,%1,%2\;subfe %0,%0,%0"
   [(set_attr "type" "two")
    (set_attr "length" "8")])
 
@@ -14599,12 +15605,11 @@
 ;; register, we'd rather use CR0 since it is much easier to copy a
 ;; register CC value to there.
 
-(define_insn ""
+(define_insn "*cbranch_direct"
   [(set (pc)
 	(if_then_else (match_operator 1 "branch_comparison_operator"
-				      [(match_operand 2
-						      "cc_reg_operand" "y")
-				       (const_int 0)])
+		       [(match_operand 2 "cmpi_cc_reg_operand" "kcrxx")
+			(const_int 0)])
 		      (label_ref (match_operand 0 "" ""))
 		      (pc)))]
   ""
@@ -14614,7 +15619,7 @@
 }"
   [(set_attr "type" "branch")])
 
-(define_insn ""
+(define_insn "*creturn_direct"
   [(set (pc)
 	(if_then_else (match_operator 0 "branch_comparison_operator"
 				      [(match_operand 1
@@ -14622,7 +15627,7 @@
 				       (const_int 0)])
 		      (any_return)
 		      (pc)))]
-  "<return_pred>"
+  "!TARGET_VLE && <return_pred>"
   "*
 {
   return output_cbranch (operands[0], NULL, 0, insn);
@@ -14630,12 +15635,11 @@
   [(set_attr "type" "jmpreg")
    (set_attr "length" "4")])
 
-(define_insn ""
+(define_insn "*cbranch_reverse"
   [(set (pc)
 	(if_then_else (match_operator 1 "branch_comparison_operator"
-				      [(match_operand 2
-						      "cc_reg_operand" "y")
-				       (const_int 0)])
+		       [(match_operand 2 "cmpi_cc_reg_operand" "kcrxx")
+			(const_int 0)])
 		      (pc)
 		      (label_ref (match_operand 0 "" ""))))]
   ""
@@ -14645,7 +15649,7 @@
 }"
   [(set_attr "type" "branch")])
 
-(define_insn ""
+(define_insn "*creturn_reverse"
   [(set (pc)
 	(if_then_else (match_operator 0 "branch_comparison_operator"
 				      [(match_operand 1
@@ -14653,7 +15657,7 @@
 				       (const_int 0)])
 		      (pc)
 		      (any_return)))]
-  "<return_pred>"
+  "!TARGET_VLE && <return_pred>"
   "*
 {
   return output_cbranch (operands[0], NULL, 1, insn);
@@ -14685,7 +15689,7 @@
 				       (const_int 0)])])
 		      (const_int 1)))]
   ""
-  "cr%q1 %E0,%j2,%j4"
+  "%^cr%q1 %E0,%j2,%j4"
   [(set_attr "type" "cr_logical,delayed_cr")])
 
 ; Why is the constant -1 here, but 1 in the previous pattern?
@@ -14705,7 +15709,7 @@
 				 (const_int 0)])])
 		      (const_int -1)))]
   ""
-  "cr%q1 %E0,%j2,%j4"
+  "%^cr%q1 %E0,%j2,%j4"
   [(set_attr "type" "cr_logical,delayed_cr")])
 
 (define_insn "*cceq_rev_compare"
@@ -14717,7 +15721,7 @@
 				       (const_int 0)])
 		      (const_int 0)))]
   ""
-  "crnot %E0,%j1"
+  "%^crnot %E0,%j1"
   [(set_attr "type" "cr_logical,delayed_cr")])
 
 ;; If we are comparing the result of two comparisons, this can be done
@@ -14780,14 +15784,21 @@
   [(set (pc)
 	(label_ref (match_operand 0 "" "")))]
   ""
-  "b %l0"
+  "%^b %l0"
   [(set_attr "type" "branch")])
 
-(define_insn "<return_str>return"
-  [(any_return)]
-  "<return_pred>"
-  "blr"
-  [(set_attr "type" "jmpreg")])
+(define_expand "return"
+  [(return)]
+  "direct_return ()"
+  "")
+
+(define_insn "*return"
+  [(return)]
+  "direct_return ()"
+  "%+blr"
+  [(set_attr "type" "jmpreg")
+   (set (attr "length") (cond [(eq_attr "is_vle" "yes") (const_int 2)]
+			      (const_int 4)))])
 
 (define_expand "indirect_jump"
   [(set (pc) (match_operand 0 "register_operand" ""))])
@@ -14796,8 +15807,8 @@
   [(set (pc) (match_operand:P 0 "register_operand" "c,*l"))]
   ""
   "@
-   bctr
-   blr"
+   %+bctr
+   %+blr"
   [(set_attr "type" "jmpreg")])
 
 ;; Table jump for switch statements:
@@ -14848,14 +15859,17 @@
    (use (label_ref (match_operand 1 "" "")))]
   ""
   "@
-   bctr
-   blr"
+   %+bctr
+   %+blr"
   [(set_attr "type" "jmpreg")])
 
 (define_insn "nop"
   [(const_int 0)]
   ""
-  "nop")
+  "*
+{
+  return \"%+nop\";
+}")
 
 (define_insn "group_ending_nop"
   [(unspec [(const_int 0)] UNSPEC_GRP_END_NOP)]
@@ -14928,9 +15942,9 @@
   if (which_alternative != 0)
     return \"#\";
   else if (get_attr_length (insn) == 4)
-    return \"bdnz %l0\";
-  else
-    return \"bdz $+8\;b %l0\";
+    	return \"%^bdnz %l0\";
+  	else
+    	return \"%^bdz $+8\;%^b %l0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "*,12,16,16")])
@@ -14952,9 +15966,9 @@
   if (which_alternative != 0)
     return \"#\";
   else if (get_attr_length (insn) == 4)
-    return \"bdz %l0\";
-  else
-    return \"bdnz $+8\;b %l0\";
+    	return \"%^bdz %l0\";
+  	else
+    	return \"%^bdnz $+8\;%^b %l0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "*,12,16,16")])
@@ -14978,9 +15992,9 @@
   if (which_alternative != 0)
     return \"#\";
   else if (get_attr_length (insn) == 4)
-    return \"bdz %l0\";
+    return \"%^bdz %l0\";
   else
-    return \"bdnz $+8\;b %l0\";
+   	return \"%^bdnz $+8\;%^b %l0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "*,12,16,16")])
@@ -15002,9 +16016,9 @@
   if (which_alternative != 0)
     return \"#\";
   else if (get_attr_length (insn) == 4)
-    return \"bdnz %l0\";
+   	return \"%^bdnz %l0\";
   else
-    return \"bdz $+8\;b %l0\";
+   	return \"%^bdz $+8\;%^b %l0\";
 }"
   [(set_attr "type" "branch")
    (set_attr "length" "*,12,16,16")])
@@ -15137,15 +16152,15 @@
 		   [(set (match_operand:SI 1 "memory_operand" "=m")
 			 (match_operand:SI 2 "gpc_reg_operand" "r"))])]
   ""
-  "stw %2,%1"
+  "%^stw %2,%1"
   [(set_attr "type" "store")])
 
 (define_insn "*stmw"
   [(match_parallel 0 "stmw_operation"
 		   [(set (match_operand:SI 1 "memory_operand" "=m")
        			 (match_operand:SI 2 "gpc_reg_operand" "r"))])]
-  "TARGET_MULTIPLE"
-  "stmw %2,%1"
+  "TARGET_VLE_MULTIPLE"
+  "%^stmw %2,%1"
   [(set_attr "type" "store_ux")])
 
 ; The following comment applies to:
@@ -15171,7 +16186,7 @@
 		    (set (match_operand:P 2 "memory_operand" "=m")
 			 (match_operand:P 3 "gpc_reg_operand" "r"))])]
   ""
-  "bl %1"
+  "%^bl %1"
   [(set_attr "type" "branch")
    (set_attr "length" "4")])
 
@@ -15183,7 +16198,7 @@
 		    (set (match_operand:P 2 "memory_operand" "=m")
 			 (match_operand:P 3 "gpc_reg_operand" "r"))])]
   ""
-  "bl %1"
+  "%^bl %1"
   [(set_attr "type" "branch")
    (set_attr "length" "4")])
 
@@ -15303,8 +16318,8 @@
   [(match_parallel 0 "lmw_operation"
 		   [(set (match_operand:SI 1 "gpc_reg_operand" "=r")
        			 (match_operand:SI 2 "memory_operand" "m"))])]
-  "TARGET_MULTIPLE"
-  "lmw %1,%2"
+  "TARGET_VLE_MULTIPLE"
+  "%^lmw %1,%2"
   [(set_attr "type" "load_ux")
    (set_attr "cell_micro" "always")])
 
@@ -15312,7 +16327,7 @@
   [(simple_return)
    (use (match_operand:P 0 "register_operand" "lc"))]
   ""
-  "b%T0"
+  "%+b%T0"
   [(set_attr "type" "jmpreg")])
 
 ; FIXME: This would probably be somewhat simpler if the Cygnus sibcall
@@ -15341,7 +16356,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "bl %2"
+ "%^bl %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15353,7 +16368,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "bl %2"
+ "%^bl %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15365,7 +16380,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "bl %2"
+ "%^bl %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15378,7 +16393,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15391,7 +16406,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15404,7 +16419,7 @@
 		   (set (match_operand:P 3 "gpc_reg_operand" "=r")
 			(match_operand:P 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15417,7 +16432,7 @@
 		   (set (match_operand:DF 3 "gpc_reg_operand" "=d")
 			(match_operand:DF 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15430,7 +16445,7 @@
 		   (set (match_operand:DF 3 "gpc_reg_operand" "=d")
 			(match_operand:DF 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15443,7 +16458,7 @@
 		   (set (match_operand:DF 3 "gpc_reg_operand" "=d")
 			(match_operand:DF 4 "memory_operand" "m"))])]
  ""
- "b %2"
+ "%^b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -15455,7 +16470,7 @@
 		   (use (reg:P 11))
 		   (set (match_operand:DF 3 "gpc_reg_operand" "=d")
 			(match_operand:DF 4 "memory_operand" "m"))])]
- ""
+ "!TARGET_VLE"
  "b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
@@ -15468,7 +16483,7 @@
 		   (use (reg:P 1))
 		   (set (match_operand:DF 3 "gpc_reg_operand" "=d")
 			(match_operand:DF 4 "memory_operand" "m"))])]
- ""
+ "!TARGET_VLE"
  "b %2"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
@@ -15680,6 +16695,14 @@
 	       "cmpw %2,%0,%1\;"
 	       "bne- %2,$-16";
       }
+    else if (TARGET_VLE)
+      {
+        return "mftbu %0\;"
+	       "mftb %L0\;"
+	       "mftbu %1\;"
+	       "cmpw %2,%0,%1\;"
+	       "e_bne %2,$-16";
+      }
     else
       {
         return "mftbu %0\;"
@@ -15697,6 +16720,14 @@
 	       "cmpw %2,%L0,%1\;"
 	       "bne- %2,$-16";
       }
+    else if (TARGET_VLE)
+      {
+        return "mftbu %L0\;"
+	       "mftb %0\;"
+	       "mftbu %1\;"
+	       "cmpw %2,%L0,%1\;"
+	       "e_bne %2,$-16";
+      }
     else
       {
         return "mftbu %L0\;"
diff --git a/gcc/config/rs6000/rs6000.opt b/gcc/config/rs6000/rs6000.opt
index 1da8ac5..90fb016 100644
--- a/gcc/config/rs6000/rs6000.opt
+++ b/gcc/config/rs6000/rs6000.opt
@@ -152,6 +152,10 @@ maltivec2
 Target Report Mask(ALTIVEC2) Var(rs6000_isa_flags)
 Use AltiVec PowerPC V2.07 instructions
 
+mvle
+Target Report Mask(VLE) Var(rs6000_isa_flags)
+Use VLE instructions
+
 mhard-dfp
 Target Report Mask(DFP) Var(rs6000_isa_flags)
 Use decimal floating point instructions
diff --git a/gcc/config/rs6000/spe.h b/gcc/config/rs6000/spe.h
index f84741e..fb3d18b 100644
--- a/gcc/config/rs6000/spe.h
+++ b/gcc/config/rs6000/spe.h
@@ -28,12 +28,7 @@
 
 #define __vector __attribute__((vector_size(8)))
 
-typedef int 	 		int32_t;
-typedef unsigned 		uint32_t;
-typedef short    		int16_t;
-typedef unsigned short  	uint16_t;
-typedef long long 		int64_t;
-typedef unsigned long long	uint64_t;
+#include <stdint.h>
 
 typedef short 			__vector __ev64_s16__;
 typedef unsigned short  	__vector __ev64_u16__;
diff --git a/gcc/config/rs6000/spe.md b/gcc/config/rs6000/spe.md
index ad7eaf0..548c1a0 100644
--- a/gcc/config/rs6000/spe.md
+++ b/gcc/config/rs6000/spe.md
@@ -2288,9 +2288,9 @@
 	known to be dead.  */
       if (refers_to_regno_p (REGNO (operands[0]), REGNO (operands[0]) + 1,
 			     operands[1], 0))
-	return \"lwz %L0,%L1\;lwz %0,%1\";
+	return \"%^lwz %L0,%L1\;%^lwz %0,%1\";
       else
-        return \"lwz%U1%X1 %0,%1\;lwz %L0,%L1\";
+        return \"%e1lwz%U1%X1 %0,%1\;%^lwz %L0,%L1\";
     }
 }"
   [(set_attr "length" "8,8")])
@@ -2314,9 +2314,9 @@
 	return \"evldd%X1 %Z0,%y1\;evmergehi %Y0,%Z0,%Z0\";
       if (refers_to_regno_p (REGNO (operands[0]), REGNO (operands[0]) + 1,
 			     operands[1], 0))
-	return \"lwz %Z0,%L1\;lwz %Y0,%1\";
+	return \"%^lwz %Z0,%L1\;%^lwz %Y0,%1\";
       else
-        return \"lwz%U1%X1 %Y0,%1\;lwz %Z0,%L1\";
+        return \"%e1lwz%U1%X1 %Y0,%1\;%^lwz %Z0,%L1\";
     }
 }"
   [(set_attr "length" "8,8")])
@@ -2335,7 +2335,7 @@
    || (TARGET_SPE && <MODE>mode != DFmode && <MODE>mode != TFmode)"
   "@
    evmergelo %0,%1,%0
-   evmergelohi %0,%0,%0\;lwz%U1%X1 %0,%1\;evmergelohi %0,%0,%0"
+   evmergelohi %0,%0,%0\;%e1lwz%U1%X1 %0,%1\;evmergelohi %0,%0,%0"
   [(set_attr "length" "4,12")])
 
 (define_insn_and_split "*mov_si<mode>_e500_subreg0_elf_low"
@@ -2365,7 +2365,7 @@
    || (TARGET_SPE && <MODE>mode != DFmode && <MODE>mode != TFmode)"
   "@
    evmergehi %0,%0,%1
-   evmergelohi %1,%1,%1\;stw%U0%X0 %1,%0"
+   evmergelohi %1,%1,%1\;%e0stw%U0%X0 %1,%0"
   [(set_attr "length" "4,8")])
 
 (define_insn "*mov_si<mode>_e500_subreg4"
@@ -2375,7 +2375,7 @@
    || (TARGET_SPE && <MODE>mode != DFmode && <MODE>mode != TFmode)"
   "@
    mr %0,%1
-   lwz%U1%X1 %0,%1")
+   %e1lwz%U1%X1 %0,%1")
 
 (define_insn "*mov_si<mode>_e500_subreg4_elf_low"
   [(set (subreg:SI (match_operand:SPE64TF 0 "register_operand" "+r") 4)
@@ -2393,7 +2393,7 @@
    || (TARGET_SPE && <MODE>mode != DFmode && <MODE>mode != TFmode)"
   "@
    mr %0,%1
-   stw%U0%X0 %1,%0")
+   %e0stw%U0%X0 %1,%0")
 
 (define_insn "*mov_sitf_e500_subreg8"
   [(set (subreg:SI (match_operand:TF 0 "register_operand" "+r,&r") 8)
@@ -2401,7 +2401,7 @@
   "TARGET_E500_DOUBLE"
   "@
    evmergelo %L0,%1,%L0
-   evmergelohi %L0,%L0,%L0\;lwz%U1%X1 %L0,%1\;evmergelohi %L0,%L0,%L0"
+   evmergelohi %L0,%L0,%L0\;%e0lwz%U1%X1 %L0,%1\;evmergelohi %L0,%L0,%L0"
   [(set_attr "length" "4,12")])
 
 (define_insn "*mov_sitf_e500_subreg8_2"
@@ -2410,7 +2410,7 @@
   "TARGET_E500_DOUBLE"
   "@
    evmergehi %0,%0,%L1
-   evmergelohi %L1,%L1,%L1\;stw%U0%X0 %L1,%0"
+   evmergelohi %L1,%L1,%L1\;%e0stw%U0%X0 %L1,%0"
   [(set_attr "length" "4,8")])
 
 (define_insn "*mov_sitf_e500_subreg12"
@@ -2419,7 +2419,7 @@
   "TARGET_E500_DOUBLE"
   "@
    mr %L0,%1
-   lwz%U1%X1 %L0,%1")
+   %e1lwz%U1%X1 %L0,%1")
 
 (define_insn "*mov_sitf_e500_subreg12_2"
   [(set (match_operand:SI 0 "rs6000_nonimmediate_operand" "+r,m")
@@ -2427,7 +2427,7 @@
   "TARGET_E500_DOUBLE"
   "@
    mr %0,%L1
-   stw%U0%X0 %L1,%0")
+   %e0stw%U0%X0 %L1,%0")
 
 ;; FIXME: Allow r=CONST0.
 (define_insn "*movdf_e500_double"
@@ -2572,7 +2572,7 @@
    (clobber (match_operand:SI 4 "gpc_reg_operand" "=&r"))]
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128"
-  "mfspefscr %3\;rlwinm %4,%3,0,0,29\;ori %4,%4,1\;efdadd %2,%1,%L1\;mtspefscr %3\;efdctsiz %0, %2"
+  "mfspefscr %3\;%^rlwinm %4,%3,0,0,29\;%^ori %4,%4,1\;efdadd %2,%1,%L1\;mtspefscr %3\;efdctsiz %0, %2"
   [(set_attr "length" "24")])
 
 (define_insn "spe_negtf2_internal"
@@ -3097,7 +3097,7 @@
 ;; Same thing, but for IBM long double.
 
 (define_insn "cmptfeq_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3105,12 +3105,12 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && !(flag_finite_math_only && !flag_trapping_math)"
-  "efdcmpeq %0,%1,%2\;bng %0,$+8\;efdcmpeq %0,%L1,%L2"
+  "efdcmpeq %0,%1,%2\;%^bng %0,$+8\;efdcmpeq %0,%L1,%L2"
   [(set_attr "type" "veccmp")
    (set_attr "length" "12")])
 
 (define_insn "tsttfeq_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3118,12 +3118,12 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && flag_finite_math_only && !flag_trapping_math"
-  "efdtsteq %0,%1,%2\;bng %0,$+8\;efdtsteq %0,%L1,%L2"
+  "efdtsteq %0,%1,%2\;%^bng %0,$+8\;efdtsteq %0,%L1,%L2"
   [(set_attr "type" "veccmpsimple")
    (set_attr "length" "12")])
 
 (define_insn "cmptfgt_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3131,12 +3131,12 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && !(flag_finite_math_only && !flag_trapping_math)"
-  "efdcmpgt %0,%1,%2\;bgt %0,$+16\;efdcmpeq %0,%1,%2\;bng %0,$+8\;efdcmpgt %0,%L1,%L2"
+  "efdcmpgt %0,%1,%2\;%^bgt %0,$+16\;efdcmpeq %0,%1,%2\;%^bng %0,$+8\;efdcmpgt %0,%L1,%L2"
   [(set_attr "type" "veccmp")
    (set_attr "length" "20")])
 
 (define_insn "tsttfgt_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3144,12 +3144,12 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && flag_finite_math_only && !flag_trapping_math"
-  "efdtstgt %0,%1,%2\;bgt %0,$+16\;efdtsteq %0,%1,%2\;bng %0,$+8\;efdtstgt %0,%L1,%L2"
+  "efdtstgt %0,%1,%2\;%^bgt %0,$+16\;efdtsteq %0,%1,%2\;%^bng %0,$+8\;efdtstgt %0,%L1,%L2"
   [(set_attr "type" "veccmpsimple")
    (set_attr "length" "20")])
 
 (define_insn "cmptflt_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3157,12 +3157,12 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && !(flag_finite_math_only && !flag_trapping_math)"
-  "efdcmplt %0,%1,%2\;bgt %0,$+16\;efdcmpeq %0,%1,%2\;bng %0,$+8\;efdcmplt %0,%L1,%L2"
+  "efdcmplt %0,%1,%2\;%^bgt %0,$+16\;efdcmpeq %0,%1,%2\;%^bng %0,$+8\;efdcmplt %0,%L1,%L2"
   [(set_attr "type" "veccmp")
    (set_attr "length" "20")])
 
 (define_insn "tsttflt_gpr"
-  [(set (match_operand:CCFP 0 "cc_reg_operand" "=y")
+  [(set (match_operand:CCFP 0 "cmpi_cc_reg_operand" "=kcrxx")
 	(unspec:CCFP
 	 [(compare:CCFP (match_operand:TF 1 "gpc_reg_operand" "r")
 			(match_operand:TF 2 "gpc_reg_operand" "r"))]
@@ -3170,7 +3170,7 @@
   "!TARGET_IEEEQUAD
    && TARGET_HARD_FLOAT && TARGET_E500_DOUBLE && TARGET_LONG_DOUBLE_128
    && flag_finite_math_only && !flag_trapping_math"
-  "efdtstlt %0,%1,%2\;bgt %0,$+16\;efdtsteq %0,%1,%2\;bng %0,$+8\;efdtstlt %0,%L1,%L2"
+  "efdtstlt %0,%1,%2\;%^bgt %0,$+16\;efdtsteq %0,%1,%2\;%^bng %0,$+8\;efdtstlt %0,%L1,%L2"
   [(set_attr "type" "veccmpsimple")
    (set_attr "length" "20")])
 
@@ -3181,7 +3181,7 @@
 		      (match_operand 2 "cc_reg_operand" "y")]
 		     E500_CR_IOR_COMPARE))]
   "TARGET_HARD_FLOAT && !TARGET_FPRS"
-  "cror 4*%0+gt,4*%1+gt,4*%2+gt"
+  "%^cror 4*%0+gt,4*%1+gt,4*%2+gt"
   [(set_attr "type" "cr_logical")])
 
 ;; Out-of-line prologues and epilogues.
@@ -3193,7 +3193,7 @@
 		    (set (match_operand:V2SI 2 "memory_operand" "=m")
 			 (match_operand:V2SI 3 "gpc_reg_operand" "r"))])]
   "TARGET_SPE_ABI"
-  "bl %z1"
+  "%^bl %z1"
   [(set_attr "type" "branch")
    (set_attr "length" "4")])
 
@@ -3205,7 +3205,7 @@
 		   (set (match_operand:V2SI 2 "gpc_reg_operand" "=r")
 			(match_operand:V2SI 3 "memory_operand" "m"))])]
  "TARGET_SPE_ABI"
- "bl %z1"
+ "%^bl %z1"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
 
@@ -3218,6 +3218,6 @@
 		   (set (match_operand:V2SI 2 "gpc_reg_operand" "=r")
 			(match_operand:V2SI 3 "memory_operand" "m"))])]
  "TARGET_SPE_ABI"
- "b %z1"
+ "%^b %z1"
  [(set_attr "type" "branch")
   (set_attr "length" "4")])
diff --git a/gcc/config/rs6000/sync.md b/gcc/config/rs6000/sync.md
index 63152ed..37c4512 100644
--- a/gcc/config/rs6000/sync.md
+++ b/gcc/config/rs6000/sync.md
@@ -104,7 +104,7 @@
 (define_insn "isync"
   [(unspec_volatile:BLK [(const_int 0)] UNSPECV_ISYNC)]
   ""
-  "isync"
+  "%+isync"
   [(set_attr "type" "isync")])
 
 ;; Types that we should provide atomic instructions for.
@@ -119,9 +119,9 @@
 (define_insn "loadsync_<mode>"
   [(unspec_volatile:BLK [(match_operand:AINT 0 "register_operand" "r")]
 			UNSPECV_ISYNC)
-   (clobber (match_scratch:CC 1 "=y"))]
+   (clobber (match_scratch:CC 1 "=kcreg"))]
   ""
-  "cmpw %1,%0,%0\;bne- %1,$+4\;isync"
+  "cmpw %1,%0,%0\;%^bne%- %1,$+4\;%+isync"
   [(set_attr "type" "isync")
    (set_attr "length" "12")])
 
diff --git a/gcc/config/rs6000/sysv4.h b/gcc/config/rs6000/sysv4.h
index 6196fb3..e6d74d9 100644
--- a/gcc/config/rs6000/sysv4.h
+++ b/gcc/config/rs6000/sysv4.h
@@ -300,6 +300,7 @@ do {									\
 /* Use ELF style section commands.  */
 
 #define	TEXT_SECTION_ASM_OP	"\t.section\t\".text\""
+#define	TEXT_SECTION_ASM_OP_BOOKE	"\t.section\t\".text\""
 
 #define	DATA_SECTION_ASM_OP	"\t.section\t\".data\""
 
diff --git a/gcc/config/rs6000/t-e200 b/gcc/config/rs6000/t-e200
new file mode 100644
index 0000000..9572d97
--- /dev/null
+++ b/gcc/config/rs6000/t-e200
@@ -0,0 +1,18 @@
+# Multilibs for powerpc e200 embedded ELF targets.
+# Note: "fshort-double" "spfp" "fshort-double fshort-double/*" removed because it is not available in fortran
+# What we really want are these variants:
+#	-mcpu=e200z[023467]
+#	-mcpu=e200z[023467] -fshort-double
+#	-mcpu=e200z[023467] -msoft-float
+#	-mcpu=e200z[3467] -mspe
+# so we'll need to create exceptions later below.
+
+MULTILIB_OPTIONS    = mcpu=e200z2/mcpu=e200z3/mcpu=e200z4/mcpu=e200z6/mcpu=e200z7 mhard-float mspe mno-vle
+
+MULTILIB_DIRNAMES	= e200z2 e200z3 e200z4 e200z6 e200z7 fp spe booke
+
+MULTILIB_EXTRA_OPTS	= mstrict-align
+
+MULTILIB_EXCEPTIONS	= mhard-float mhard-float/* mspe mspe/* mno-vle mno-vle/* \
+			  mcpu=e200z2/*mspe*
+
diff --git a/gcc/cse.c b/gcc/cse.c
index 9b8b816..6b45d28 100644
--- a/gcc/cse.c
+++ b/gcc/cse.c
@@ -6178,6 +6178,11 @@ cse_process_notes_1 (rtx x, rtx object, bool *changed)
       validate_change (object, &XEXP (x, i),
 		       cse_process_notes (XEXP (x, i), object, changed), 0);
 
+  /* Rebuild a PLUS expression in canonical form if the first operand
+     ends up as a constant.  */
+  if (code == PLUS && GET_CODE (XEXP (x, 0)) == CONST_INT)
+    return plus_constant (GET_MODE (x), XEXP(x, 1), INTVAL (XEXP (x, 0)));
+
   return x;
 }
 
diff --git a/gcc/doc/md.texi b/gcc/doc/md.texi
index e7f4b8b..c22fcd7 100644
--- a/gcc/doc/md.texi
+++ b/gcc/doc/md.texi
@@ -2111,6 +2111,15 @@ Floating point register (containing 64-bit value)
 @item f
 Floating point register (containing 32-bit value)
 
+@item kareg
+Alternate General Purpose Register in the range r8-r23 to be used in VLE
+
+@item kcreg
+CR fields from Field 0 to Field 3 to be used in VLE
+
+@item kregs
+General Purpose Register in the ranges r0-r7 or r24-r31 to be used in VLE
+
 @item v
 Altivec vector register
 
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0048.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0048.c
new file mode 100644
index 0000000..4cc1f3b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0048.c
@@ -0,0 +1,22 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O2 -mvle" } */
+
+/* CMPE200GCC-48: ICE: insn does not satisfy its constraints *cmpsi_arithmetic_vle */
+
+char a;
+int b, f;
+long c;
+long *d;
+short e;
+void fn1(int p1) {
+  for (;;) {
+    long *g = &c;
+    f = a >> b;
+    *d = !f;
+    for (; c;)
+      ;
+    e = p1;
+    *g = e || p1;
+  }
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0049.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0049.c
new file mode 100644
index 0000000..b9d2c01
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0049.c
@@ -0,0 +1,22 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O1 -mvle" } */
+
+/* CMPE200GCC-49: ICE: in final_scan_insn, at final.c:2952 @ {*rs6000.md:2268} */
+
+long *a;
+long b, c;
+short d;
+void fn1(long long p1) {
+lbl_3528:
+  for (; b;) {
+    long e;
+    *a = e > p1 <= p1;
+  }
+  if (p1) {
+    d = p1;
+    c = d - p1;
+    if (c)
+      goto lbl_3528;
+  }
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0050.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0050.c
new file mode 100644
index 0000000..c1e2411
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0050.c
@@ -0,0 +1,8 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O2 -mvle" } */
+
+/* CMPE200GCC-50: illegal immediate value in "e_subfic" */
+
+long long a, b;
+main() { b = 777 - a; }
\ No newline at end of file
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0051.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0051.c
new file mode 100644
index 0000000..015616d
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0051.c
@@ -0,0 +1,18 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-w -O1 -mvle" } */
+
+/* CMPE200GCC-51: internal compiler error: in final_scan_insn, at final.c:2952 @ {*andsi3_internal4} */
+
+struct {
+  unsigned f3 : 23
+} a;
+b, c;
+fn1() {
+lbl_1964:
+  if (b)
+    if (a.f3)
+      goto lbl_1964;
+    else
+      c = 0;
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0052.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0052.c
new file mode 100644
index 0000000..e0cd341
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0052.c
@@ -0,0 +1,24 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O2 -mcpu=e200z4" } */
+/* { dg-final { scan-assembler "isel" } } */
+
+/* CMPE200GCC-52: ISEL instruction is not enabled by default for e200zX cores. */
+
+int gen_isel(int c)
+{
+  if ((unsigned int)c > 50)
+    {
+      c = 5;
+    }
+else if ((unsigned int)c > 30)
+    {
+      c = -1;
+    }
+else
+    {
+      c = 5;
+    }
+
+return c;
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0092.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0092.c
new file mode 100644
index 0000000..0d25444
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0092.c
@@ -0,0 +1,27 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O1 -mvle" } */
+
+/* CMPE200GCC-92: internal compiler error: in validate_condition_mode, at config/rs6000/rs6000.c:16601 */
+
+typedef unsigned char uint8_t;
+typedef long int int32_t;
+
+
+static uint8_t
+(safe_rshift_func_uint8_t_u_u)(uint8_t left, unsigned int right )
+{
+  return (left >> ((unsigned int)right));
+}
+
+
+fn1(p_39)
+{
+  int32_t l_711[1][3][3];
+  int i, j, k;
+  for (i = j = 0; j < 3; j++)
+    for (k = 0; k < 3; k++)
+      l_711[i][j][k] = 1;
+  g_705safe_div_func_int32_t_s_s(
+      safe_rshift_func_uint8_t_u_u(p_39, l_711[0][1][1]) >= p_39);
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0093.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0093.c
new file mode 100644
index 0000000..7702d93
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0093.c
@@ -0,0 +1,22 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-w -O3 -mvle" } */
+
+/* CMPE200GCC-93: ICE: in final_scan_insn, at final.c:2952 @ {*rs6000.md:5825} */
+
+
+a, b;
+fn1() {
+  for (;;) {
+    char c[] = {4, 5, 4, 5, 4, 5, 4, 5};
+    if (c[0]) {
+      a = 6;
+      for (;; a--)
+        if (c[a])
+          break;
+    }
+    for (; b;)
+      for (;;)
+        ;
+  }
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0103.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0103.c
new file mode 100644
index 0000000..204c2c7
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0103.c
@@ -0,0 +1,27 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O2 -mvle" } */
+/* { dg-final { scan-assembler-not "e_andi\\. \[0-9\]+,\[0-9\]+,-129" } } */
+
+/* CMPE200GCC-103: Incorrect optimization of bitfield */
+
+typedef unsigned short int  uint16_t;
+typedef struct
+{
+    volatile uint16_t field1:6;
+    volatile uint16_t field2:3;
+    volatile uint16_t field3:7;
+} test_struct_S;
+ test_struct_S test_struct = { .field1 = 1, .field2 = 7, .field3 = 0 };  // 0x0780
+
+int main(void)
+{
+volatile int counter = 0;
+
+if(test_struct.field3 == 0)
+ {
+   test_struct.field1 = 2;
+ }
+
+return counter;
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0118.c b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0118.c
new file mode 100644
index 0000000..317dc89
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/cmpe200gcc-0118.c
@@ -0,0 +1,27 @@
+/* { dg-do compile { target { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O3 -mvle" } */
+
+/* CMPE200GCC-118: ICE: in final_scan_insn, at final.c:2952 @ *rs6000.md:6439*/
+
+int a, b, c, e;
+long long d[7];
+long long f;
+unsigned short g;
+fn1() {
+  for (;;) {
+    long h = 1;
+    c = 0;
+    for (; c <= 4; c++) {
+      g = d[e];
+      *d = (f = g) >= a;
+    }
+    for (;; h++) {
+      if (d[h])
+        break;
+      d[h + 2] = 8062120543989913884;
+    }
+    if (b)
+      break;
+  }
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/lsp-builtin.c b/gcc/testsuite/gcc.target/powerpc/lsp-builtin.c
new file mode 100644
index 0000000..a2b1d82
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/lsp-builtin.c
@@ -0,0 +1,1409 @@
+/* { dg-xfail-if "LSP builtins aren't implemented yet CMPE200GCC-124" { *-*-* } } */
+/* { dg-do compile { xfail { powerpc-*-*vle } } } */
+/* { dg-skip-if "not a VLE target" { !powerpc-*-*vle } { "*" } { "" } } */
+/* { dg-options "-O0 -mvle -mlsp" } */
+/* { dg-final { xfail {scan-assembler "zvaddih" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubifh" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddh" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfh" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfh" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddh" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddhx" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfhx" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfhx" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddhx" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddhus" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfhus" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddhxss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfhxss" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfhxss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddhxss" } } } */
+/* { dg-final { xfail {scan-assembler "zvmergehih" } } } */
+/* { dg-final { xfail {scan-assembler "zvmergeloh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmergehiloh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmergelohih" } } } */
+/* { dg-final { xfail {scan-assembler "zvpkshgwshfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvpkswshfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvpkswuhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvpkswshs" } } } */
+/* { dg-final { xfail {scan-assembler "zvpkuwuhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvsplatih" } } } */
+/* { dg-final { xfail {scan-assembler "zvsplatfih" } } } */
+/* { dg-final { xfail {scan-assembler "zcntlsw" } } } */
+/* { dg-final { xfail {scan-assembler "zvcntlzh" } } } */
+/* { dg-final { xfail {scan-assembler "zvcntlsh" } } } */
+/* { dg-final { xfail {scan-assembler "znegws" } } } */
+/* { dg-final { xfail {scan-assembler "zvnegh" } } } */
+/* { dg-final { xfail {scan-assembler "zvneghs" } } } */
+/* { dg-final { xfail {scan-assembler "zvnegho" } } } */
+/* { dg-final { xfail {scan-assembler "zvneghos" } } } */
+/* { dg-final { xfail {scan-assembler "zrndwh" } } } */
+/* { dg-final { xfail {scan-assembler "zrndwhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvabsh" } } } */
+/* { dg-final { xfail {scan-assembler "zvabshs" } } } */
+/* { dg-final { xfail {scan-assembler "zabsw" } } } */
+/* { dg-final { xfail {scan-assembler "zabsws" } } } */
+/* { dg-final { xfail {scan-assembler "zsatswuw" } } } */
+/* { dg-final { xfail {scan-assembler "zsatuwsw" } } } */
+/* { dg-final { xfail {scan-assembler "zsatswuh" } } } */
+/* { dg-final { xfail {scan-assembler "zsatswsh" } } } */
+/* { dg-final { xfail {scan-assembler "zvsatshuh" } } } */
+/* { dg-final { xfail {scan-assembler "zvsatuhsh" } } } */
+/* { dg-final { xfail {scan-assembler "zsatuwuh" } } } */
+/* { dg-final { xfail {scan-assembler "zsatuwsh" } } } */
+/* { dg-final { xfail {scan-assembler "zsatsduw" } } } */
+/* { dg-final { xfail {scan-assembler "zsatsdsw" } } } */
+/* { dg-final { xfail {scan-assembler "zsatuduw" } } } */
+/* { dg-final { xfail {scan-assembler "zdivwsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvsrhu" } } } */
+/* { dg-final { xfail {scan-assembler "zvsrhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvsrhiu" } } } */
+/* { dg-final { xfail {scan-assembler "zvsrhis" } } } */
+/* { dg-final { xfail {scan-assembler "zvslh" } } } */
+/* { dg-final { xfail {scan-assembler "zvrlh" } } } */
+/* { dg-final { xfail {scan-assembler "zvslhi" } } } */
+/* { dg-final { xfail {scan-assembler "zvrlhi" } } } */
+/* { dg-final { xfail {scan-assembler "zvslhus" } } } */
+/* { dg-final { xfail {scan-assembler "zvslhss" } } } */
+/* { dg-final { xfail {scan-assembler "zvslhius" } } } */
+/* { dg-final { xfail {scan-assembler "zvslhiss" } } } */
+/* { dg-final { xfail {scan-assembler "zslwus" } } } */
+/* { dg-final { xfail {scan-assembler "zslwss" } } } */
+/* { dg-final { xfail {scan-assembler "zslwius" } } } */
+/* { dg-final { xfail {scan-assembler "zslwiss" } } } */
+/* { dg-final { xfail {scan-assembler "zaddwgui" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfwgui" } } } */
+/* { dg-final { xfail {scan-assembler "zaddwgsi" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfwgsi" } } } */
+/* { dg-final { xfail {scan-assembler "zaddwgsf" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfwgsf" } } } */
+/* { dg-final { xfail {scan-assembler "zaddd" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfd" } } } */
+/* { dg-final { xfail {scan-assembler "zadddss" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfdss" } } } */
+/* { dg-final { xfail {scan-assembler "zadddus" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfdus" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfw" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddw" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddw" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfw" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddsubfwss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfaddwss" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddwss" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfwss" } } } */
+/* { dg-final { xfail {scan-assembler "zvaddwus" } } } */
+/* { dg-final { xfail {scan-assembler "zvsubfwus" } } } */
+/* { dg-final { xfail {scan-assembler "zvunpkhgwsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvunpkhsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvunpkhui" } } } */
+/* { dg-final { xfail {scan-assembler "zvunpkhsi" } } } */
+/* { dg-final { xfail {scan-assembler "zunpkwgsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwasmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgwasmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgwssmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfanp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulgwsmfranp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfanp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllgwsmfranp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfanp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuugwsmfranp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfanp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlgwsmfranp" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogwsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsi" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogui" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsi" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsui" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsi" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgaui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgaui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasmf" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgsui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmheguiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgauiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheguian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgauian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhegsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgasmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmheoguiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgauiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheoguian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgauian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheogsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxgasmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmhoguiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhoguian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhogsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphgssmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgui" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsi" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsui" } } } */
+/* { dg-final { xfail {scan-assembler "zmwguiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwguian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwguiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwguians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmf" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmfaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmfraa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmfan" } } } */
+/* { dg-final { xfail {scan-assembler "zmwgsmfran" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsf" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfr" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhului" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsi" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsi" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusi" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsi" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlui" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuluianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsuianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfanps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhulsfranps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhlluianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsuianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfanps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhllsfranps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuuuianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusuianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfanps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuusfranps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxluianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuianp" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsuianps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfanps" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhxlsfranps" } } } */
+/* { dg-final { xfail {scan-assembler "zmheui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesi" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesui" } } } */
+/* { dg-final { xfail {scan-assembler "zmheoui" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosi" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhoui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosi" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosui" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesf" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosf" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosf" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmheuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesfans" } } } */
+/* { dg-final { xfail {scan-assembler "zmhesfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zmheouiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheouiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheouian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheouians" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosians" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosfans" } } } */
+/* { dg-final { xfail {scan-assembler "zmheosfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zmhouiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhouiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhouian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhouians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosuian" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosfans" } } } */
+/* { dg-final { xfail {scan-assembler "zmhosfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuih" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuih" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuih" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuihs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsihs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsuihs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuiaah" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuiaah" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuiaah" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuianh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuianh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuianh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuiaahs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhuianhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsiaahs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsianhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsuiaahs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsuianhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfrh" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfaahs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfraahs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfanhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvmhsfranhs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphaui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphauis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasuis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphauiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphauiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphauian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphauians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphasfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxaui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxauis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasuis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxauiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxauiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxauian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxauians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphxasuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssi" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssui" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsuis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssuis" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssuiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssuian" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssuians" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfans" } } } */
+/* { dg-final { xfail {scan-assembler "zvdotphssfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluiaa" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluian" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluis" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsis" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsuis" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsuiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwlsuians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluiaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwluians" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsf" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsfr" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsfaas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsfraas" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsfans" } } } */
+/* { dg-final { xfail {scan-assembler "zmwsfrans" } } } */
+/* { dg-final { xfail {scan-assembler "zaddwus" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfwus" } } } */
+/* { dg-final { xfail {scan-assembler "zaddwss" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfwss" } } } */
+/* { dg-final { xfail {scan-assembler "zaddheuw" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfheuw" } } } */
+/* { dg-final { xfail {scan-assembler "zaddhesw" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfhesw" } } } */
+/* { dg-final { xfail {scan-assembler "zaddhouw" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfhouw" } } } */
+/* { dg-final { xfail {scan-assembler "zaddhosw" } } } */
+/* { dg-final { xfail {scan-assembler "zsubfhosw" } } } */
+/* { dg-final { xfail {scan-assembler "zpkswgshfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zpkswgswfrs" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmpgthu" } } } */
+/* { dg-final { xfail {scan-assembler "zvselh" } } } */
+/* { dg-final { xfail {scan-assembler "zxtrw" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmpgthu" } } } */
+/* { dg-final { xfail {scan-assembler "zbrminc" } } } */
+/* { dg-final { xfail {scan-assembler "zcircinc" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmpgthu" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmpgthu" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmplthu" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmplthu" } } } */
+/* { dg-final { xfail {scan-assembler "zvcmpeqh" } } } */
+/* { dg-final { xfail {scan-assembler "zlddx" } } } */
+/* { dg-final { xfail {scan-assembler "zldd" } } } */
+/* { dg-final { xfail {scan-assembler "zldwx" } } } */
+/* { dg-final { xfail {scan-assembler "zldw" } } } */
+/* { dg-final { xfail {scan-assembler "zldhx" } } } */
+/* { dg-final { xfail {scan-assembler "zldh" } } } */
+/* { dg-final { xfail {scan-assembler "zlwgsfdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwgsfd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwosdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwosd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatwdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatwd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhgwsfdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhgwsfd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhedx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhed" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhosdx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhosd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhoudx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhoud" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwh" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwx" } } } */
+/* { dg-final { xfail {scan-assembler "zlww" } } } */
+/* { dg-final { xfail {scan-assembler "zlhgwsfx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhgwsf" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhsplatx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhsplat" } } } */
+/* { dg-final { xfail {scan-assembler "zstddx" } } } */
+/* { dg-final { xfail {scan-assembler "zstdd" } } } */
+/* { dg-final { xfail {scan-assembler "zstdwx" } } } */
+/* { dg-final { xfail {scan-assembler "zstdw" } } } */
+/* { dg-final { xfail {scan-assembler "zstdhx" } } } */
+/* { dg-final { xfail {scan-assembler "zstdh" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhedx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhed" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhodx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhod" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhex" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhe" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhosx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhos" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhoux" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhou" } } } */
+/* { dg-final { xfail {scan-assembler "zsthex" } } } */
+/* { dg-final { xfail {scan-assembler "zsthe" } } } */
+/* { dg-final { xfail {scan-assembler "zsthox" } } } */
+/* { dg-final { xfail {scan-assembler "zstho" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwh" } } } */
+/* { dg-final { xfail {scan-assembler "zstwwx" } } } */
+/* { dg-final { xfail {scan-assembler "zstww" } } } */
+/* { dg-final { xfail {scan-assembler "zlddmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlddu" } } } */
+/* { dg-final { xfail {scan-assembler "zldwmx" } } } */
+/* { dg-final { xfail {scan-assembler "zldwu" } } } */
+/* { dg-final { xfail {scan-assembler "zldhmx" } } } */
+/* { dg-final { xfail {scan-assembler "zldhu" } } } */
+/* { dg-final { xfail {scan-assembler "zlwgsfdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwgsfd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwosdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwosd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatwdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatwd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhsplatd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhgwsfdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhgwsfd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhedmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhed" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhosdmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhosd" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhoudmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhoud" } } } */
+/* { dg-final { xfail {scan-assembler "zlwhmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlwh" } } } */
+/* { dg-final { xfail {scan-assembler "zlwwmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlww" } } } */
+/* { dg-final { xfail {scan-assembler "zlhgwsfmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhgwsf" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhsplatmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhsplat" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhemx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhe" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhosmx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhos" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhoumx" } } } */
+/* { dg-final { xfail {scan-assembler "zlhhou" } } } */
+/* { dg-final { xfail {scan-assembler "zstddmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstddu" } } } */
+/* { dg-final { xfail {scan-assembler "zstdwmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstdwu" } } } */
+/* { dg-final { xfail {scan-assembler "zstdhmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstdhu" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhedmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhed" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhodmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhod" } } } */
+/* { dg-final { xfail {scan-assembler "zsthemx" } } } */
+/* { dg-final { xfail {scan-assembler "zsthe" } } } */
+/* { dg-final { xfail {scan-assembler "zsthomx" } } } */
+/* { dg-final { xfail {scan-assembler "zstho" } } } */
+/* { dg-final { xfail {scan-assembler "zstwhmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstwh" } } } */
+/* { dg-final { xfail {scan-assembler "zstwwmx" } } } */
+/* { dg-final { xfail {scan-assembler "zstww" } } } */
+
+
+#include <lsp.h>
+
+void use_builtins (void * ptr_a, void * ptr_b, void * ptr_c)
+{
+/* input variables */
+volatile __lsp32_16__  in32_16_a, in32_16_b, in32_16_c;
+volatile __lsp32_32__  in32_32_a, in32_32_b, in32_32_c;
+volatile __lsp5_simm__ in5_simm = -1;
+volatile __lsp5_uimm__ in5_uimm = 31;
+volatile __lsp4_uimm__ in4_uimm = 15;
+volatile __lsp64_64__  in64_64;
+volatile __lsp64_32__  in64_32;
+volatile __lsp2_selmode__ in2_selmode;
+volatile __lsp3_cmpsel__ in3_cmpsel;
+volatile __lsp2_offset__ in2_offset;
+
+/* out variables */
+volatile __lsp32_16__ out32_16;
+volatile __lsp32_32__ out32_32;
+volatile __lsp64_64__ out64_32;
+volatile __lsp64_64__ out64_64;
+volatile __lsp4_crd__ out4_crd;
+
+
+out32_16 = __builtin_lsp_zvaddih           ( in32_16_a, in5_uimm );
+out32_16 = __builtin_lsp_zvsubifh          ( in32_16_a, in5_uimm );
+out32_16 = __builtin_lsp_zvaddh            ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfh           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddsubfh        ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfaddh        ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddhx           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfhx          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddsubfhx       ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfaddhx       ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddhus          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfhus         ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddhss          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfhss         ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddsubfhss      ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfaddhss      ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddhxss         ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfhxss        ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvaddsubfhxss     ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsubfaddhxss     ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmergehih        ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmergeloh        ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmergehiloh      ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmergelohih      ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvpkshgwshfrs     ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvpkswshfrs       ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvpkswuhs         ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvpkswshs         ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvpkuwuhs         ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvsplatih         ( in5_simm );
+out32_16 = __builtin_lsp_zvsplatfih        ( in5_simm );
+out32_32 = __builtin_lsp_zcntlsw           ( in32_32_a );
+out32_16 = __builtin_lsp_zvcntlzh          ( in32_16_a );
+out32_16 = __builtin_lsp_zvcntlsh          ( in32_16_a );
+out32_32 = __builtin_lsp_znegws            ( in32_32_a );
+out32_16 = __builtin_lsp_zvnegh            ( in32_16_a );
+out32_16 = __builtin_lsp_zvneghs           ( in32_16_a );
+out32_16 = __builtin_lsp_zvnegho           ( in32_16_a );
+out32_16 = __builtin_lsp_zvneghos          ( in32_16_a );
+out32_16 = __builtin_lsp_zrndwh            ( in32_32_a );
+out32_16 = __builtin_lsp_zrndwhss          ( in32_32_a );
+out32_16 = __builtin_lsp_zvabsh            ( in32_16_a );
+out32_16 = __builtin_lsp_zvabshs           ( in32_16_a );
+out32_32 = __builtin_lsp_zabsw             ( in32_32_a );
+out32_32 = __builtin_lsp_zabsws            ( in32_32_a );
+out32_32 = __builtin_lsp_zsatswuw          ( in32_32_a );
+out32_32 = __builtin_lsp_zsatuwsw          ( in32_32_a );
+out32_16 = __builtin_lsp_zsatswuh          ( in32_32_a );
+out32_16 = __builtin_lsp_zsatswsh          ( in32_32_a );
+out32_16 = __builtin_lsp_zvsatshuh         ( in32_16_a );
+out32_16 = __builtin_lsp_zvsatuhsh         ( in32_16_a );
+out32_16 = __builtin_lsp_zsatuwuh          ( in32_32_a );
+out32_16 = __builtin_lsp_zsatuwsh          ( in32_32_a );
+out32_32 = __builtin_lsp_zsatsduw          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zsatsdsw          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zsatuduw          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zdivwsf           ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvsrhu            ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsrhs            ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvsrhiu           ( in32_16_a, in4_uimm );
+out32_16 = __builtin_lsp_zvsrhis           ( in32_16_a, in4_uimm );
+out32_16 = __builtin_lsp_zvslh             ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvrlh             ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvslhi            ( in32_16_a, in4_uimm );
+out32_16 = __builtin_lsp_zvrlhi            ( in32_16_a, in4_uimm );
+out32_16 = __builtin_lsp_zvslhus           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvslhss           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvslhius          ( in32_16_a, in4_uimm );
+out32_16 = __builtin_lsp_zvslhiss          ( in32_16_a, in4_uimm );
+out32_32 = __builtin_lsp_zslwus            ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zslwss            ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zslwius           ( in32_32_a, in4_uimm );
+out32_32 = __builtin_lsp_zslwiss           ( in32_32_a, in4_uimm );
+out64_64 = __builtin_lsp_zaddwgui          ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zsubfwgui         ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zaddwgsi          ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zsubfwgsi         ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zaddwgsf          ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zsubfwgsf         ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zaddd             ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zsubfd            ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zadddss           ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zsubfdss          ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zadddus           ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zsubfdus          ( in64_64, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvaddsubfw        ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvsubfaddw        ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvaddw            ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvsubfw           ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvaddsubfwss      ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvsubfaddwss      ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvaddwss          ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvsubfwss         ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvaddwus          ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvsubfwus         ( in64_32, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvunpkhgwsf       ( in32_16_a );
+out64_32 = __builtin_lsp_zvunpkhsf         ( in32_16_a );
+out64_32 = __builtin_lsp_zvunpkhui         ( in32_16_a );
+out64_32 = __builtin_lsp_zvunpkhsi         ( in32_16_a );
+out64_32 = __builtin_lsp_zunpkwgsf         ( in32_32_a );
+out32_32 = __builtin_lsp_zvdotphgwasmf     ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphgwasmfr    ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxgwasmf    ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxgwasmfr   ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphgwssmf     ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphgwssmfr    ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphgwasmfaa   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwasmfraa  ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwasmfan   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwasmfran  ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxgwasmfaa  ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxgwasmfraa ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxgwasmfan  ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxgwasmfran ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwssmfaa   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwssmfraa  ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwssmfan   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphgwssmfran  ( in32_32_a, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmf       ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhulgwsmfr      ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllgwsmf       ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllgwsmfr      ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuugwsmf       ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuugwsmfr      ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlgwsmf       ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlgwsmfr      ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhulgwsmfaa     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmfraa    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmfan     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmfran    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmfanp    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulgwsmfranp   ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfaa     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfraa    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfan     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfran    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfanp    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllgwsmfranp   ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfaa     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfraa    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfan     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfran    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfanp    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuugwsmfranp   ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfaa     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfraa    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfan     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfran    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfanp    ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlgwsmfranp   ( in64_32, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheogwsmf        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheogwsmfr       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhegwsmf         ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhegwsmfr        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhogwsmf         ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhogwsmfr        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheogwsmfaa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheogwsmfraa     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheogwsmfan      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheogwsmfran     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhegwsmfaa       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhegwsmfraa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhegwsmfan       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhegwsmfran      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhogwsmfaa       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhogwsmfraa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhogwsmfan       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhogwsmfran      ( in32_32_a, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegui           ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhegsi           ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhegsui          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhegsmf          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmheogui          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmheogsi          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmheogsui         ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmheogsmf         ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhogui           ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhogsi           ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhogsui          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmhogsmf          ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgaui       ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgasi       ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgasui      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgasmf      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphxgaui      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphxgasi      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphxgasui     ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphxgasmf     ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgsui       ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgssi       ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgssui      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zvdotphgssmf      ( in32_16_a, in32_16_b );
+out64_64 = __builtin_lsp_zmheguiaa         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgauiaa     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheguian         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgauian     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsiaa         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasiaa     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsian         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasian     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsuiaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasuiaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsuian        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasuian    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsmfaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasmfaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhegsmfan        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgasmfan    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheoguiaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgauiaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheoguian        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgauian    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsiaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasiaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsian        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasian    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsuiaa       ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasuiaa   ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsuian       ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasuian   ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsmfaa       ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasmfaa   ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmheogsmfan       ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphxgasmfan   ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhoguiaa         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgsuiaa     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhoguian         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgsuian     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsiaa         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssiaa     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsian         ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssian     ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsuiaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssuiaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsuian        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssuian    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsmfaa        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssmfaa    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmhogsmfan        ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zvdotphgssmfan    ( in64_64, in32_16_b, in32_16_c );
+out64_64 = __builtin_lsp_zmwgui            ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zmwgsi            ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zmwgsui           ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zmwguiaa          ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwguian          ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsiaa          ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsian          ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsuiaa         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsuian         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwguiaas         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwguians         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsiaas         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsians         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsuiaas        ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsuians        ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsmf           ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zmwgsmfr          ( in32_32_a, in32_32_b );
+out64_64 = __builtin_lsp_zmwgsmfaa         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsmfraa        ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsmfan         ( in64_64, in32_32_b, in32_32_c );
+out64_64 = __builtin_lsp_zmwgsmfran        ( in64_64, in32_32_b, in32_32_c );
+out64_32 = __builtin_lsp_zvmhulsf          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhulsfr         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllsf          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllsfr         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuusf          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuusfr         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlsf          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlsfr         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhului          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhulsi          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhulsui         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllui          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllsi          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhllsui         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuuui          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuusi          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuusui         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlsui         ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlsi          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhxlui          ( in32_16_a, in32_16_b );
+out64_32 = __builtin_lsp_zvmhuluiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuluiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuluian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuluians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuluianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuluianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuiaa       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuiaas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuian       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuians      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuianp      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsuianps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfraas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfans       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfrans      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfanps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhulsfranps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhlluianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuiaa       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuiaas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuian       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuians      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuianp      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsuianps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfraas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfans       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfrans      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfanps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhllsfranps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuuuianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuiaa       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuiaas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuian       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuians      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuianp      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusuianps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfraas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfans       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfrans      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfanps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhuusfranps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxluianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsiaa        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsiaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsian        ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsians       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsianp       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsianps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuiaa       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuiaas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuian       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuians      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuianp      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsuianps     ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfaas       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfraas      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfans       ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfrans      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfanps      ( in64_32, in32_16_b, in32_16_c );
+out64_32 = __builtin_lsp_zvmhxlsfranps     ( in64_32, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheui            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhesi            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhesui           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheoui           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheosi           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheosui          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhoui            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhosi            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhosui           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhesf            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhesfr           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheosf           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheosfr          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhosf            ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmhosfr           ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zmheuiaa          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheuiaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheuian          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheuians         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesiaa          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesiaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesian          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesians         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesuiaa         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesuiaas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesuian         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesuians        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesfaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesfraas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesfans         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhesfrans        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheouiaa         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheouiaas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheouian         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheouians        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosiaa         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosiaas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosian         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosians        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosuiaa        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosuiaas       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosuian        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosuians       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosfaas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosfraas       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosfans        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmheosfrans       ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhouiaa          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhouiaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhouian          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhouians         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosiaa          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosiaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosian          ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosians         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosuiaa         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosuiaas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosuian         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosuians        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosfaas         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosfraas        ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosfans         ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmhosfrans        ( in32_32_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsih           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsuih          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhuih           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhuihs          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsihs          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsuihs         ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsiaah         ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsuiaah        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhuiaah         ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsianh         ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsuianh        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhuianh         ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhuiaahs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhuianhs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsiaahs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsianhs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsuiaahs       ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsuianhs       ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsfh           ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsfrh          ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zvmhsfaahs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsfraahs       ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsfanhs        ( in32_16_a, in32_16_b, in32_16_c );
+out32_16 = __builtin_lsp_zvmhsfranhs       ( in32_16_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphaui        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphauis       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasi        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasis       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasui       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasuis      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphauiaa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphauiaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphauian      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphauians     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasiaa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasiaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasian      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasians     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasuiaa     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasuiaas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasuian     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasuians    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasfs       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasfrs      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasfs      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasfrs     ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphasfaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasfraas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasfans     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphasfrans    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasfaas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasfraas   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasfans    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasfrans   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxaui       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxauis      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasi       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasis      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasui      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxasuis     ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphxauiaa     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxauiaas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxauian     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxauians    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasiaa     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasiaas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasian     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasians    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasuiaa    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasuiaas   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasuian    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphxasuians   ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphsui        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssi        ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssui       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphsuis       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssis       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssuis      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphsuiaa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphsuian      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssiaa      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssian      ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssuiaa     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssuian     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphsuiaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphsuians     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssiaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssians     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssuiaas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssuians    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssfs       ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssfrs      ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zvdotphssfaas     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssfraas    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssfans     ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zvdotphssfrans    ( in32_32_a, in32_16_b, in32_16_c );
+out32_32 = __builtin_lsp_zmwlsiaa          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsuiaa         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwluiaa          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsian          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsuian         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwluian          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwluis           ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zmwlsis           ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zmwlsuis          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zmwlsiaas         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsians         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsuiaas        ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwlsuians        ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwluiaas         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwluians         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwsf             ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zmwsfr            ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zmwsfaas          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwsfraas         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwsfans          ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zmwsfrans         ( in32_32_a, in32_32_b, in32_32_c );
+out32_32 = __builtin_lsp_zaddwus           ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zsubfwus          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zaddwss           ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zsubfwss          ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zaddheuw          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zsubfheuw         ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zaddhesw          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zsubfhesw         ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zaddhouw          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zsubfhouw         ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zaddhosw          ( in32_16_a, in32_16_b );
+out32_32 = __builtin_lsp_zsubfhosw         ( in32_16_a, in32_16_b );
+out32_16 = __builtin_lsp_zpkswgshfrs       ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zpkswgswfrs       ( in32_32_a, in32_32_b );
+out32_16 = __builtin_lsp_zvselh            ( in32_16_a, in32_16_b, in2_selmode );
+out32_32 = __builtin_lsp_zxtrw             ( in32_32_a, in32_32_b, in2_offset );
+out32_32 = __builtin_lsp_zbrminc           ( in32_32_a, in32_32_b );
+out32_32 = __builtin_lsp_zcircinc          ( in32_32_a, in32_32_b );
+out4_crd = __builtin_lsp_zvcmpgthu         ( in32_16_a, in32_16_b, in3_cmpsel );
+out4_crd = __builtin_lsp_zvcmpgths         ( in32_16_a, in32_16_b, in3_cmpsel );
+out4_crd = __builtin_lsp_zvcmplthu         ( in32_16_a, in32_16_b, in3_cmpsel );
+out4_crd = __builtin_lsp_zvcmplths         ( in32_16_a, in32_16_b, in3_cmpsel );
+out4_crd = __builtin_lsp_zvcmpeqh          ( in32_16_a, in32_16_b, in3_cmpsel );
+out64_64 = __builtin_lsp_zlddx             ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zldd              ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zldwx             ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zldw              ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zldhx             ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zldh              ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwgsfdx          ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwgsfd           ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwwosdx          ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwwosd           ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhsplatwdx      ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhsplatwd       ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhsplatdx       ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhsplatd        ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhgwsfdx        ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhgwsfd         ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhedx           ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhed            ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhosdx          ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhosd           ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhoudx          ( ptr_a, in32_32_b );
+out64_64 = __builtin_lsp_zlwhoud           ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlwhx             ( ptr_a, in32_32_b );
+out32_16 = __builtin_lsp_zlwh              ( ptr_a, in5_uimm );
+out32_32 = __builtin_lsp_zlwwx             ( ptr_a, in32_32_b );
+out32_32 = __builtin_lsp_zlww              ( ptr_a, in5_uimm );
+out32_32 = __builtin_lsp_zlhgwsfx          ( ptr_a, in32_32_b );
+out32_32 = __builtin_lsp_zlhgwsf           ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhsplatx        ( ptr_a, in32_32_b );
+out32_16 = __builtin_lsp_zlhhsplat         ( ptr_a, in5_uimm );
+           __builtin_lsp_zstddx            ( in64_64, ptr_b, in32_32_c );
+           __builtin_lsp_zstdd             ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstdwx            ( in64_64, ptr_b, in32_32_c );
+           __builtin_lsp_zstdw             ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstdhx            ( in64_64, ptr_b, in32_32_c );
+           __builtin_lsp_zstdh             ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhedx          ( in64_64, ptr_b, in32_32_c );
+           __builtin_lsp_zstwhed           ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhodx          ( in64_64, ptr_b, in32_32_c );
+           __builtin_lsp_zstwhod           ( in64_64, ptr_b, in5_uimm );
+out32_16 = __builtin_lsp_zlhhex            ( ptr_a, in32_32_b );
+out32_16 = __builtin_lsp_zlhhe             ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhosx           ( ptr_a, in32_32_b );
+out32_16 = __builtin_lsp_zlhhos            ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhoux           ( ptr_a, in32_32_b );
+out32_16 = __builtin_lsp_zlhhou            ( ptr_a, in5_uimm );
+           __builtin_lsp_zsthex            ( in32_16_a, ptr_b, in32_32_c );
+           __builtin_lsp_zsthe             ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zsthox            ( in32_16_a, ptr_b, in32_32_c );
+           __builtin_lsp_zstho             ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhx            ( in32_16_a, ptr_b, in32_32_c );
+           __builtin_lsp_zstwh             ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zstwwx            ( in32_32_a, ptr_b, in32_32_c );
+           __builtin_lsp_zstww             ( in32_32_a, ptr_b, in5_uimm );
+out64_64 = __builtin_lsp_zlddmx            ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlddu             ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zldwmx            ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zldwu             ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zldhmx            ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zldhu             ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwgsfdmx         ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwgsfdu          ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwwosdmx         ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwwosdu          ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhsplatwdmx     ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhsplatwdu      ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhsplatdmx      ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhsplatdu       ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhgwsfdmx       ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhgwsfdu        ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhedmx          ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhedu           ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhosdmx         ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhosdu          ( ptr_a, in5_uimm );
+out64_64 = __builtin_lsp_zlwhoudmx         ( in32_32_a, ptr_b );
+out64_64 = __builtin_lsp_zlwhoudu          ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlwhmx            ( in32_32_a, ptr_b );
+out32_16 = __builtin_lsp_zlwhu             ( ptr_a, in5_uimm );
+out32_32 = __builtin_lsp_zlwwmx            ( in32_32_a, ptr_b );
+out32_32 = __builtin_lsp_zlwwu             ( ptr_a, in5_uimm );
+out32_32 = __builtin_lsp_zlhgwsfmx         ( in32_32_a, ptr_b );
+out32_32 = __builtin_lsp_zlhgwsfu          ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhsplatmx       ( in32_32_a, ptr_b );
+out32_16 = __builtin_lsp_zlhhsplatu        ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhemx           ( in32_32_a, ptr_b );
+out32_16 = __builtin_lsp_zlhheu            ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhosmx          ( in32_32_a, ptr_b );
+out32_16 = __builtin_lsp_zlhhosu           ( ptr_a, in5_uimm );
+out32_16 = __builtin_lsp_zlhhoumx          ( in32_32_a, ptr_b );
+out32_16 = __builtin_lsp_zlhhouu           ( ptr_a, in5_uimm );
+           __builtin_lsp_zstddmx           ( in64_64, in32_32_b, ptr_c );
+           __builtin_lsp_zstddu            ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstdwmx           ( in64_64, in32_32_b, ptr_c );
+           __builtin_lsp_zstdwu            ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstdhmx           ( in64_64, in32_32_b, ptr_c );
+           __builtin_lsp_zstdhu            ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhedmx         ( in64_64, in32_32_b, ptr_c );
+           __builtin_lsp_zstwhedu          ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhodmx         ( in64_64, in32_32_b, ptr_c );
+           __builtin_lsp_zstwhodu          ( in64_64, ptr_b, in5_uimm );
+           __builtin_lsp_zsthemx           ( in32_16_a, in32_32_b, ptr_c );
+           __builtin_lsp_zstheu            ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zsthomx           ( in32_16_a, in32_32_b, ptr_c );
+           __builtin_lsp_zsthou            ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zstwhmx           ( in32_16_a, in32_32_b, ptr_c );
+           __builtin_lsp_zstwhu            ( in32_16_a, ptr_b, in5_uimm );
+           __builtin_lsp_zstwwmx           ( in32_32_a, in32_32_b, ptr_c );
+           __builtin_lsp_zstwwu            ( in32_32_a, ptr_b, in5_uimm );
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/vle_decorated.c b/gcc/testsuite/gcc.target/powerpc/vle_decorated.c
new file mode 100644
index 0000000..36795b2
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/vle_decorated.c
@@ -0,0 +1,11 @@
+/* { dg-do compile { target { powerpc*-*-eabivle } } } */
+/* { dg-options "-O1 -mcpu=e200z4" } */
+
+unsigned
+access (unsigned int decoration, unsigned int *device)
+{
+  unsigned result;
+  
+  __asm __volatile("lwdx %0,%1,%2" : "=r"(result) : "r"(decoration), "r" (device));
+  return result;
+}
diff --git a/gcc/testsuite/gcc.target/powerpc/vle_decorated_booke.c b/gcc/testsuite/gcc.target/powerpc/vle_decorated_booke.c
new file mode 100644
index 0000000..f71fb7b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/powerpc/vle_decorated_booke.c
@@ -0,0 +1,11 @@
+/* { dg-do compile { target { powerpc*-*-eabivle } } } */
+/* { dg-options "-O1 -mcpu=e200z4 -mno-vle" } */
+
+unsigned
+access (unsigned int decoration, unsigned int *device)
+{
+  unsigned result;
+  
+  __asm __volatile("lwdx %0,%1,%2" : "=r"(result) : "r"(decoration), "r" (device));
+  return result;
+}
diff --git a/gcc/varasm.c b/gcc/varasm.c
index ef75e89..4297479 100644
--- a/gcc/varasm.c
+++ b/gcc/varasm.c
@@ -5959,7 +5959,7 @@ init_varasm_once (void)
 
 #ifdef TEXT_SECTION_ASM_OP
   text_section = get_unnamed_section (SECTION_CODE, output_section_asm_op,
-				      TEXT_SECTION_ASM_OP);
+				      (TARGET_VLE)?(TEXT_SECTION_ASM_OP):(TEXT_SECTION_ASM_OP_BOOKE));
 #endif
 
 #ifdef DATA_SECTION_ASM_OP
diff --git a/libgcc/config.host b/libgcc/config.host
index 7b8ad23..e8b3212 100644
--- a/libgcc/config.host
+++ b/libgcc/config.host
@@ -966,6 +966,13 @@ powerpc-xilinx-eabi*)
 	tmake_file="${tmake_file} rs6000/t-ppccomm rs6000/t-crtstuff t-crtstuff-pic t-fdpbit"
 	extra_parts="$extra_parts crtbegin.o crtend.o crtbeginS.o crtendS.o crtbeginT.o ecrti.o ecrtn.o ncrti.o ncrtn.o"
 	;;
+powerpc-*-eabivle)
+	tmake_file="${tmake_file} rs6000/t-e200 rs6000/t-crtstuff t-crtstuff-pic t-fdpbit"
+	if test x"${ppc_has_spe}" = xyes; then
+		tmake_file="${tmake_file} rs6000/t-spe-fprules"
+	fi
+ 	extra_parts="$extra_parts crtbegin.o crtend.o crtbeginS.o crtendS.o crtbeginT.o ecrti.o ecrtn.o ncrti.o ncrtn.o"
+	;;
 powerpc-*-eabi*)
 	tmake_file="${tmake_file} rs6000/t-ppccomm rs6000/t-savresfgpr rs6000/t-crtstuff t-crtstuff-pic t-fdpbit"
 	extra_parts="$extra_parts crtbegin.o crtend.o crtbeginS.o crtendS.o crtbeginT.o ecrti.o ecrtn.o ncrti.o ncrtn.o"
diff --git a/libgcc/config/rs6000/crtresfpr.S b/libgcc/config/rs6000/crtresfpr.S
index a5e5691..5244448 100644
--- a/libgcc/config/rs6000/crtresfpr.S
+++ b/libgcc/config/rs6000/crtresfpr.S
@@ -31,7 +31,7 @@
 	#include "ppc-asm.h"
 
 /* On PowerPC64 Linux, these functions are provided by the linker.  */
-#ifndef __powerpc64__
+#if !defined(__powerpc64__)  && !defined (__VLE__)
 
 /* Routines for restoring floating point registers, called by the compiler.  */
 /* Called with r11 pointing to the stack header word of the caller of the */
diff --git a/libgcc/config/rs6000/crtresxfpr.S b/libgcc/config/rs6000/crtresxfpr.S
index 3373a53..1f72928 100644
--- a/libgcc/config/rs6000/crtresxfpr.S
+++ b/libgcc/config/rs6000/crtresxfpr.S
@@ -31,7 +31,7 @@
 	#include "ppc-asm.h"
 
 /* On PowerPC64 Linux, these functions are provided by the linker.  */
-#ifndef __powerpc64__
+#if !defined(__powerpc64__)  && !defined (__VLE__)
 
 /* Routines for restoring floating point registers, called by the compiler.  */
 /* Called with r11 pointing to the stack header word of the caller of the */
diff --git a/libgcc/config/rs6000/crtsavfpr.S b/libgcc/config/rs6000/crtsavfpr.S
index b7f9b3c..6f0a220 100644
--- a/libgcc/config/rs6000/crtsavfpr.S
+++ b/libgcc/config/rs6000/crtsavfpr.S
@@ -31,7 +31,7 @@
 	#include "ppc-asm.h"
 
 /* On PowerPC64 Linux, these functions are provided by the linker.  */
-#ifndef __powerpc64__
+#if !defined(__powerpc64__)  && !defined (__VLE__)
 
 /* Routines for saving floating point registers, called by the compiler.  */
 /* Called with r11 pointing to the stack header word of the caller of the */
diff --git a/libgcc/config/rs6000/e200crtres32gpr.S b/libgcc/config/rs6000/e200crtres32gpr.S
new file mode 100644
index 0000000..eedae21
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtres32gpr.S
@@ -0,0 +1,95 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for restoring 32-bit integer registers, called by the compiler.  */
+/* "Bare" versions that simply return to their caller.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_rest32gpr_14)	e_lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15)	e_lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16)	e_lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17)	e_lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18)	e_lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19)	e_lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20)	e_lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21)	e_lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22)	e_lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23)	e_lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24)	e_lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25)	e_lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26)	e_lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27)	e_lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28)	e_lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29)	e_lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30)	e_lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31)	e_lwz 31,-4(11)
+				se_blr
+#else
+HIDDEN_FUNC(_rest32gpr_14)	lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15)	lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16)	lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17)	lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18)	lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19)	lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20)	lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21)	lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22)	lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23)	lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24)	lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25)	lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26)	lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27)	lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28)	lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29)	lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30)	lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31)	lwz 31,-4(11)
+				blr
+#endif
+FUNC_END(_rest32gpr_31)
+FUNC_END(_rest32gpr_30)
+FUNC_END(_rest32gpr_29)
+FUNC_END(_rest32gpr_28)
+FUNC_END(_rest32gpr_27)
+FUNC_END(_rest32gpr_26)
+FUNC_END(_rest32gpr_25)
+FUNC_END(_rest32gpr_24)
+FUNC_END(_rest32gpr_23)
+FUNC_END(_rest32gpr_22)
+FUNC_END(_rest32gpr_21)
+FUNC_END(_rest32gpr_20)
+FUNC_END(_rest32gpr_19)
+FUNC_END(_rest32gpr_18)
+FUNC_END(_rest32gpr_17)
+FUNC_END(_rest32gpr_16)
+FUNC_END(_rest32gpr_15)
+FUNC_END(_rest32gpr_14)
diff --git a/libgcc/config/rs6000/e200crtres64gpr.S b/libgcc/config/rs6000/e200crtres64gpr.S
new file mode 100644
index 0000000..94293ea
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtres64gpr.S
@@ -0,0 +1,81 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ * 
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* Routines for restoring 64-bit integer registers, called by the compiler.  */
+/* "Bare" versions that return to their caller.  */
+
+HIDDEN_FUNC(_rest64gpr_14)	evldd 14,0(11)
+HIDDEN_FUNC(_rest64gpr_15)	evldd 15,8(11)
+HIDDEN_FUNC(_rest64gpr_16)	evldd 16,16(11)
+HIDDEN_FUNC(_rest64gpr_17)	evldd 17,24(11)
+HIDDEN_FUNC(_rest64gpr_18)	evldd 18,32(11)
+HIDDEN_FUNC(_rest64gpr_19)	evldd 19,40(11)
+HIDDEN_FUNC(_rest64gpr_20)	evldd 20,48(11)
+HIDDEN_FUNC(_rest64gpr_21)	evldd 21,56(11)
+HIDDEN_FUNC(_rest64gpr_22)	evldd 22,64(11)
+HIDDEN_FUNC(_rest64gpr_23)	evldd 23,72(11)
+HIDDEN_FUNC(_rest64gpr_24)	evldd 24,80(11)
+HIDDEN_FUNC(_rest64gpr_25)	evldd 25,88(11)
+HIDDEN_FUNC(_rest64gpr_26)	evldd 26,96(11)
+HIDDEN_FUNC(_rest64gpr_27)	evldd 27,104(11)
+HIDDEN_FUNC(_rest64gpr_28)	evldd 28,112(11)
+HIDDEN_FUNC(_rest64gpr_29)	evldd 29,120(11)
+HIDDEN_FUNC(_rest64gpr_30)	evldd 30,128(11)
+HIDDEN_FUNC(_rest64gpr_31)	evldd 31,136(11)
+#ifdef __VLE__
+				se_blr
+#else
+				blr
+#endif
+FUNC_END(_rest64gpr_31)
+FUNC_END(_rest64gpr_30)
+FUNC_END(_rest64gpr_29)
+FUNC_END(_rest64gpr_28)
+FUNC_END(_rest64gpr_27)
+FUNC_END(_rest64gpr_26)
+FUNC_END(_rest64gpr_25)
+FUNC_END(_rest64gpr_24)
+FUNC_END(_rest64gpr_23)
+FUNC_END(_rest64gpr_22)
+FUNC_END(_rest64gpr_21)
+FUNC_END(_rest64gpr_20)
+FUNC_END(_rest64gpr_19)
+FUNC_END(_rest64gpr_18)
+FUNC_END(_rest64gpr_17)
+FUNC_END(_rest64gpr_16)
+FUNC_END(_rest64gpr_15)
+FUNC_END(_rest64gpr_14)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtres64gprctr.S b/libgcc/config/rs6000/e200crtres64gprctr.S
new file mode 100644
index 0000000..c77e90b
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtres64gprctr.S
@@ -0,0 +1,133 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* Routines for restoring 64-bit integer registers where the number of
+   registers to be restored is passed in CTR, called by the compiler.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_rest64gpr_ctr_14)	evldd 14,0(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_15)	evldd 15,8(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_16)	evldd 16,16(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_17)	evldd 17,24(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_18)	evldd 18,32(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_19)	evldd 19,40(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_20)	evldd 20,48(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_21)	evldd 21,56(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_22)	evldd 22,64(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_23)	evldd 23,72(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_24)	evldd 24,80(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_25)	evldd 25,88(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_26)	evldd 26,96(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_27)	evldd 27,104(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_28)	evldd 28,112(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_29)	evldd 29,120(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_30)	evldd 30,128(11)
+				e_bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_31)	evldd 31,136(11)
+_rest64gpr_ctr_done:		se_blr
+#else
+HIDDEN_FUNC(_rest64gpr_ctr_14)	evldd 14,0(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_15)	evldd 15,8(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_16)	evldd 16,16(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_17)	evldd 17,24(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_18)	evldd 18,32(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_19)	evldd 19,40(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_20)	evldd 20,48(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_21)	evldd 21,56(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_22)	evldd 22,64(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_23)	evldd 23,72(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_24)	evldd 24,80(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_25)	evldd 25,88(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_26)	evldd 26,96(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_27)	evldd 27,104(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_28)	evldd 28,112(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_29)	evldd 29,120(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_30)	evldd 30,128(11)
+				bdz _rest64gpr_ctr_done
+HIDDEN_FUNC(_rest64gpr_ctr_31)	evldd 31,136(11)
+_rest64gpr_ctr_done:		blr
+#endif
+FUNC_END(_rest64gpr_ctr_31)
+FUNC_END(_rest64gpr_ctr_30)
+FUNC_END(_rest64gpr_ctr_29)
+FUNC_END(_rest64gpr_ctr_28)
+FUNC_END(_rest64gpr_ctr_27)
+FUNC_END(_rest64gpr_ctr_26)
+FUNC_END(_rest64gpr_ctr_25)
+FUNC_END(_rest64gpr_ctr_24)
+FUNC_END(_rest64gpr_ctr_23)
+FUNC_END(_rest64gpr_ctr_22)
+FUNC_END(_rest64gpr_ctr_21)
+FUNC_END(_rest64gpr_ctr_20)
+FUNC_END(_rest64gpr_ctr_19)
+FUNC_END(_rest64gpr_ctr_18)
+FUNC_END(_rest64gpr_ctr_17)
+FUNC_END(_rest64gpr_ctr_16)
+FUNC_END(_rest64gpr_ctr_15)
+FUNC_END(_rest64gpr_ctr_14)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtresgpr.S b/libgcc/config/rs6000/e200crtresgpr.S
new file mode 100644
index 0000000..c2d6c4c
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtresgpr.S
@@ -0,0 +1,101 @@
+/*
+ * Special support for eabi and SVR4
+ *
+ *   Copyright (C) 1995-2014 Free Software Foundation, Inc.
+ *   Written By Michael Meissner
+ *   64-bit support written by David Edelsohn
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+/* Do any initializations needed for the eabi environment */
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for restoring integer registers, called by the compiler.  */
+/* Called with r11 pointing to the stack header word of the caller of the */
+/* function, just beyond the end of the integer restore area.  */
+
+CFI_STARTPROC
+#ifdef __VLE__
+HIDDEN_FUNC(_restgpr_14)	e_lwz	14,-72(11)	/* restore gp registers */
+HIDDEN_FUNC(_restgpr_15)	e_lwz	15,-68(11)
+HIDDEN_FUNC(_restgpr_16)	e_lwz	16,-64(11)
+HIDDEN_FUNC(_restgpr_17)	e_lwz	17,-60(11)
+HIDDEN_FUNC(_restgpr_18)	e_lwz	18,-56(11)
+HIDDEN_FUNC(_restgpr_19)	e_lwz	19,-52(11)
+HIDDEN_FUNC(_restgpr_20)	e_lwz	20,-48(11)
+HIDDEN_FUNC(_restgpr_21)	e_lwz	21,-44(11)
+HIDDEN_FUNC(_restgpr_22)	e_lwz	22,-40(11)
+HIDDEN_FUNC(_restgpr_23)	e_lwz	23,-36(11)
+HIDDEN_FUNC(_restgpr_24)	e_lwz	24,-32(11)
+HIDDEN_FUNC(_restgpr_25)	e_lwz	25,-28(11)
+HIDDEN_FUNC(_restgpr_26)	e_lwz	26,-24(11)
+HIDDEN_FUNC(_restgpr_27)	e_lwz	27,-20(11)
+HIDDEN_FUNC(_restgpr_28)	e_lwz	28,-16(11)
+HIDDEN_FUNC(_restgpr_29)	e_lwz	29,-12(11)
+HIDDEN_FUNC(_restgpr_30)	e_lwz	30,-8(11)
+HIDDEN_FUNC(_restgpr_31)	e_lwz	31,-4(11)
+			se_blr
+#else
+HIDDEN_FUNC(_restgpr_14)	lwz	14,-72(11)	/* restore gp registers */
+HIDDEN_FUNC(_restgpr_15)	lwz	15,-68(11)
+HIDDEN_FUNC(_restgpr_16)	lwz	16,-64(11)
+HIDDEN_FUNC(_restgpr_17)	lwz	17,-60(11)
+HIDDEN_FUNC(_restgpr_18)	lwz	18,-56(11)
+HIDDEN_FUNC(_restgpr_19)	lwz	19,-52(11)
+HIDDEN_FUNC(_restgpr_20)	lwz	20,-48(11)
+HIDDEN_FUNC(_restgpr_21)	lwz	21,-44(11)
+HIDDEN_FUNC(_restgpr_22)	lwz	22,-40(11)
+HIDDEN_FUNC(_restgpr_23)	lwz	23,-36(11)
+HIDDEN_FUNC(_restgpr_24)	lwz	24,-32(11)
+HIDDEN_FUNC(_restgpr_25)	lwz	25,-28(11)
+HIDDEN_FUNC(_restgpr_26)	lwz	26,-24(11)
+HIDDEN_FUNC(_restgpr_27)	lwz	27,-20(11)
+HIDDEN_FUNC(_restgpr_28)	lwz	28,-16(11)
+HIDDEN_FUNC(_restgpr_29)	lwz	29,-12(11)
+HIDDEN_FUNC(_restgpr_30)	lwz	30,-8(11)
+HIDDEN_FUNC(_restgpr_31)	lwz	31,-4(11)
+			blr
+#endif
+FUNC_END(_restgpr_31)
+FUNC_END(_restgpr_30)
+FUNC_END(_restgpr_29)
+FUNC_END(_restgpr_28)
+FUNC_END(_restgpr_27)
+FUNC_END(_restgpr_26)
+FUNC_END(_restgpr_25)
+FUNC_END(_restgpr_24)
+FUNC_END(_restgpr_23)
+FUNC_END(_restgpr_22)
+FUNC_END(_restgpr_21)
+FUNC_END(_restgpr_20)
+FUNC_END(_restgpr_19)
+FUNC_END(_restgpr_18)
+FUNC_END(_restgpr_17)
+FUNC_END(_restgpr_16)
+FUNC_END(_restgpr_15)
+FUNC_END(_restgpr_14)
+CFI_ENDPROC
diff --git a/libgcc/config/rs6000/e200crtrest32gpr.S b/libgcc/config/rs6000/e200crtrest32gpr.S
new file mode 100644
index 0000000..14ae909
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtrest32gpr.S
@@ -0,0 +1,99 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for restoring 32-bit integer registers, called by the compiler.  */
+/* "Tail" versions that perform a tail call.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_rest32gpr_14_t)	e_lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15_t)	e_lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16_t)	e_lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17_t)	e_lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18_t)	e_lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19_t)	e_lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20_t)	e_lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21_t)	e_lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22_t)	e_lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23_t)	e_lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24_t)	e_lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25_t)	e_lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26_t)	e_lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27_t)	e_lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28_t)	e_lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29_t)	e_lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30_t)	e_lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31_t)	e_lwz 31,-4(11)
+				e_lwz 0,4(11)
+				se_mfar 1,11
+				se_blr
+#else
+HIDDEN_FUNC(_rest32gpr_14_t)	lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15_t)	lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16_t)	lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17_t)	lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18_t)	lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19_t)	lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20_t)	lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21_t)	lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22_t)	lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23_t)	lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24_t)	lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25_t)	lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26_t)	lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27_t)	lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28_t)	lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29_t)	lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30_t)	lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31_t)	lwz 31,-4(11)
+				lwz 0,4(11)
+				mr 1,11
+				blr
+#endif
+FUNC_END(_rest32gpr_31_t)
+FUNC_END(_rest32gpr_30_t)
+FUNC_END(_rest32gpr_29_t)
+FUNC_END(_rest32gpr_28_t)
+FUNC_END(_rest32gpr_27_t)
+FUNC_END(_rest32gpr_26_t)
+FUNC_END(_rest32gpr_25_t)
+FUNC_END(_rest32gpr_24_t)
+FUNC_END(_rest32gpr_23_t)
+FUNC_END(_rest32gpr_22_t)
+FUNC_END(_rest32gpr_21_t)
+FUNC_END(_rest32gpr_20_t)
+FUNC_END(_rest32gpr_19_t)
+FUNC_END(_rest32gpr_18_t)
+FUNC_END(_rest32gpr_17_t)
+FUNC_END(_rest32gpr_16_t)
+FUNC_END(_rest32gpr_15_t)
+FUNC_END(_rest32gpr_14_t)
diff --git a/libgcc/config/rs6000/e200crtrest64gpr.S b/libgcc/config/rs6000/e200crtrest64gpr.S
new file mode 100644
index 0000000..da2e09e
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtrest64gpr.S
@@ -0,0 +1,85 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* "Tail" versions that perform a tail call.  */
+
+HIDDEN_FUNC(_rest64gpr_14_t)	evldd 14,0(11)
+HIDDEN_FUNC(_rest64gpr_15_t)	evldd 15,8(11)
+HIDDEN_FUNC(_rest64gpr_16_t)	evldd 16,16(11)
+HIDDEN_FUNC(_rest64gpr_17_t)	evldd 17,24(11)
+HIDDEN_FUNC(_rest64gpr_18_t)	evldd 18,32(11)
+HIDDEN_FUNC(_rest64gpr_19_t)	evldd 19,40(11)
+HIDDEN_FUNC(_rest64gpr_20_t)	evldd 20,48(11)
+HIDDEN_FUNC(_rest64gpr_21_t)	evldd 21,56(11)
+HIDDEN_FUNC(_rest64gpr_22_t)	evldd 22,64(11)
+HIDDEN_FUNC(_rest64gpr_23_t)	evldd 23,72(11)
+HIDDEN_FUNC(_rest64gpr_24_t)	evldd 24,80(11)
+HIDDEN_FUNC(_rest64gpr_25_t)	evldd 25,88(11)
+HIDDEN_FUNC(_rest64gpr_26_t)	evldd 26,96(11)
+HIDDEN_FUNC(_rest64gpr_27_t)	evldd 27,104(11)
+HIDDEN_FUNC(_rest64gpr_28_t)	evldd 28,112(11)
+HIDDEN_FUNC(_rest64gpr_29_t)	evldd 29,120(11)
+HIDDEN_FUNC(_rest64gpr_30_t)	evldd 30,128(11)
+#ifdef __VLE__
+HIDDEN_FUNC(_rest64gpr_31_t)	e_lwz 0,148(11)
+				evldd 31,136(11)
+				e_addi 1,11,144
+				se_blr
+#else
+HIDDEN_FUNC(_rest64gpr_31_t)	lwz 0,148(11)
+				evldd 31,136(11)
+				addi 1,11,144
+				blr
+#endif
+FUNC_END(_rest64gpr_31_t)
+FUNC_END(_rest64gpr_30_t)
+FUNC_END(_rest64gpr_29_t)
+FUNC_END(_rest64gpr_28_t)
+FUNC_END(_rest64gpr_27_t)
+FUNC_END(_rest64gpr_26_t)
+FUNC_END(_rest64gpr_25_t)
+FUNC_END(_rest64gpr_24_t)
+FUNC_END(_rest64gpr_23_t)
+FUNC_END(_rest64gpr_22_t)
+FUNC_END(_rest64gpr_21_t)
+FUNC_END(_rest64gpr_20_t)
+FUNC_END(_rest64gpr_19_t)
+FUNC_END(_rest64gpr_18_t)
+FUNC_END(_rest64gpr_17_t)
+FUNC_END(_rest64gpr_16_t)
+FUNC_END(_rest64gpr_15_t)
+FUNC_END(_rest64gpr_14_t)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtresx32gpr.S b/libgcc/config/rs6000/e200crtresx32gpr.S
new file mode 100644
index 0000000..d400b55
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtresx32gpr.S
@@ -0,0 +1,100 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for restoring 32-bit integer registers, called by the compiler.  */
+/* "Exit" versions that return to the caller's caller.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_rest32gpr_14_x)	e_lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15_x)	e_lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16_x)	e_lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17_x)	e_lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18_x)	e_lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19_x)	e_lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20_x)	e_lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21_x)	e_lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22_x)	e_lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23_x)	e_lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24_x)	e_lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25_x)	e_lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26_x)	e_lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27_x)	e_lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28_x)	e_lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29_x)	e_lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30_x)	e_lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31_x)	e_lwz 0,4(11)
+				e_lwz 31,-4(11)
+				se_mfar 1,11
+				se_mtlr 0
+				se_blr
+#else
+HIDDEN_FUNC(_rest32gpr_14_x)	lwz 14,-72(11)
+HIDDEN_FUNC(_rest32gpr_15_x)	lwz 15,-68(11)
+HIDDEN_FUNC(_rest32gpr_16_x)	lwz 16,-64(11)
+HIDDEN_FUNC(_rest32gpr_17_x)	lwz 17,-60(11)
+HIDDEN_FUNC(_rest32gpr_18_x)	lwz 18,-56(11)
+HIDDEN_FUNC(_rest32gpr_19_x)	lwz 19,-52(11)
+HIDDEN_FUNC(_rest32gpr_20_x)	lwz 20,-48(11)
+HIDDEN_FUNC(_rest32gpr_21_x)	lwz 21,-44(11)
+HIDDEN_FUNC(_rest32gpr_22_x)	lwz 22,-40(11)
+HIDDEN_FUNC(_rest32gpr_23_x)	lwz 23,-36(11)
+HIDDEN_FUNC(_rest32gpr_24_x)	lwz 24,-32(11)
+HIDDEN_FUNC(_rest32gpr_25_x)	lwz 25,-28(11)
+HIDDEN_FUNC(_rest32gpr_26_x)	lwz 26,-24(11)
+HIDDEN_FUNC(_rest32gpr_27_x)	lwz 27,-20(11)
+HIDDEN_FUNC(_rest32gpr_28_x)	lwz 28,-16(11)
+HIDDEN_FUNC(_rest32gpr_29_x)	lwz 29,-12(11)
+HIDDEN_FUNC(_rest32gpr_30_x)	lwz 30,-8(11)
+HIDDEN_FUNC(_rest32gpr_31_x)	lwz 0,4(11)
+				lwz 31,-4(11)
+				mr 1,11
+				mtlr 0
+				blr
+#endif
+FUNC_END(_rest32gpr_31_x)
+FUNC_END(_rest32gpr_30_x)
+FUNC_END(_rest32gpr_29_x)
+FUNC_END(_rest32gpr_28_x)
+FUNC_END(_rest32gpr_27_x)
+FUNC_END(_rest32gpr_26_x)
+FUNC_END(_rest32gpr_25_x)
+FUNC_END(_rest32gpr_24_x)
+FUNC_END(_rest32gpr_23_x)
+FUNC_END(_rest32gpr_22_x)
+FUNC_END(_rest32gpr_21_x)
+FUNC_END(_rest32gpr_20_x)
+FUNC_END(_rest32gpr_19_x)
+FUNC_END(_rest32gpr_18_x)
+FUNC_END(_rest32gpr_17_x)
+FUNC_END(_rest32gpr_16_x)
+FUNC_END(_rest32gpr_15_x)
+FUNC_END(_rest32gpr_14_x)
diff --git a/libgcc/config/rs6000/e200crtresx64gpr.S b/libgcc/config/rs6000/e200crtresx64gpr.S
new file mode 100644
index 0000000..e6bc807
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtresx64gpr.S
@@ -0,0 +1,87 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* "Exit" versions that return to their caller's caller.  */
+
+HIDDEN_FUNC(_rest64gpr_14_x)	evldd 14,0(11)
+HIDDEN_FUNC(_rest64gpr_15_x)	evldd 15,8(11)
+HIDDEN_FUNC(_rest64gpr_16_x)	evldd 16,16(11)
+HIDDEN_FUNC(_rest64gpr_17_x)	evldd 17,24(11)
+HIDDEN_FUNC(_rest64gpr_18_x)	evldd 18,32(11)
+HIDDEN_FUNC(_rest64gpr_19_x)	evldd 19,40(11)
+HIDDEN_FUNC(_rest64gpr_20_x)	evldd 20,48(11)
+HIDDEN_FUNC(_rest64gpr_21_x)	evldd 21,56(11)
+HIDDEN_FUNC(_rest64gpr_22_x)	evldd 22,64(11)
+HIDDEN_FUNC(_rest64gpr_23_x)	evldd 23,72(11)
+HIDDEN_FUNC(_rest64gpr_24_x)	evldd 24,80(11)
+HIDDEN_FUNC(_rest64gpr_25_x)	evldd 25,88(11)
+HIDDEN_FUNC(_rest64gpr_26_x)	evldd 26,96(11)
+HIDDEN_FUNC(_rest64gpr_27_x)	evldd 27,104(11)
+HIDDEN_FUNC(_rest64gpr_28_x)	evldd 28,112(11)
+HIDDEN_FUNC(_rest64gpr_29_x)	evldd 29,120(11)
+HIDDEN_FUNC(_rest64gpr_30_x)	evldd 30,128(11)
+#ifdef __VLE__
+HIDDEN_FUNC(_rest64gpr_31_x)	e_lwz 0,148(11)
+				evldd 31,136(11)
+				e_addi 1,11,144
+				se_mtlr 0
+				se_blr
+#else
+HIDDEN_FUNC(_rest64gpr_31_x)	lwz 0,148(11)
+				evldd 31,136(11)
+				addi 1,11,144
+				mtlr 0
+				blr
+#endif
+FUNC_END(_rest64gpr_31_x)
+FUNC_END(_rest64gpr_30_x)
+FUNC_END(_rest64gpr_29_x)
+FUNC_END(_rest64gpr_28_x)
+FUNC_END(_rest64gpr_27_x)
+FUNC_END(_rest64gpr_26_x)
+FUNC_END(_rest64gpr_25_x)
+FUNC_END(_rest64gpr_24_x)
+FUNC_END(_rest64gpr_23_x)
+FUNC_END(_rest64gpr_22_x)
+FUNC_END(_rest64gpr_21_x)
+FUNC_END(_rest64gpr_20_x)
+FUNC_END(_rest64gpr_19_x)
+FUNC_END(_rest64gpr_18_x)
+FUNC_END(_rest64gpr_17_x)
+FUNC_END(_rest64gpr_16_x)
+FUNC_END(_rest64gpr_15_x)
+FUNC_END(_rest64gpr_14_x)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtresxgpr.S b/libgcc/config/rs6000/e200crtresxgpr.S
new file mode 100644
index 0000000..945557d
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtresxgpr.S
@@ -0,0 +1,167 @@
+/*
+ * Special support for eabi and SVR4
+ *
+ *   Copyright (C) 1995-2014 Free Software Foundation, Inc.
+ *   Written By Michael Meissner
+ *   64-bit support written by David Edelsohn
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+/* Do any initializations needed for the eabi environment */
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for restoring integer registers, called by the compiler.  */
+/* Called with r11 pointing to the stack header word of the caller of the */
+/* function, just beyond the end of the integer restore area.  */
+
+CFI_STARTPROC
+CFI_DEF_CFA_REGISTER (11)
+CFI_OFFSET (65, 4)
+CFI_OFFSET (14, -72)
+CFI_OFFSET (15, -68)
+CFI_OFFSET (16, -64)
+CFI_OFFSET (17, -60)
+CFI_OFFSET (18, -56)
+CFI_OFFSET (19, -52)
+CFI_OFFSET (20, -48)
+CFI_OFFSET (21, -44)
+CFI_OFFSET (22, -40)
+CFI_OFFSET (23, -36)
+CFI_OFFSET (24, -32)
+CFI_OFFSET (25, -28)
+CFI_OFFSET (26, -24)
+CFI_OFFSET (27, -20)
+CFI_OFFSET (28, -16)
+CFI_OFFSET (29, -12)
+CFI_OFFSET (30, -8)
+CFI_OFFSET (31, -4)
+#ifdef __VLE__
+HIDDEN_FUNC(_restgpr_14_x)	e_lwz	14,-72(11)	/* restore gp registers */
+CFI_RESTORE (14)
+HIDDEN_FUNC(_restgpr_15_x)	e_lwz	15,-68(11)
+CFI_RESTORE (15)
+HIDDEN_FUNC(_restgpr_16_x)	e_lwz	16,-64(11)
+CFI_RESTORE (16)
+HIDDEN_FUNC(_restgpr_17_x)	e_lwz	17,-60(11)
+CFI_RESTORE (17)
+HIDDEN_FUNC(_restgpr_18_x)	e_lwz	18,-56(11)
+CFI_RESTORE (18)
+HIDDEN_FUNC(_restgpr_19_x)	e_lwz	19,-52(11)
+CFI_RESTORE (19)
+HIDDEN_FUNC(_restgpr_20_x)	e_lwz	20,-48(11)
+CFI_RESTORE (20)
+HIDDEN_FUNC(_restgpr_21_x)	e_lwz	21,-44(11)
+CFI_RESTORE (21)
+HIDDEN_FUNC(_restgpr_22_x)	e_lwz	22,-40(11)
+CFI_RESTORE (22)
+HIDDEN_FUNC(_restgpr_23_x)	e_lwz	23,-36(11)
+CFI_RESTORE (23)
+HIDDEN_FUNC(_restgpr_24_x)	e_lwz	24,-32(11)
+CFI_RESTORE (24)
+HIDDEN_FUNC(_restgpr_25_x)	e_lwz	25,-28(11)
+CFI_RESTORE (25)
+HIDDEN_FUNC(_restgpr_26_x)	e_lwz	26,-24(11)
+CFI_RESTORE (26)
+HIDDEN_FUNC(_restgpr_27_x)	e_lwz	27,-20(11)
+CFI_RESTORE (27)
+HIDDEN_FUNC(_restgpr_28_x)	e_lwz	28,-16(11)
+CFI_RESTORE (28)
+HIDDEN_FUNC(_restgpr_29_x)	e_lwz	29,-12(11)
+CFI_RESTORE (29)
+HIDDEN_FUNC(_restgpr_30_x)	e_lwz	30,-8(11)
+CFI_RESTORE (30)
+HIDDEN_FUNC(_restgpr_31_x)	e_lwz	0,4(11)
+				e_lwz	31,-4(11)
+CFI_RESTORE (31)
+				se_mtlr	0
+CFI_RESTORE (65)
+				se_mfar	1,11
+CFI_DEF_CFA_REGISTER (1)
+				se_blr
+#else
+HIDDEN_FUNC(_restgpr_14_x)	lwz	14,-72(11)	/* restore gp registers */
+CFI_RESTORE (14)
+HIDDEN_FUNC(_restgpr_15_x)	lwz	15,-68(11)
+CFI_RESTORE (15)
+HIDDEN_FUNC(_restgpr_16_x)	lwz	16,-64(11)
+CFI_RESTORE (16)
+HIDDEN_FUNC(_restgpr_17_x)	lwz	17,-60(11)
+CFI_RESTORE (17)
+HIDDEN_FUNC(_restgpr_18_x)	lwz	18,-56(11)
+CFI_RESTORE (18)
+HIDDEN_FUNC(_restgpr_19_x)	lwz	19,-52(11)
+CFI_RESTORE (19)
+HIDDEN_FUNC(_restgpr_20_x)	lwz	20,-48(11)
+CFI_RESTORE (20)
+HIDDEN_FUNC(_restgpr_21_x)	lwz	21,-44(11)
+CFI_RESTORE (21)
+HIDDEN_FUNC(_restgpr_22_x)	lwz	22,-40(11)
+CFI_RESTORE (22)
+HIDDEN_FUNC(_restgpr_23_x)	lwz	23,-36(11)
+CFI_RESTORE (23)
+HIDDEN_FUNC(_restgpr_24_x)	lwz	24,-32(11)
+CFI_RESTORE (24)
+HIDDEN_FUNC(_restgpr_25_x)	lwz	25,-28(11)
+CFI_RESTORE (25)
+HIDDEN_FUNC(_restgpr_26_x)	lwz	26,-24(11)
+CFI_RESTORE (26)
+HIDDEN_FUNC(_restgpr_27_x)	lwz	27,-20(11)
+CFI_RESTORE (27)
+HIDDEN_FUNC(_restgpr_28_x)	lwz	28,-16(11)
+CFI_RESTORE (28)
+HIDDEN_FUNC(_restgpr_29_x)	lwz	29,-12(11)
+CFI_RESTORE (29)
+HIDDEN_FUNC(_restgpr_30_x)	lwz	30,-8(11)
+CFI_RESTORE (30)
+HIDDEN_FUNC(_restgpr_31_x)	lwz	0,4(11)
+				lwz	31,-4(11)
+CFI_RESTORE (31)
+				mtlr	0
+CFI_RESTORE (65)
+				mr	1,11
+CFI_DEF_CFA_REGISTER (1)
+				blr
+#endif
+FUNC_END(_restgpr_31_x)
+FUNC_END(_restgpr_30_x)
+FUNC_END(_restgpr_29_x)
+FUNC_END(_restgpr_28_x)
+FUNC_END(_restgpr_27_x)
+FUNC_END(_restgpr_26_x)
+FUNC_END(_restgpr_25_x)
+FUNC_END(_restgpr_24_x)
+FUNC_END(_restgpr_23_x)
+FUNC_END(_restgpr_22_x)
+FUNC_END(_restgpr_21_x)
+FUNC_END(_restgpr_20_x)
+FUNC_END(_restgpr_19_x)
+FUNC_END(_restgpr_18_x)
+FUNC_END(_restgpr_17_x)
+FUNC_END(_restgpr_16_x)
+FUNC_END(_restgpr_15_x)
+FUNC_END(_restgpr_14_x)
+CFI_ENDPROC
diff --git a/libgcc/config/rs6000/e200crtsav32gpr.S b/libgcc/config/rs6000/e200crtsav32gpr.S
new file mode 100644
index 0000000..5635fef
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtsav32gpr.S
@@ -0,0 +1,95 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for saving 32-bit integer registers, called by the compiler.  */
+/* "Bare" versions that simply return to their caller.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_save32gpr_14)	e_stw 14,-72(11)
+HIDDEN_FUNC(_save32gpr_15)	e_stw 15,-68(11)
+HIDDEN_FUNC(_save32gpr_16)	e_stw 16,-64(11)
+HIDDEN_FUNC(_save32gpr_17)	e_stw 17,-60(11)
+HIDDEN_FUNC(_save32gpr_18)	e_stw 18,-56(11)
+HIDDEN_FUNC(_save32gpr_19)	e_stw 19,-52(11)
+HIDDEN_FUNC(_save32gpr_20)	e_stw 20,-48(11)
+HIDDEN_FUNC(_save32gpr_21)	e_stw 21,-44(11)
+HIDDEN_FUNC(_save32gpr_22)	e_stw 22,-40(11)
+HIDDEN_FUNC(_save32gpr_23)	e_stw 23,-36(11)
+HIDDEN_FUNC(_save32gpr_24)	e_stw 24,-32(11)
+HIDDEN_FUNC(_save32gpr_25)	e_stw 25,-28(11)
+HIDDEN_FUNC(_save32gpr_26)	e_stw 26,-24(11)
+HIDDEN_FUNC(_save32gpr_27)	e_stw 27,-20(11)
+HIDDEN_FUNC(_save32gpr_28)	e_stw 28,-16(11)
+HIDDEN_FUNC(_save32gpr_29)	e_stw 29,-12(11)
+HIDDEN_FUNC(_save32gpr_30)	e_stw 30,-8(11)
+HIDDEN_FUNC(_save32gpr_31)	e_stw 31,-4(11)
+				se_blr
+#else
+HIDDEN_FUNC(_save32gpr_14)	stw 14,-72(11)
+HIDDEN_FUNC(_save32gpr_15)	stw 15,-68(11)
+HIDDEN_FUNC(_save32gpr_16)	stw 16,-64(11)
+HIDDEN_FUNC(_save32gpr_17)	stw 17,-60(11)
+HIDDEN_FUNC(_save32gpr_18)	stw 18,-56(11)
+HIDDEN_FUNC(_save32gpr_19)	stw 19,-52(11)
+HIDDEN_FUNC(_save32gpr_20)	stw 20,-48(11)
+HIDDEN_FUNC(_save32gpr_21)	stw 21,-44(11)
+HIDDEN_FUNC(_save32gpr_22)	stw 22,-40(11)
+HIDDEN_FUNC(_save32gpr_23)	stw 23,-36(11)
+HIDDEN_FUNC(_save32gpr_24)	stw 24,-32(11)
+HIDDEN_FUNC(_save32gpr_25)	stw 25,-28(11)
+HIDDEN_FUNC(_save32gpr_26)	stw 26,-24(11)
+HIDDEN_FUNC(_save32gpr_27)	stw 27,-20(11)
+HIDDEN_FUNC(_save32gpr_28)	stw 28,-16(11)
+HIDDEN_FUNC(_save32gpr_29)	stw 29,-12(11)
+HIDDEN_FUNC(_save32gpr_30)	stw 30,-8(11)
+HIDDEN_FUNC(_save32gpr_31)	stw 31,-4(11)
+				blr
+#endif
+FUNC_END(_save32gpr_31)
+FUNC_END(_save32gpr_30)
+FUNC_END(_save32gpr_29)
+FUNC_END(_save32gpr_28)
+FUNC_END(_save32gpr_27)
+FUNC_END(_save32gpr_26)
+FUNC_END(_save32gpr_25)
+FUNC_END(_save32gpr_24)
+FUNC_END(_save32gpr_23)
+FUNC_END(_save32gpr_22)
+FUNC_END(_save32gpr_21)
+FUNC_END(_save32gpr_20)
+FUNC_END(_save32gpr_19)
+FUNC_END(_save32gpr_18)
+FUNC_END(_save32gpr_17)
+FUNC_END(_save32gpr_16)
+FUNC_END(_save32gpr_15)
+FUNC_END(_save32gpr_14)
diff --git a/libgcc/config/rs6000/e200crtsav64gpr.S b/libgcc/config/rs6000/e200crtsav64gpr.S
new file mode 100644
index 0000000..aabe910
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtsav64gpr.S
@@ -0,0 +1,80 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* Routines for saving 64-bit integer registers, called by the compiler.  */
+
+HIDDEN_FUNC(_save64gpr_14)	evstdd 14,0(11)
+HIDDEN_FUNC(_save64gpr_15)	evstdd 15,8(11)
+HIDDEN_FUNC(_save64gpr_16)	evstdd 16,16(11)
+HIDDEN_FUNC(_save64gpr_17)	evstdd 17,24(11)
+HIDDEN_FUNC(_save64gpr_18)	evstdd 18,32(11)
+HIDDEN_FUNC(_save64gpr_19)	evstdd 19,40(11)
+HIDDEN_FUNC(_save64gpr_20)	evstdd 20,48(11)
+HIDDEN_FUNC(_save64gpr_21)	evstdd 21,56(11)
+HIDDEN_FUNC(_save64gpr_22)	evstdd 22,64(11)
+HIDDEN_FUNC(_save64gpr_23)	evstdd 23,72(11)
+HIDDEN_FUNC(_save64gpr_24)	evstdd 24,80(11)
+HIDDEN_FUNC(_save64gpr_25)	evstdd 25,88(11)
+HIDDEN_FUNC(_save64gpr_26)	evstdd 26,96(11)
+HIDDEN_FUNC(_save64gpr_27)	evstdd 27,104(11)
+HIDDEN_FUNC(_save64gpr_28)	evstdd 28,112(11)
+HIDDEN_FUNC(_save64gpr_29)	evstdd 29,120(11)
+HIDDEN_FUNC(_save64gpr_30)	evstdd 30,128(11)
+HIDDEN_FUNC(_save64gpr_31)	evstdd 31,136(11)
+#ifdef __VLE__
+				se_blr
+#else
+				blr
+#endif
+FUNC_END(_save64gpr_31)
+FUNC_END(_save64gpr_30)
+FUNC_END(_save64gpr_29)
+FUNC_END(_save64gpr_28)
+FUNC_END(_save64gpr_27)
+FUNC_END(_save64gpr_26)
+FUNC_END(_save64gpr_25)
+FUNC_END(_save64gpr_24)
+FUNC_END(_save64gpr_23)
+FUNC_END(_save64gpr_22)
+FUNC_END(_save64gpr_21)
+FUNC_END(_save64gpr_20)
+FUNC_END(_save64gpr_19)
+FUNC_END(_save64gpr_18)
+FUNC_END(_save64gpr_17)
+FUNC_END(_save64gpr_16)
+FUNC_END(_save64gpr_15)
+FUNC_END(_save64gpr_14)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtsav64gprctr.S b/libgcc/config/rs6000/e200crtsav64gprctr.S
new file mode 100644
index 0000000..77033df
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtsav64gprctr.S
@@ -0,0 +1,134 @@
+/*
+ * Special support for e500 eabi and SVR4
+ *
+ *   Copyright (C) 2008-2014 Free Software Foundation, Inc.
+ *   Written by Nathan Froyd
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifdef __SPE__
+
+/* Routines for saving 64-bit integer registers where the number of
+   registers to be saved is passed in CTR, called by the compiler.  */
+/* "Bare" versions that return to their caller.  */
+
+#ifdef __VLE__
+HIDDEN_FUNC(_save64gpr_ctr_14)	evstdd 14,0(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_15)	evstdd 15,8(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_16)	evstdd 16,16(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_17)	evstdd 17,24(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_18)	evstdd 18,32(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_19)	evstdd 19,40(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_20)	evstdd 20,48(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_21)	evstdd 21,56(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_22)	evstdd 22,64(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_23)	evstdd 23,72(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_24)	evstdd 24,80(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_25)	evstdd 25,88(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_26)	evstdd 26,96(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_27)	evstdd 27,104(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_28)	evstdd 28,112(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_29)	evstdd 29,120(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_30)	evstdd 30,128(11)
+				e_bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_31)	evstdd 31,136(11)
+_save64gpr_ctr_done:		se_blr
+#else
+HIDDEN_FUNC(_save64gpr_ctr_14)	evstdd 14,0(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_15)	evstdd 15,8(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_16)	evstdd 16,16(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_17)	evstdd 17,24(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_18)	evstdd 18,32(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_19)	evstdd 19,40(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_20)	evstdd 20,48(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_21)	evstdd 21,56(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_22)	evstdd 22,64(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_23)	evstdd 23,72(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_24)	evstdd 24,80(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_25)	evstdd 25,88(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_26)	evstdd 26,96(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_27)	evstdd 27,104(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_28)	evstdd 28,112(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_29)	evstdd 29,120(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_30)	evstdd 30,128(11)
+				bdz _save64gpr_ctr_done
+HIDDEN_FUNC(_save64gpr_ctr_31)	evstdd 31,136(11)
+_save64gpr_ctr_done:		blr
+#endif
+FUNC_END(_save64gpr_ctr_31)
+FUNC_END(_save64gpr_ctr_30)
+FUNC_END(_save64gpr_ctr_29)
+FUNC_END(_save64gpr_ctr_28)
+FUNC_END(_save64gpr_ctr_27)
+FUNC_END(_save64gpr_ctr_26)
+FUNC_END(_save64gpr_ctr_25)
+FUNC_END(_save64gpr_ctr_24)
+FUNC_END(_save64gpr_ctr_23)
+FUNC_END(_save64gpr_ctr_22)
+FUNC_END(_save64gpr_ctr_21)
+FUNC_END(_save64gpr_ctr_20)
+FUNC_END(_save64gpr_ctr_19)
+FUNC_END(_save64gpr_ctr_18)
+FUNC_END(_save64gpr_ctr_17)
+FUNC_END(_save64gpr_ctr_16)
+FUNC_END(_save64gpr_ctr_15)
+FUNC_END(_save64gpr_ctr_14)
+
+#endif
diff --git a/libgcc/config/rs6000/e200crtsavgpr.S b/libgcc/config/rs6000/e200crtsavgpr.S
new file mode 100644
index 0000000..1a8de07
--- /dev/null
+++ b/libgcc/config/rs6000/e200crtsavgpr.S
@@ -0,0 +1,101 @@
+/*
+ * Special support for eabi and SVR4
+ *
+ *   Copyright (C) 1995-2014 Free Software Foundation, Inc.
+ *   Written By Michael Meissner
+ *   64-bit support written by David Edelsohn
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+/* Do any initializations needed for the eabi environment */
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+/* Routines for saving integer registers, called by the compiler.  */
+/* Called with r11 pointing to the stack header word of the caller of the */
+/* function, just beyond the end of the integer save area.  */
+
+CFI_STARTPROC
+#ifdef __VLE__
+HIDDEN_FUNC(_savegpr_14)	e_stw	14,-72(11)	/* save gp registers */
+HIDDEN_FUNC(_savegpr_15)	e_stw	15,-68(11)
+HIDDEN_FUNC(_savegpr_16)	e_stw	16,-64(11)
+HIDDEN_FUNC(_savegpr_17)	e_stw	17,-60(11)
+HIDDEN_FUNC(_savegpr_18)	e_stw	18,-56(11)
+HIDDEN_FUNC(_savegpr_19)	e_stw	19,-52(11)
+HIDDEN_FUNC(_savegpr_20)	e_stw	20,-48(11)
+HIDDEN_FUNC(_savegpr_21)	e_stw	21,-44(11)
+HIDDEN_FUNC(_savegpr_22)	e_stw	22,-40(11)
+HIDDEN_FUNC(_savegpr_23)	e_stw	23,-36(11)
+HIDDEN_FUNC(_savegpr_24)	e_stw	24,-32(11)
+HIDDEN_FUNC(_savegpr_25)	e_stw	25,-28(11)
+HIDDEN_FUNC(_savegpr_26)	e_stw	26,-24(11)
+HIDDEN_FUNC(_savegpr_27)	e_stw	27,-20(11)
+HIDDEN_FUNC(_savegpr_28)	e_stw	28,-16(11)
+HIDDEN_FUNC(_savegpr_29)	e_stw	29,-12(11)
+HIDDEN_FUNC(_savegpr_30)	e_stw	30,-8(11)
+HIDDEN_FUNC(_savegpr_31)	e_stw	31,-4(11)
+			se_blr
+#else
+HIDDEN_FUNC(_savegpr_14)	stw	14,-72(11)	/* save gp registers */
+HIDDEN_FUNC(_savegpr_15)	stw	15,-68(11)
+HIDDEN_FUNC(_savegpr_16)	stw	16,-64(11)
+HIDDEN_FUNC(_savegpr_17)	stw	17,-60(11)
+HIDDEN_FUNC(_savegpr_18)	stw	18,-56(11)
+HIDDEN_FUNC(_savegpr_19)	stw	19,-52(11)
+HIDDEN_FUNC(_savegpr_20)	stw	20,-48(11)
+HIDDEN_FUNC(_savegpr_21)	stw	21,-44(11)
+HIDDEN_FUNC(_savegpr_22)	stw	22,-40(11)
+HIDDEN_FUNC(_savegpr_23)	stw	23,-36(11)
+HIDDEN_FUNC(_savegpr_24)	stw	24,-32(11)
+HIDDEN_FUNC(_savegpr_25)	stw	25,-28(11)
+HIDDEN_FUNC(_savegpr_26)	stw	26,-24(11)
+HIDDEN_FUNC(_savegpr_27)	stw	27,-20(11)
+HIDDEN_FUNC(_savegpr_28)	stw	28,-16(11)
+HIDDEN_FUNC(_savegpr_29)	stw	29,-12(11)
+HIDDEN_FUNC(_savegpr_30)	stw	30,-8(11)
+HIDDEN_FUNC(_savegpr_31)	stw	31,-4(11)
+			blr
+#endif
+FUNC_END(_savegpr_31)
+FUNC_END(_savegpr_30)
+FUNC_END(_savegpr_29)
+FUNC_END(_savegpr_28)
+FUNC_END(_savegpr_27)
+FUNC_END(_savegpr_26)
+FUNC_END(_savegpr_25)
+FUNC_END(_savegpr_24)
+FUNC_END(_savegpr_23)
+FUNC_END(_savegpr_22)
+FUNC_END(_savegpr_21)
+FUNC_END(_savegpr_20)
+FUNC_END(_savegpr_19)
+FUNC_END(_savegpr_18)
+FUNC_END(_savegpr_17)
+FUNC_END(_savegpr_16)
+FUNC_END(_savegpr_15)
+FUNC_END(_savegpr_14)
+CFI_ENDPROC
diff --git a/libgcc/config/rs6000/eabivle-ci.S b/libgcc/config/rs6000/eabivle-ci.S
new file mode 100644
index 0000000..78c0057
--- /dev/null
+++ b/libgcc/config/rs6000/eabivle-ci.S
@@ -0,0 +1,118 @@
+/* crti.s for eabi
+   Copyright (C) 1996-2014 Free Software Foundation, Inc.
+   Written By Michael Meissner
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 3, or (at your option) any
+later version.
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+/* This file just supplies labeled starting points for the .got* and other
+   special sections.  It is linked in first before other modules.  */
+ 
+	.ident	"GNU C crti.s"
+
+#include <ppc-asm.h>
+
+	.section ".fixup","aw"
+	.globl	__FIXUP_START__
+	.type	__FIXUP_START__,@object
+__FIXUP_START__:
+
+	.section ".ctors","aw"
+	.globl	__CTOR_LIST__
+	.type	__CTOR_LIST__,@object
+__CTOR_LIST__:
+
+	.section ".dtors","aw"
+	.globl	__DTOR_LIST__
+	.type	__DTOR_LIST__,@object
+__DTOR_LIST__:
+
+	.section ".sdata","aw"
+	.globl	__SDATA_START__
+	.type	__SDATA_START__,@object
+	.weak	_SDA_BASE_
+	.type	_SDA_BASE_,@object
+__SDATA_START__:
+_SDA_BASE_:
+
+	.section ".sbss","aw",@nobits
+	.globl	__SBSS_START__
+	.type	__SBSS_START__,@object
+__SBSS_START__:
+
+	.section ".sdata2","a"
+	.weak	_SDA2_BASE_
+	.type	_SDA2_BASE_,@object
+	.globl	__SDATA2_START__
+	.type	__SDATA2_START__,@object
+__SDATA2_START__:
+_SDA2_BASE_:
+
+	.section ".sbss2","a"
+	.globl	__SBSS2_START__
+	.type	__SBSS2_START__,@object
+__SBSS2_START__:
+
+	.section ".gcc_except_table","aw"
+	.globl	__EXCEPT_START__
+	.type	__EXCEPT_START__,@object
+__EXCEPT_START__:
+
+	.section ".eh_frame","aw"
+	.globl	__EH_FRAME_BEGIN__
+	.type	__EH_FRAME_BEGIN__,@object
+__EH_FRAME_BEGIN__:
+
+/* Head of __init function used for static constructors.  */
+#ifdef __VLE__
+	.section ".init","axv"
+#else
+	.section ".init","ax"
+#endif
+	.align 2
+FUNC_START(__init)
+#ifdef __VLE__
+	e_stwu 1,-16(1)
+	se_mflr 0
+	se_nop
+	e_stw 0,20(1)
+#else
+	stwu 1,-16(1)
+	mflr 0
+	stw 0,20(1)
+#endif
+
+/* Head of __fini function used for static destructors.  */
+#ifdef __VLE__
+	.section ".fini","axv"
+#else
+	.section ".fini","ax"
+#endif
+	.align 2
+FUNC_START(__fini)
+#ifdef __VLE__
+	e_stwu 1,-16(1)
+	se_mflr 0
+	se_nop
+	e_stw 0,20(1)
+#else
+	stwu 1,-16(1)
+	mflr 0
+	stw 0,20(1)
+#endif
diff --git a/libgcc/config/rs6000/eabivle-cn.S b/libgcc/config/rs6000/eabivle-cn.S
new file mode 100644
index 0000000..2dcc34d
--- /dev/null
+++ b/libgcc/config/rs6000/eabivle-cn.S
@@ -0,0 +1,109 @@
+/* crtn.s for eabi
+   Copyright (C) 1996-2014 Free Software Foundation, Inc.
+   Written By Michael Meissner
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 3, or (at your option) any
+later version.
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+/* This file just supplies labeled ending points for the .got* and other
+   special sections.  It is linked in last after other modules.  */
+ 
+	.ident	"GNU C crtn.s"
+
+	.section ".fixup","aw"
+	.globl	__FIXUP_END__
+	.type	__FIXUP_END__,@object
+__FIXUP_END__:
+
+	.section ".ctors","aw"
+	.globl	__CTOR_END__
+	.type	__CTOR_END__,@object
+__CTOR_END__:
+
+	.section ".dtors","aw"
+	.weak	__DTOR_END__
+	.type	__DTOR_END__,@object
+__DTOR_END__:
+
+	.section ".sdata","aw"
+	.globl	__SDATA_END__
+	.type	__SDATA_END__,@object
+__SDATA_END__:
+
+	.section ".sbss","aw",@nobits
+	.globl	__SBSS_END__
+	.type	__SBSS_END__,@object
+__SBSS_END__:
+
+	.section ".sdata2","a"
+	.globl	__SDATA2_END__
+	.type	__SDATA2_END__,@object
+__SDATA2_END__:
+
+	.section ".sbss2","a"
+	.globl	__SBSS2_END__
+	.type	__SBSS2_END__,@object
+__SBSS2_END__:
+
+	.section ".gcc_except_table","aw"
+	.globl	__EXCEPT_END__
+	.type	__EXCEPT_END__,@object
+__EXCEPT_END__:
+
+	.section ".eh_frame","aw"
+	.globl	__EH_FRAME_END__
+	.type	__EH_FRAME_END__,@object
+__EH_FRAME_END__:
+        .long   0
+
+/* Tail of __init function used for static constructors.  */
+#ifdef __VLE__
+	.section ".init","axv"
+#else
+	.section ".init","ax"
+#endif
+#ifdef __VLE__
+	e_lwz 0,20(1)
+	se_mtlr 0
+	se_addi 1,16
+	se_blr
+#else
+	lwz 0,20(1)
+	mtlr 0
+	addi 1,1,16
+	blr
+#endif
+
+/* Tail of __fini function used for static destructors.  */
+#ifdef __VLE__
+	.section ".fini","axv"
+#else
+	.section ".fini","ax"
+#endif
+#ifdef __VLE__
+	e_lwz 0,20(1)
+	se_mtlr 0
+	se_addi 1,16
+	se_blr
+#else
+	lwz 0,20(1)
+	mtlr 0
+	addi 1,1,16
+	blr
+#endif
diff --git a/libgcc/config/rs6000/eabivle.S b/libgcc/config/rs6000/eabivle.S
new file mode 100644
index 0000000..82f0960
--- /dev/null
+++ b/libgcc/config/rs6000/eabivle.S
@@ -0,0 +1,443 @@
+/*
+ * Special support for eabi and SVR4
+ *
+ *   Copyright (C) 1995-2014 Free Software Foundation, Inc.
+ *   Written By Michael Meissner
+ * 
+ * This file is free software; you can redistribute it and/or modify it
+ * under the terms of the GNU General Public License as published by the
+ * Free Software Foundation; either version 3, or (at your option) any
+ * later version.
+ * 
+ * This file is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ * 
+ * Under Section 7 of GPL version 3, you are granted additional
+ * permissions described in the GCC Runtime Library Exception, version
+ * 3.1, as published by the Free Software Foundation.
+ *
+ * You should have received a copy of the GNU General Public License and
+ * a copy of the GCC Runtime Library Exception along with this program;
+ * see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+ * <http://www.gnu.org/licenses/>.
+ */ 
+
+/* Do any initializations needed for the eabi environment */
+
+#ifdef __VLE__
+	.section ".text","axv"
+#else
+	.section ".text","ax"
+#endif
+	#include "ppc-asm.h"
+
+#ifndef __powerpc64__
+
+	 .section ".got2","aw"
+	.align	2
+.LCTOC1 = . /* +32768 */
+
+/* Table of addresses */
+.Ltable = .-.LCTOC1
+	.long	.LCTOC1				/* address we are really at */
+
+.Lsda = .-.LCTOC1
+	.long	_SDA_BASE_			/* address of the first small data area */
+
+.Lsdas = .-.LCTOC1
+	.long	__SDATA_START__			/* start of .sdata/.sbss section */
+
+.Lsdae = .-.LCTOC1
+	.long	__SBSS_END__			/* end of .sdata/.sbss section */
+
+.Lsda2 = .-.LCTOC1
+	.long	_SDA2_BASE_			/* address of the second small data area */
+
+.Lsda2s = .-.LCTOC1
+	.long	__SDATA2_START__		/* start of .sdata2/.sbss2 section */
+
+.Lsda2e = .-.LCTOC1
+	.long	__SBSS2_END__			/* end of .sdata2/.sbss2 section */
+
+#ifdef _RELOCATABLE
+.Lgots = .-.LCTOC1
+	.long	__GOT_START__			/* Global offset table start */
+
+.Lgotm1 = .-.LCTOC1
+	.long	_GLOBAL_OFFSET_TABLE_-4		/* end of GOT ptrs before BLCL + 3 reserved words */
+
+.Lgotm2 = .-.LCTOC1
+	.long	_GLOBAL_OFFSET_TABLE_+12	/* start of GOT ptrs after BLCL + 3 reserved words */
+
+.Lgote = .-.LCTOC1
+	.long	__GOT_END__			/* Global offset table end */
+
+.Lgot2s = .-.LCTOC1
+	.long	__GOT2_START__			/* -mrelocatable GOT pointers start */
+
+.Lgot2e = .-.LCTOC1
+	.long	__GOT2_END__			/* -mrelocatable GOT pointers end */
+
+.Lfixups = .-.LCTOC1
+	.long	__FIXUP_START__			/* start of .fixup section */
+
+.Lfixupe = .-.LCTOC1
+	.long	__FIXUP_END__			/* end of .fixup section */
+
+.Lctors = .-.LCTOC1
+	.long	__CTOR_LIST__			/* start of .ctor section */
+
+.Lctore = .-.LCTOC1
+	.long	__CTOR_END__			/* end of .ctor section */
+
+.Ldtors = .-.LCTOC1
+	.long	__DTOR_LIST__			/* start of .dtor section */
+
+.Ldtore = .-.LCTOC1
+	.long	__DTOR_END__			/* end of .dtor section */
+
+.Lexcepts = .-.LCTOC1
+	.long	__EXCEPT_START__		/* start of .gcc_except_table section */
+
+.Lexcepte = .-.LCTOC1
+	.long	__EXCEPT_END__			/* end of .gcc_except_table section */
+
+.Linit = .-.LCTOC1
+	.long	.Linit_p			/* address of variable to say we've been called */
+
+	.text
+	.align	2
+.Lptr:
+	.long	.LCTOC1-.Laddr			/* PC relative pointer to .got2 */
+#endif
+
+	.data
+	.align	2
+.Linit_p:
+	.long	0
+
+	.text
+
+FUNC_START(__eabi)
+
+/* Eliminate -mrelocatable code if not -mrelocatable, so that this file can
+   be assembled with other assemblers than GAS.  */
+#ifdef __VLE__
+#ifndef _RELOCATABLE
+	e_lis	10,.Linit_p@ha			/* init flag */
+	e_lis	11,.LCTOC1@ha			/* load address of .LCTOC1 */
+	e_lwz	9,.Linit_p@l(10)		/* init flag */
+	e_add16i	11,11,.LCTOC1@l
+	e_cmpi	2,9,0				/* init flag != 0? */
+	e_beq	2,.Lbnelr_1
+	se_blr					/* return now, if we've been called already */
+.Lbnelr_1:
+	e_stw	1,.Linit_p@l(10)		/* store a nonzero value in the done flag */
+
+#else /* -mrelocatable */
+	se_mflr	0
+	e_bl	.Laddr				/* get current address */
+.Laddr:
+	mflr	12				/* real address of .Laddr */
+	e_lwz	11,(.Lptr-.Laddr)(12)		/* linker generated address of .LCTOC1 */
+	add	11,11,12			/* correct to real pointer */
+	e_lwz	12,.Ltable(11)			/* get linker's idea of where .Laddr is */
+	e_lwz	10,.Linit(11)			/* address of init flag */
+	subf.	12,12,11			/* calculate difference */
+	lwzx	9,10,12				/* done flag */
+	e_cmpi	2,9,0				/* init flag != 0? */
+	mtlr	0				/* restore in case branch was taken */
+	e_beq	2,.Lbnelr_2
+	se_blr					/* return now, if we've been called already */
+.Lbnelr_2:
+	stwx	1,10,12				/* store a nonzero value in the done flag */
+	e_beq	0,.Lsdata			/* skip if we don't need to relocate */
+
+/* We need to relocate the .got2 pointers.  */
+
+	e_lwz	3,.Lgot2s(11)			/* GOT2 pointers start */
+	e_lwz	4,.Lgot2e(11)			/* GOT2 pointers end */
+	add	3,12,3				/* adjust pointers */
+	add	4,12,4
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert pointers in .got2 section */
+
+/* Fixup the .ctor section for static constructors */
+
+	e_lwz	3,.Lctors(11)			/* constructors pointers start */
+	e_lwz	4,.Lctore(11)			/* constructors pointers end */
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert constructors */
+
+/* Fixup the .dtor section for static destructors */
+
+	e_lwz	3,.Ldtors(11)			/* destructors pointers start */
+	e_lwz	4,.Ldtore(11)			/* destructors pointers end */
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert destructors */
+
+/* Fixup the .gcc_except_table section for G++ exceptions */
+
+	e_lwz	3,.Lexcepts(11)			/* exception table pointers start */
+	e_lwz	4,.Lexcepte(11)			/* exception table pointers end */
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert exceptions */
+
+/* Fixup the addresses in the GOT below _GLOBAL_OFFSET_TABLE_-4 */
+
+	e_lwz	3,.Lgots(11)			/* GOT table pointers start */
+	e_lwz	4,.Lgotm1(11)			/* GOT table pointers below _GLOBAL_OFFSET_TABLE-4 */
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert lower GOT */
+
+/* Fixup the addresses in the GOT above _GLOBAL_OFFSET_TABLE_+12 */
+
+	e_lwz	3,.Lgotm2(11)			/* GOT table pointers above _GLOBAL_OFFSET_TABLE+12 */
+	e_lwz	4,.Lgote(11)			/* GOT table pointers end */
+	e_bl	FUNC_NAME(__eabi_convert)	/* convert lower GOT */
+
+/* Fixup any user initialized pointers now (the compiler drops pointers to */
+/* each of the relocs that it does in the .fixup section).  */
+
+.Lfix:
+	e_lwz	3,.Lfixups(11)			/* fixup pointers start */
+	e_lwz	4,.Lfixupe(11)			/* fixup pointers end */
+	e_bl	FUNC_NAME(__eabi_uconvert)	/* convert user initialized pointers */
+
+.Lsdata:
+	mtlr	0				/* restore link register */
+#endif /* _RELOCATABLE */
+
+/* Only load up register 13 if there is a .sdata and/or .sbss section */
+	e_lwz	3,.Lsdas(11)			/* start of .sdata/.sbss section */
+	e_lwz	4,.Lsdae(11)			/* end of .sdata/.sbss section */
+	cmpw	1,3,4				/* .sdata/.sbss section non-empty? */
+	e_beq	1,.Lsda2l			/* skip loading r13 */
+
+	e_lwz	13,.Lsda(11)			/* load r13 with _SDA_BASE_ address */
+
+/* Only load up register 2 if there is a .sdata2 and/or .sbss2 section */
+
+.Lsda2l:	
+	e_lwz	3,.Lsda2s(11)			/* start of .sdata/.sbss section */
+	e_lwz	4,.Lsda2e(11)			/* end of .sdata/.sbss section */
+	cmpw	1,3,4				/* .sdata/.sbss section non-empty? */
+	e_beq	1,.Ldone			/* skip loading r2 */
+
+	e_lwz	2,.Lsda2(11)			/* load r2 with _SDA2_BASE_ address */
+
+/* Done adjusting pointers, return by way of doing the C++ global constructors.  */
+
+.Ldone:
+	e_b	FUNC_NAME(__init)	/* do any C++ global constructors (which returns to caller) */
+#else
+#ifndef _RELOCATABLE
+	addis	10,0,.Linit_p@ha		/* init flag */
+	addis	11,0,.LCTOC1@ha			/* load address of .LCTOC1 */
+	lwz	9,.Linit_p@l(10)		/* init flag */
+	addi	11,11,.LCTOC1@l
+	cmplwi	2,9,0				/* init flag != 0? */
+	bnelr	2				/* return now, if we've been called already */
+	stw	1,.Linit_p@l(10)		/* store a nonzero value in the done flag */
+
+#else /* -mrelocatable */
+	mflr	0
+	bl	.Laddr				/* get current address */
+.Laddr:
+	mflr	12				/* real address of .Laddr */
+	lwz	11,(.Lptr-.Laddr)(12)		/* linker generated address of .LCTOC1 */
+	add	11,11,12			/* correct to real pointer */
+	lwz	12,.Ltable(11)			/* get linker's idea of where .Laddr is */
+	lwz	10,.Linit(11)			/* address of init flag */
+	subf.	12,12,11			/* calculate difference */
+	lwzx	9,10,12				/* done flag */
+	cmplwi	2,9,0				/* init flag != 0? */
+	mtlr	0				/* restore in case branch was taken */
+	bnelr	2				/* return now, if we've been called already */
+	stwx	1,10,12				/* store a nonzero value in the done flag */
+	beq+	0,.Lsdata			/* skip if we don't need to relocate */
+
+/* We need to relocate the .got2 pointers.  */
+
+	lwz	3,.Lgot2s(11)			/* GOT2 pointers start */
+	lwz	4,.Lgot2e(11)			/* GOT2 pointers end */
+	add	3,12,3				/* adjust pointers */
+	add	4,12,4
+	bl	FUNC_NAME(__eabi_convert)	/* convert pointers in .got2 section */
+
+/* Fixup the .ctor section for static constructors */
+
+	lwz	3,.Lctors(11)			/* constructors pointers start */
+	lwz	4,.Lctore(11)			/* constructors pointers end */
+	bl	FUNC_NAME(__eabi_convert)	/* convert constructors */
+
+/* Fixup the .dtor section for static destructors */
+
+	lwz	3,.Ldtors(11)			/* destructors pointers start */
+	lwz	4,.Ldtore(11)			/* destructors pointers end */
+	bl	FUNC_NAME(__eabi_convert)	/* convert destructors */
+
+/* Fixup the .gcc_except_table section for G++ exceptions */
+
+	lwz	3,.Lexcepts(11)			/* exception table pointers start */
+	lwz	4,.Lexcepte(11)			/* exception table pointers end */
+	bl	FUNC_NAME(__eabi_convert)	/* convert exceptions */
+
+/* Fixup the addresses in the GOT below _GLOBAL_OFFSET_TABLE_-4 */
+
+	lwz	3,.Lgots(11)			/* GOT table pointers start */
+	lwz	4,.Lgotm1(11)			/* GOT table pointers below _GLOBAL_OFFSET_TABLE-4 */
+	bl	FUNC_NAME(__eabi_convert)	/* convert lower GOT */
+
+/* Fixup the addresses in the GOT above _GLOBAL_OFFSET_TABLE_+12 */
+
+	lwz	3,.Lgotm2(11)			/* GOT table pointers above _GLOBAL_OFFSET_TABLE+12 */
+	lwz	4,.Lgote(11)			/* GOT table pointers end */
+	bl	FUNC_NAME(__eabi_convert)	/* convert lower GOT */
+
+/* Fixup any user initialized pointers now (the compiler drops pointers to */
+/* each of the relocs that it does in the .fixup section).  */
+
+.Lfix:
+	lwz	3,.Lfixups(11)			/* fixup pointers start */
+	lwz	4,.Lfixupe(11)			/* fixup pointers end */
+	bl	FUNC_NAME(__eabi_uconvert)	/* convert user initialized pointers */
+
+.Lsdata:
+	mtlr	0				/* restore link register */
+#endif /* _RELOCATABLE */
+
+/* Only load up register 13 if there is a .sdata and/or .sbss section */
+	lwz	3,.Lsdas(11)			/* start of .sdata/.sbss section */
+	lwz	4,.Lsdae(11)			/* end of .sdata/.sbss section */
+	cmpw	1,3,4				/* .sdata/.sbss section non-empty? */
+	beq-	1,.Lsda2l			/* skip loading r13 */
+
+	lwz	13,.Lsda(11)			/* load r13 with _SDA_BASE_ address */
+
+/* Only load up register 2 if there is a .sdata2 and/or .sbss2 section */
+
+.Lsda2l:	
+	lwz	3,.Lsda2s(11)			/* start of .sdata/.sbss section */
+	lwz	4,.Lsda2e(11)			/* end of .sdata/.sbss section */
+	cmpw	1,3,4				/* .sdata/.sbss section non-empty? */
+	beq+	1,.Ldone			/* skip loading r2 */
+
+	lwz	2,.Lsda2(11)			/* load r2 with _SDA2_BASE_ address */
+
+/* Done adjusting pointers, return by way of doing the C++ global constructors.  */
+
+.Ldone:
+	b	FUNC_NAME(__init)	/* do any C++ global constructors (which returns to caller) */
+#endif
+FUNC_END(__eabi)
+
+/* Special subroutine to convert a bunch of pointers directly.
+   r0		has original link register
+   r3		has low pointer to convert
+   r4		has high pointer to convert
+   r5 .. r10	are scratch registers
+   r11		has the address of .LCTOC1 in it.
+   r12		has the value to add to each pointer
+   r13 .. r31	are unchanged */
+#ifdef _RELOCATABLE
+#ifdef __VLE__
+FUNC_START(__eabi_convert)
+        cmpw	1,3,4				/* any pointers to convert? */
+        subf	5,3,4				/* calculate number of words to convert */
+	e_blt	1,.Lbnelr_3
+	se_blr					/* return if no pointers */
+.Lbnelr_3:
+
+        srawi	5,5,2
+	e_add16i	3,3,-4				/* start-4 for use with lwzu */
+        mtctr	5
+
+.Lcvt:
+	e_lwzu	6,4(3)				/* pointer to convert */
+	e_cmpi	0,6,0
+	e_beq	.Lcvt2				/* if pointer is null, don't convert */
+
+        add	6,6,12				/* convert pointer */
+        e_stw	6,0(3)
+.Lcvt2:
+        e_bdnz	.Lcvt
+        se_blr
+FUNC_END(__eabi_convert)
+#else
+FUNC_START(__eabi_convert)
+        cmplw	1,3,4				/* any pointers to convert? */
+        subf	5,3,4				/* calculate number of words to convert */
+        bclr	4,4				/* return if no pointers */
+
+        srawi	5,5,2
+	addi	3,3,-4				/* start-4 for use with lwzu */
+        mtctr	5
+
+.Lcvt:
+	lwzu	6,4(3)				/* pointer to convert */
+	cmpwi	0,6,0
+	beq-	.Lcvt2				/* if pointer is null, don't convert */
+
+        add	6,6,12				/* convert pointer */
+        stw	6,0(3)
+.Lcvt2:
+        bdnz+	.Lcvt
+        blr
+FUNC_END(__eabi_convert)
+#endif
+
+/* Special subroutine to convert the pointers the user has initialized.  The
+   compiler has placed the address of the initialized pointer into the .fixup
+   section.
+
+   r0		has original link register
+   r3		has low pointer to convert
+   r4		has high pointer to convert
+   r5 .. r10	are scratch registers
+   r11		has the address of .LCTOC1 in it.
+   r12		has the value to add to each pointer
+   r13 .. r31	are unchanged */
+
+#ifdef __VLE__
+FUNC_START(__eabi_uconvert)
+        cmpw	1,3,4				/* any pointers to convert? */
+        subf	5,3,4				/* calculate number of words to convert */
+	e_blt	1,.Lbnelr_4
+	se_blr					/* return if no pointers */
+.Lbnelr_4:
+
+        srawi	5,5,2
+	e_add16i	3,3,-4				/* start-4 for use with lwzu */
+        mtctr	5
+
+.Lucvt:
+	e_lwzu	6,4(3)				/* next pointer to pointer to convert */
+	add	6,6,12				/* adjust pointer */
+	e_lwz	7,0(6)				/* get the pointer it points to */
+	e_stw	6,0(3)				/* store adjusted pointer */
+	add	7,7,12				/* adjust */
+	e_stw	7,0(6)
+        e_bdnz	.Lucvt
+        se_blr
+FUNC_END(__eabi_uconvert)
+#else
+FUNC_START(__eabi_uconvert)
+        cmplw	1,3,4				/* any pointers to convert? */
+        subf	5,3,4				/* calculate number of words to convert */
+        bclr	4,4				/* return if no pointers */
+
+        srawi	5,5,2
+	addi	3,3,-4				/* start-4 for use with lwzu */
+        mtctr	5
+
+.Lucvt:
+	lwzu	6,4(3)				/* next pointer to pointer to convert */
+	add	6,6,12				/* adjust pointer */
+	lwz	7,0(6)				/* get the pointer it points to */
+	stw	6,0(3)				/* store adjusted pointer */
+	add	7,7,12				/* adjust */
+	stw	7,0(6)
+        bdnz+	.Lucvt
+        blr
+FUNC_END(__eabi_uconvert)
+#endif
+#endif
+#endif
diff --git a/libgcc/config/rs6000/sol-ci.S b/libgcc/config/rs6000/sol-ci.S
index e5b5635..6ded473 100644
--- a/libgcc/config/rs6000/sol-ci.S
+++ b/libgcc/config/rs6000/sol-ci.S
@@ -27,7 +27,7 @@
  
 	.ident	"GNU C scrti.s"
 
-#ifndef __powerpc64__
+#if !defined(__powerpc64__) && !defined(__VLE__)
 # Start of .text
 	.section ".text"
 	.globl	_ex_text0
diff --git a/libgcc/config/rs6000/sol-cn.S b/libgcc/config/rs6000/sol-cn.S
index 7a5f43c..7a934f1 100644
--- a/libgcc/config/rs6000/sol-cn.S
+++ b/libgcc/config/rs6000/sol-cn.S
@@ -27,7 +27,7 @@
  
 	.ident	"GNU C scrtn.s"
 
-#ifndef __powerpc64__
+#if !defined(__powerpc64__) && !defined(__VLE__)
 # Default versions of exception handling register/deregister
 	.weak	_ex_register
 	.weak	_ex_deregister
diff --git a/libgcc/config/rs6000/t-e200 b/libgcc/config/rs6000/t-e200
new file mode 100644
index 0000000..f8a3d2e
--- /dev/null
+++ b/libgcc/config/rs6000/t-e200
@@ -0,0 +1,29 @@
+# These can't end up in shared libgcc
+LIB2ADD_ST += \
+	   $(srcdir)/config/rs6000/tramp.S \
+	   $(srcdir)/config/rs6000/e200crtsavgpr.S \
+	   $(srcdir)/config/rs6000/e200crtresgpr.S \
+	   $(srcdir)/config/rs6000/e200crtresxgpr.S \
+	   $(srcdir)/config/rs6000/e200crtres32gpr.S \
+	   $(srcdir)/config/rs6000/e200crtres64gpr.S \
+	   $(srcdir)/config/rs6000/e200crtres64gprctr.S \
+	   $(srcdir)/config/rs6000/e200crtrest32gpr.S \
+	   $(srcdir)/config/rs6000/e200crtrest64gpr.S \
+	   $(srcdir)/config/rs6000/e200crtresx32gpr.S \
+	   $(srcdir)/config/rs6000/e200crtresx64gpr.S \
+	   $(srcdir)/config/rs6000/e200crtsav32gpr.S \
+	   $(srcdir)/config/rs6000/e200crtsav64gpr.S \
+	   $(srcdir)/config/rs6000/e200crtsav64gprctr.S \
+	   $(srcdir)/config/rs6000/eabivle.S
+
+# We build {e,n}crti.o and {e,n}crtn.o, which serve to add begin and
+# end labels to all of the special sections used when we link using gcc.
+
+# Assemble startup files.
+ecrti$(objext): $(srcdir)/config/rs6000/eabivle-ci.S
+	$(crt_compile) -c $<
+
+ecrtn$(objext): $(srcdir)/config/rs6000/eabivle-cn.S
+	$(crt_compile) -c $<
+
+	   
diff --git a/libgcc/config/rs6000/tramp.S b/libgcc/config/rs6000/tramp.S
index 6f435b5..f39456d 100644
--- a/libgcc/config/rs6000/tramp.S
+++ b/libgcc/config/rs6000/tramp.S
@@ -29,7 +29,84 @@
 #include "ppc-asm.h"
 #include "config.h"
 
-#ifndef __powerpc64__
+#ifdef __VLE__
+	.type	trampoline_initial,@object
+	.align	2
+trampoline_initial:
+	se_mflr	r0
+	se_bl	1f
+.Lfunc = .-trampoline_initial
+	.long	0			/* will be replaced with function address */
+.Lchain = .-trampoline_initial
+	.long	0			/* will be replaced with static chain */
+1:	mflr	r11
+	se_mtlr	r0
+	e_lwz	r0,0(r11)		/* function address */
+	e_lwz	r11,4(r11)		/* static chain */
+	se_mtctr	r0
+	se_bctr
+	se_nop				/* Bump initialization size to 32.  */
+
+trampoline_size = .-trampoline_initial
+	.size	trampoline_initial,trampoline_size
+
+
+/* R3 = stack address to store trampoline */
+/* R4 = length of trampoline area */
+/* R5 = function address */
+/* R6 = static chain */
+
+FUNC_START(__trampoline_setup)
+	se_mflr	r0		/* save return address */
+	se_bl	.LCF0		/* load up __trampoline_initial into r7 */
+.LCF0:
+        mflr	r11
+        e_add16i r7,r11,trampoline_initial-4-.LCF0 /* trampoline address -4 */
+
+	e_li	r8,trampoline_size	/* verify that the trampoline is big enough */
+	cmpw	cr1,r8,r4
+	e_srwi	r4,r4,2		/* # words to move */
+	e_add16i r9,r3,-4	/* adjust pointer for lwzu */
+	se_mtctr r4
+	e_blt	cr1,.Labort
+
+	se_mtlr	r0
+
+	/* Copy the instructions to the stack */
+.Lmove:
+	e_lwzu	r10,4(r7)
+	e_stwu	r10,4(r9)
+	e_bdnz	.Lmove
+
+	/* Store correct function and static chain */
+	e_stw	r5,.Lfunc(r3)
+	e_stw	r6,.Lchain(r3)
+
+	/* Now flush both caches */
+	se_mtctr r4
+.Lcache:
+	icbi	0,r3
+	dcbf	0,r3
+	e_add16i r3,r3,4
+	e_bdnz	.Lcache
+
+	/* Finally synchronize things & return */
+	sync
+	se_isync
+	se_blr
+
+.Labort:
+#if (defined __PIC__ || defined __pic__) && defined HAVE_AS_REL16
+	se_bl	1f
+1:	se_mflr	r30
+	e_add2is r30,_GLOBAL_OFFSET_TABLE_-1b@ha
+	e_add16i r30,r30,_GLOBAL_OFFSET_TABLE_-1b@l
+#endif
+	e_bl	JUMP_TARGET(abort)
+FUNC_END(__trampoline_setup)
+
+#elif !defined(__powerpc64__)
+
 	.type	trampoline_initial,@object
 	.align	2
 trampoline_initial:
diff --git a/libgcc/configure b/libgcc/configure
index 35896de..c5b1984 100644
--- a/libgcc/configure
+++ b/libgcc/configure
@@ -2271,7 +2271,9 @@ case "${host}" in
     rs6000-ibm-aix* | powerpc-ibm-aix*)
 	# All AIX code is PIC.
 	;;
-
+    powerpc-*-eabivle)
+	# no PIC.
+	;;
     # Some targets support both -fPIC and -fpic, but prefer the latter.
     # FIXME: Why?
     i[34567]86-*-* | x86_64-*-*)
@@ -4354,6 +4356,21 @@ fi
 $as_echo "$libgcc_cv_mips_hard_float" >&6; }
 esac
 
+# Check SPE for rs6000.
+case ${host} in
+powerpc*)
+  cat > conftest.c <<EOF
+#if defined __SPE__ && !defined __VLE__
+ppc_has_spe=yes
+#else
+ppc_has_spe=no
+#endif
+EOF
+    eval `${CC-cc} -E conftest.c | grep ppc_has_spe=`
+    rm -f conftest.c
+    ;;
+esac
+
 # Collect host-machine-specific information.
 . ${srcdir}/config.host
 
diff --git a/libgcc/configure.ac b/libgcc/configure.ac
index d877d21..cf8704f 100644
--- a/libgcc/configure.ac
+++ b/libgcc/configure.ac
@@ -304,6 +304,21 @@ mips*-*-*)
     [libgcc_cv_mips_hard_float=no])])
 esac
 
+# Check SPE for rs6000.
+case ${host} in
+powerpc*)
+  cat > conftest.c <<EOF
+#if defined __SPE__ && !defined __VLE__
+ppc_has_spe=yes
+#else
+ppc_has_spe=no
+#endif
+EOF
+    eval `${CC-cc} -E conftest.c | grep ppc_has_spe=`
+    rm -f conftest.c
+    ;;
+esac
+
 # Collect host-machine-specific information.
 . ${srcdir}/config.host
 
diff --git a/libiberty/Makefile.in b/libiberty/Makefile.in
index 75ff82d..7089a71 100644
--- a/libiberty/Makefile.in
+++ b/libiberty/Makefile.in
@@ -142,7 +142,7 @@ CFILES = alloca.c argv.c asprintf.c atexit.c				\
 	partition.c pexecute.c						\
 	 pex-common.c pex-djgpp.c pex-msdos.c pex-one.c			\
 	 pex-unix.c pex-win32.c						\
-         physmem.c putenv.c						\
+         physmem.c putenv.c qsort.c					\
 	random.c regex.c rename.c rindex.c				\
 	safe-ctype.c setenv.c setproctitle.c sha1.c sigsetmask.c        \
 	 simple-object.c simple-object-coff.c simple-object-elf.c	\
@@ -179,7 +179,7 @@ REQUIRED_OFILES =							\
 	./obstack.$(objext)						\
 	./partition.$(objext) ./pexecute.$(objext) ./physmem.$(objext)	\
 	./pex-common.$(objext) ./pex-one.$(objext)			\
-	./@pexecute@.$(objext)						\
+	./@pexecute@.$(objext) ./qsort.$(objext)			\
 	./safe-ctype.$(objext)						\
 	./simple-object.$(objext) ./simple-object-coff.$(objext)	\
 	./simple-object-elf.$(objext) ./simple-object-mach-o.$(objext)	\
@@ -930,6 +930,15 @@ $(CONFIGURED_OFILES): stamp-picdir
 	else true; fi
 	$(COMPILE.c) $(srcdir)/putenv.c $(OUTPUT_OPTION)
 
+./qsort.$(objext): $(srcdir)/qsort.c $(INCDIR)/ansidecl.h
+	if [ x"$(PICFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(srcdir)/qsort.c -o pic/$@; \
+	else true; fi
+	if [ x"$(NOASANFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(NOASANFLAG) $(srcdir)/qsort.c -o noasan/$@; \
+	else true; fi
+	  $(COMPILE.c) $(srcdir)/qsort.c $(OUTPUT_OPTION)
+
 ./random.$(objext): $(srcdir)/random.c $(INCDIR)/ansidecl.h
 	if [ x"$(PICFLAG)" != x ]; then \
 	  $(COMPILE.c) $(PICFLAG) $(srcdir)/random.c -o pic/$@; \
diff --git a/libiberty/qsort.c b/libiberty/qsort.c
new file mode 100644
index 0000000..1445351
--- /dev/null
+++ b/libiberty/qsort.c
@@ -0,0 +1,262 @@
+/* Copyright (C) 1991-2016 Free Software Foundation, Inc.
+This file is part of the GNU C Library.
+Written by Douglas C. Schmidt (schmidt@ics.uci.edu).
+
+The GNU C Library is free software; you can redistribute it and/or
+modify it under the terms of the GNU Lesser General Public
+License as published by the Free Software Foundation; either
+version 2.1 of the License, or (at your option) any later version.
+
+The GNU C Library is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+Lesser General Public License for more details.
+
+You should have received a copy of the GNU Lesser General Public
+License along with the GNU C Library; if not, see
+<http://www.gnu.org/licenses/>.  */
+
+/* If you consider tuning this algorithm, you should consult first:
+Engineering a sort function; Jon Bentley and M. Douglas McIlroy;
+Software - Practice and Experience; Vol. 23 (11), 1249-1265, 1993.  */
+
+#if defined(__MINGW32__) 
+ #include <malloc.h>
+#else
+ #include <alloca.h>
+#endif
+#include <limits.h>
+#include <stdlib.h>
+#include <string.h>
+
+/* Byte-wise swap two items of size SIZE. */
+#define SWAP(a, b, size)						      \
+  do									      \
+    {									      \
+      size_t __size = (size);						      \
+      char *__a = (a), *__b = (b);					      \
+      do								      \
+	{								      \
+	  char __tmp = *__a;						      \
+	  *__a++ = *__b;						      \
+	  *__b++ = __tmp;						      \
+	} while (--__size > 0);						      \
+    } while (0)
+
+/* Discontinue quicksort algorithm when partition gets below this size.
+This particular magic number was chosen to work best on a Sun 4/260. */
+#define MAX_THRESH 4
+
+/* Stack node declarations used to store unfulfilled partition obligations. */
+typedef struct
+  {
+  char *lo;
+  char *hi;
+  } stack_node;
+
+/* The next 4 #defines implement a very fast in-line stack abstraction. */
+/* The stack needs log (total_elements) entries (we could even subtract
+log(MAX_THRESH)).  Since total_elements has type size_t, we get as
+upper bound for log (total_elements):
+bits per byte (CHAR_BIT) * sizeof(size_t).  */
+#define STACK_SIZE	(CHAR_BIT * sizeof(size_t))
+#define PUSH(low, high)	((void) ((top->lo = (low)), (top->hi = (high)), ++top))
+#define	POP(low, high)	((void) (--top, (low = top->lo), (high = top->hi)))
+#define	STACK_NOT_EMPTY	(stack < top)
+
+typedef int(*__compar_fn_t) (const void *, const void *);
+typedef int(*__compar_d_fn_t) (const void *, const void *, void *);
+
+/* Order size using quicksort.  This implementation incorporates
+four optimizations discussed in Sedgewick:
+
+1. Non-recursive, using an explicit stack of pointer that store the
+next array partition to sort.  To save time, this maximum amount
+of space required to store an array of SIZE_MAX is allocated on the
+stack.  Assuming a 32-bit (64 bit) integer for size_t, this needs
+only 32 * sizeof(stack_node) == 256 bytes (for 64 bit: 1024 bytes).
+Pretty cheap, actually.
+
+2. Chose the pivot element using a median-of-three decision tree.
+This reduces the probability of selecting a bad pivot value and
+eliminates certain extraneous comparisons.
+
+3. Only quicksorts TOTAL_ELEMS / MAX_THRESH partitions, leaving
+insertion sort to order the MAX_THRESH items within each partition.
+This is a big win, since insertion sort is faster for small, mostly
+sorted array segments.
+
+4. The larger of the two sub-partitions is always pushed onto the
+stack first, with the algorithm then concentrating on the
+smaller partition.  This *guarantees* no more than log (total_elems)
+stack size is needed (actually O(1) in this case)!  */
+
+void
+_quicksort(void *const pbase, size_t total_elems, size_t size,
+  __compar_d_fn_t cmp, void *arg)
+  {
+  char *base_ptr = (char *)pbase;
+
+  const size_t max_thresh = MAX_THRESH * size;
+
+  if (total_elems == 0)
+    /* Avoid lossage with unsigned arithmetic below.  */
+    return;
+
+  if (total_elems > MAX_THRESH)
+    {
+    char *lo = base_ptr;
+    char *hi = &lo[size * (total_elems - 1)];
+    stack_node stack[STACK_SIZE];
+    stack_node *top = stack;
+
+    PUSH(NULL, NULL);
+
+    while (STACK_NOT_EMPTY)
+      {
+      char *left_ptr;
+      char *right_ptr;
+
+      /* Select median value from among LO, MID, and HI. Rearrange
+      LO and HI so the three values are sorted. This lowers the
+      probability of picking a pathological pivot value and
+      skips a comparison for both the LEFT_PTR and RIGHT_PTR in
+      the while loops. */
+
+      char *mid = lo + size * ((hi - lo) / size >> 1);
+
+      if ((*cmp) ((void *)mid, (void *)lo, arg) < 0)
+        SWAP(mid, lo, size);
+      if ((*cmp) ((void *)hi, (void *)mid, arg) < 0)
+        SWAP(mid, hi, size);
+      else
+        goto jump_over;
+      if ((*cmp) ((void *)mid, (void *)lo, arg) < 0)
+        SWAP(mid, lo, size);
+jump_over:;
+
+      left_ptr = lo + size;
+      right_ptr = hi - size;
+
+      /* Here's the famous ``collapse the walls'' section of quicksort.
+      Gotta like those tight inner loops!  They are the main reason
+      that this algorithm runs much faster than others. */
+      do
+        {
+        while ((*cmp) ((void *)left_ptr, (void *)mid, arg) < 0)
+          left_ptr += size;
+
+        while ((*cmp) ((void *)mid, (void *)right_ptr, arg) < 0)
+          right_ptr -= size;
+
+        if (left_ptr < right_ptr)
+          {
+          SWAP(left_ptr, right_ptr, size);
+          if (mid == left_ptr)
+            mid = right_ptr;
+          else if (mid == right_ptr)
+            mid = left_ptr;
+          left_ptr += size;
+          right_ptr -= size;
+          }
+        else if (left_ptr == right_ptr)
+          {
+          left_ptr += size;
+          right_ptr -= size;
+          break;
+          }
+        } while (left_ptr <= right_ptr);
+
+        /* Set up pointers for next iteration.  First determine whether
+        left and right partitions are below the threshold size.  If so,
+        ignore one or both.  Otherwise, push the larger partition's
+        bounds on the stack and continue sorting the smaller one. */
+
+        if ((size_t)(right_ptr - lo) <= max_thresh)
+          {
+          if ((size_t)(hi - left_ptr) <= max_thresh)
+            /* Ignore both small partitions. */
+            POP(lo, hi);
+          else
+            /* Ignore small left partition. */
+            lo = left_ptr;
+          }
+        else if ((size_t)(hi - left_ptr) <= max_thresh)
+          /* Ignore small right partition. */
+          hi = right_ptr;
+        else if ((right_ptr - lo) > (hi - left_ptr))
+          {
+          /* Push larger left partition indices. */
+          PUSH(lo, right_ptr);
+          lo = left_ptr;
+          }
+        else
+          {
+          /* Push larger right partition indices. */
+          PUSH(left_ptr, hi);
+          hi = right_ptr;
+          }
+      }
+    }
+
+  /* Once the BASE_PTR array is partially sorted by quicksort the rest
+  is completely sorted using insertion sort, since this is efficient
+  for partitions below MAX_THRESH size. BASE_PTR points to the beginning
+  of the array to sort, and END_PTR points at the very last element in
+  the array (*not* one beyond it!). */
+
+#define min(x, y) ((x) < (y) ? (x) : (y))
+
+    {
+    char *const end_ptr = &base_ptr[size * (total_elems - 1)];
+    char *tmp_ptr = base_ptr;
+    char *thresh = min(end_ptr, base_ptr + max_thresh);
+    char *run_ptr;
+
+    /* Find smallest element in first threshold and place it at the
+    array's beginning.  This is the smallest array element,
+    and the operation speeds up insertion sort's inner loop. */
+
+    for (run_ptr = tmp_ptr + size; run_ptr <= thresh; run_ptr += size)
+      if ((*cmp) ((void *)run_ptr, (void *)tmp_ptr, arg) < 0)
+        tmp_ptr = run_ptr;
+
+    if (tmp_ptr != base_ptr)
+      SWAP(tmp_ptr, base_ptr, size);
+
+    /* Insertion sort, running from left-hand-side up to right-hand-side.  */
+
+    run_ptr = base_ptr + size;
+    while ((run_ptr += size) <= end_ptr)
+      {
+      tmp_ptr = run_ptr - size;
+      while ((*cmp) ((void *)run_ptr, (void *)tmp_ptr, arg) < 0)
+        tmp_ptr -= size;
+
+      tmp_ptr += size;
+      if (tmp_ptr != run_ptr)
+        {
+        char *trav;
+
+        trav = run_ptr + size;
+        while (--trav >= run_ptr)
+          {
+          char c = *trav;
+          char *hi, *lo;
+
+          for (hi = lo = trav; (lo -= size) >= tmp_ptr; hi = lo)
+            *hi = *lo;
+          *hi = c;
+          }
+        }
+      }
+    }
+  }
+
+
+void
+qsort(void *b, size_t n, size_t s, __compar_fn_t cmp)
+  {
+  _quicksort(b, n, s, (__compar_d_fn_t)cmp, NULL);
+  }
+
diff -ru gcc-4.9.4-orig/gcc/config/rs6000/rs6000.md gcc-4.9.4/gcc/config/rs6000/rs6000.md
--- gcc-4.9.4-orig/gcc/config/rs6000/rs6000.md	2017-05-22 13:26:01.703595129 -0500
+++ gcc-4.9.4/gcc/config/rs6000/rs6000.md	2017-05-24 15:20:53.767558124 -0500
@@ -2244,7 +2244,7 @@
 			     (match_operand:P 2 "gpc_reg_operand" "r,r"))
 		    (const_int 0)))
    (clobber (match_scratch:P 3 "=r,r"))]
-  ""
+  "!TARGET_VLE"
   "@
    subf. %3,%2,%1
    #"
@@ -13063,7 +13063,7 @@
    "TARGET_ELF && ! TARGET_64BIT && TARGET_VLE"
    "@
     %^la %0,%2@l(%1)
-    mr 23,%1\n\t%^add16i %0,23,%K2")
+    %^add16i %0,%1,%K2")
 
 ;; Call and call_value insns
 (define_expand "call"
@@ -13871,6 +13871,10 @@
 				    GET_MODE (operands[0]),
 				    operands[1], operands[2]);
    }
+  if (TARGET_VLE && GET_CODE (operands[2]) == CONST_INT)
+    {
+      operands[2] = force_reg (<MODE>mode, operands[2]);
+    }
 
   rs6000_emit_cbranch (<MODE>mode, operands);
   DONE;
@@ -13906,6 +13910,10 @@
 				    GET_MODE (operands[1]),
 				    operands[2], operands[3]);
     }
+  if (TARGET_VLE && GET_CODE (operands[3]) == CONST_INT)
+    {
+      operands[3] = force_reg (<MODE>mode, operands[3]);
+    }
 
   /* For SNE, we would prefer that the xor/abs sequence be used for integers.
      For SEQ, likewise, except that comparisons with zero should be done
@@ -14033,20 +14033,18 @@
    (set_attr "length" "2,2,4,4,4")])
 
 (define_insn "*cmpsi_arithmetic_vle"
-  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,kcreg,?y,?y,?y")
-	(compare:CC (match_operand:SI 1 "gpc_reg_operand" "kregs,kregs,r,r,r,r,r")
-		    (match_operand:SI 2 "vle_arith_cmpsi_operand" "kregs,kuim5,I,ksci8,r,kli20,ksci8")))]
+  [(set (match_operand:CC 0 "cc_reg_operand" "=x,x,x,kcreg,?y")
+	(compare:CC (match_operand:SI 1 "gpc_reg_operand" "kregs,kregs,r,r,r")
+		    (match_operand:SI 2 "vle_arith_cmpsi_operand" "kregs,kuim5,I,ksci8,r")))]
   "TARGET_VLE"
   "@
    se_cmp %1,%2
    se_cmpi %1,%2
    e_cmp16i %1,%2
    e_cmpi %0,%1,%2
-   cmp %0,%1,%2
-   e_li 23,%2\n\tcmp %0,%1,23
-   e_lis 23,%2@h\n\te_or2i 23,%2@l\n\tcmp %0,%1,23"
-  [(set_attr "type" "cmp,cmp,cmp,cmp,cmp,cmp,cmp")
-   (set_attr "length" "2,2,4,4,4,8,12")])
+   cmp %0,%1,%2"
+  [(set_attr "type" "cmp,cmp,cmp,cmp,cmp")
+   (set_attr "length" "2,2,4,4,4")])
 
 (define_insn "*cmphi_logical_vle"
   [(set (match_operand:CCUNS 0 "cc_reg_operand" "=x,x,?y")
diff -ruN gcc-4.9.4-origin/gcc/config/rs6000/rs6000.md gcc-4.9.4/gcc/config/rs6000/rs6000.md
--- gcc-4.9.4-origin/gcc/config/rs6000/rs6000.md	2017-12-06 12:57:31.846522367 -0600
+++ gcc-4.9.4/gcc/config/rs6000/rs6000.md	2017-12-06 13:01:08.065507145 -0600
@@ -16690,7 +16690,7 @@
   [(set (match_operand:DI 0 "gpc_reg_operand" "=r")
         (unspec_volatile:DI [(const_int 0)] UNSPECV_MFTB))
    (clobber (match_scratch:SI 1 "=r"))
-   (clobber (match_scratch:CC 2 "=y"))]
+   (clobber (match_scratch:CC 2 "=kcreg"))]
   "!TARGET_POWERPC64"
 {
   if (WORDS_BIG_ENDIAN)
--- gcc-4.9.4/gcc/config/rs6000/rs6000.md~	2017-12-06 14:11:19.233210679 -0600
+++ gcc-4.9.4/gcc/config/rs6000/rs6000.md	2017-12-06 14:22:39.985162754 -0600
@@ -13407,10 +13407,10 @@
     && (INTVAL (operands[3]) & CALL_LONG) == 0)"
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn ("crxor 6,6,6", operands);
+    output_asm_insn ("%^crxor 6,6,6", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn ("creqv 6,6,6", operands);
+    output_asm_insn ("%^creqv 6,6,6", operands);
 
   if (flag_pic == 2)
     return "bl %z1+32768@plt";
@@ -13698,10 +13698,10 @@
   "*
 {
   if (INTVAL (operands[2]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[2]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
   if (which_alternative >= 2)
     return \"%+b%T0\";
@@ -13729,10 +13729,10 @@
   "*
 {
   if (INTVAL (operands[3]) & CALL_V4_SET_FP_ARGS)
-    output_asm_insn (\"crxor 6,6,6\", operands);
+    output_asm_insn (\"%^crxor 6,6,6\", operands);
 
   else if (INTVAL (operands[3]) & CALL_V4_CLEAR_FP_ARGS)
-    output_asm_insn (\"creqv 6,6,6\", operands);
+    output_asm_insn (\"%^creqv 6,6,6\", operands);
 
   if (which_alternative >= 2)
     return \"%+b%T1\";
